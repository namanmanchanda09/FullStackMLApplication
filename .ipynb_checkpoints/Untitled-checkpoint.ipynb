{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.drop('species',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=iris['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4,activation='relu',input_shape=[4,]))\n",
    "model.add(Dense(3,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/300\n",
      "120/120 [==============================] - 1s 8ms/sample - loss: 1.2169 - accuracy: 0.3250 - val_loss: 1.1238 - val_accuracy: 0.3333\n",
      "Epoch 2/300\n",
      "120/120 [==============================] - 0s 342us/sample - loss: 1.2073 - accuracy: 0.3333 - val_loss: 1.1172 - val_accuracy: 0.3333\n",
      "Epoch 3/300\n",
      "120/120 [==============================] - 0s 418us/sample - loss: 1.1985 - accuracy: 0.3333 - val_loss: 1.1107 - val_accuracy: 0.3333\n",
      "Epoch 4/300\n",
      "120/120 [==============================] - 0s 314us/sample - loss: 1.1898 - accuracy: 0.3333 - val_loss: 1.1042 - val_accuracy: 0.3333\n",
      "Epoch 5/300\n",
      "120/120 [==============================] - 0s 305us/sample - loss: 1.1813 - accuracy: 0.3333 - val_loss: 1.0979 - val_accuracy: 0.3333\n",
      "Epoch 6/300\n",
      "120/120 [==============================] - 0s 351us/sample - loss: 1.1724 - accuracy: 0.3333 - val_loss: 1.0916 - val_accuracy: 0.3333\n",
      "Epoch 7/300\n",
      "120/120 [==============================] - 0s 418us/sample - loss: 1.1638 - accuracy: 0.3333 - val_loss: 1.0858 - val_accuracy: 0.3333\n",
      "Epoch 8/300\n",
      "120/120 [==============================] - 0s 309us/sample - loss: 1.1555 - accuracy: 0.3333 - val_loss: 1.0801 - val_accuracy: 0.3333\n",
      "Epoch 9/300\n",
      "120/120 [==============================] - 0s 386us/sample - loss: 1.1476 - accuracy: 0.3333 - val_loss: 1.0747 - val_accuracy: 0.3333\n",
      "Epoch 10/300\n",
      "120/120 [==============================] - 0s 289us/sample - loss: 1.1399 - accuracy: 0.3333 - val_loss: 1.0694 - val_accuracy: 0.3333\n",
      "Epoch 11/300\n",
      "120/120 [==============================] - 0s 392us/sample - loss: 1.1321 - accuracy: 0.3333 - val_loss: 1.0645 - val_accuracy: 0.3333\n",
      "Epoch 12/300\n",
      "120/120 [==============================] - 0s 318us/sample - loss: 1.1247 - accuracy: 0.3333 - val_loss: 1.0596 - val_accuracy: 0.3333\n",
      "Epoch 13/300\n",
      "120/120 [==============================] - 0s 269us/sample - loss: 1.1171 - accuracy: 0.3333 - val_loss: 1.0548 - val_accuracy: 0.3333\n",
      "Epoch 14/300\n",
      "120/120 [==============================] - 0s 396us/sample - loss: 1.1103 - accuracy: 0.3333 - val_loss: 1.0500 - val_accuracy: 0.3333\n",
      "Epoch 15/300\n",
      "120/120 [==============================] - 0s 442us/sample - loss: 1.1032 - accuracy: 0.3333 - val_loss: 1.0454 - val_accuracy: 0.3333\n",
      "Epoch 16/300\n",
      "120/120 [==============================] - 0s 379us/sample - loss: 1.0964 - accuracy: 0.3333 - val_loss: 1.0408 - val_accuracy: 0.3333\n",
      "Epoch 17/300\n",
      "120/120 [==============================] - 0s 276us/sample - loss: 1.0896 - accuracy: 0.3333 - val_loss: 1.0365 - val_accuracy: 0.3333\n",
      "Epoch 18/300\n",
      "120/120 [==============================] - 0s 330us/sample - loss: 1.0834 - accuracy: 0.3333 - val_loss: 1.0322 - val_accuracy: 0.3333\n",
      "Epoch 19/300\n",
      "120/120 [==============================] - 0s 282us/sample - loss: 1.0771 - accuracy: 0.3333 - val_loss: 1.0280 - val_accuracy: 0.3333\n",
      "Epoch 20/300\n",
      "120/120 [==============================] - 0s 351us/sample - loss: 1.0713 - accuracy: 0.3333 - val_loss: 1.0238 - val_accuracy: 0.3333\n",
      "Epoch 21/300\n",
      "120/120 [==============================] - 0s 409us/sample - loss: 1.0650 - accuracy: 0.3333 - val_loss: 1.0197 - val_accuracy: 0.3333\n",
      "Epoch 22/300\n",
      "120/120 [==============================] - 0s 311us/sample - loss: 1.0592 - accuracy: 0.3333 - val_loss: 1.0156 - val_accuracy: 0.3333\n",
      "Epoch 23/300\n",
      "120/120 [==============================] - 0s 399us/sample - loss: 1.0534 - accuracy: 0.3417 - val_loss: 1.0115 - val_accuracy: 0.3333\n",
      "Epoch 24/300\n",
      "120/120 [==============================] - 0s 788us/sample - loss: 1.0476 - accuracy: 0.3417 - val_loss: 1.0076 - val_accuracy: 0.3333\n",
      "Epoch 25/300\n",
      "120/120 [==============================] - 0s 714us/sample - loss: 1.0422 - accuracy: 0.3417 - val_loss: 1.0037 - val_accuracy: 0.3667\n",
      "Epoch 26/300\n",
      "120/120 [==============================] - 0s 372us/sample - loss: 1.0366 - accuracy: 0.3500 - val_loss: 0.9998 - val_accuracy: 0.3667\n",
      "Epoch 27/300\n",
      "120/120 [==============================] - 0s 427us/sample - loss: 1.0311 - accuracy: 0.3667 - val_loss: 0.9960 - val_accuracy: 0.4000\n",
      "Epoch 28/300\n",
      "120/120 [==============================] - 0s 429us/sample - loss: 1.0257 - accuracy: 0.3833 - val_loss: 0.9923 - val_accuracy: 0.4667\n",
      "Epoch 29/300\n",
      "120/120 [==============================] - 0s 319us/sample - loss: 1.0205 - accuracy: 0.3917 - val_loss: 0.9886 - val_accuracy: 0.4667\n",
      "Epoch 30/300\n",
      "120/120 [==============================] - 0s 418us/sample - loss: 1.0153 - accuracy: 0.4167 - val_loss: 0.9849 - val_accuracy: 0.5000\n",
      "Epoch 31/300\n",
      "120/120 [==============================] - 0s 350us/sample - loss: 1.0101 - accuracy: 0.4333 - val_loss: 0.9813 - val_accuracy: 0.5333\n",
      "Epoch 32/300\n",
      "120/120 [==============================] - 0s 262us/sample - loss: 1.0049 - accuracy: 0.4833 - val_loss: 0.9776 - val_accuracy: 0.6000\n",
      "Epoch 33/300\n",
      "120/120 [==============================] - 0s 281us/sample - loss: 1.0001 - accuracy: 0.5083 - val_loss: 0.9740 - val_accuracy: 0.6000\n",
      "Epoch 34/300\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.9950 - accuracy: 0.5333 - val_loss: 0.9704 - val_accuracy: 0.6000\n",
      "Epoch 35/300\n",
      "120/120 [==============================] - 0s 226us/sample - loss: 0.9901 - accuracy: 0.5583 - val_loss: 0.9669 - val_accuracy: 0.6000\n",
      "Epoch 36/300\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.9853 - accuracy: 0.5667 - val_loss: 0.9633 - val_accuracy: 0.6000\n",
      "Epoch 37/300\n",
      "120/120 [==============================] - 0s 213us/sample - loss: 0.9805 - accuracy: 0.5667 - val_loss: 0.9599 - val_accuracy: 0.6000\n",
      "Epoch 38/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.9758 - accuracy: 0.5667 - val_loss: 0.9564 - val_accuracy: 0.6333\n",
      "Epoch 39/300\n",
      "120/120 [==============================] - 0s 211us/sample - loss: 0.9711 - accuracy: 0.5750 - val_loss: 0.9530 - val_accuracy: 0.6333\n",
      "Epoch 40/300\n",
      "120/120 [==============================] - 0s 219us/sample - loss: 0.9665 - accuracy: 0.5750 - val_loss: 0.9496 - val_accuracy: 0.6333\n",
      "Epoch 41/300\n",
      "120/120 [==============================] - 0s 227us/sample - loss: 0.9620 - accuracy: 0.5750 - val_loss: 0.9462 - val_accuracy: 0.6000\n",
      "Epoch 42/300\n",
      "120/120 [==============================] - 0s 222us/sample - loss: 0.9577 - accuracy: 0.5750 - val_loss: 0.9429 - val_accuracy: 0.6000\n",
      "Epoch 43/300\n",
      "120/120 [==============================] - 0s 206us/sample - loss: 0.9531 - accuracy: 0.5750 - val_loss: 0.9395 - val_accuracy: 0.6000\n",
      "Epoch 44/300\n",
      "120/120 [==============================] - 0s 215us/sample - loss: 0.9487 - accuracy: 0.5667 - val_loss: 0.9361 - val_accuracy: 0.6000\n",
      "Epoch 45/300\n",
      "120/120 [==============================] - 0s 272us/sample - loss: 0.9443 - accuracy: 0.5667 - val_loss: 0.9327 - val_accuracy: 0.6000\n",
      "Epoch 46/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.9400 - accuracy: 0.5667 - val_loss: 0.9293 - val_accuracy: 0.5667\n",
      "Epoch 47/300\n",
      "120/120 [==============================] - 0s 228us/sample - loss: 0.9360 - accuracy: 0.5500 - val_loss: 0.9260 - val_accuracy: 0.5667\n",
      "Epoch 48/300\n",
      "120/120 [==============================] - 0s 230us/sample - loss: 0.9316 - accuracy: 0.5500 - val_loss: 0.9227 - val_accuracy: 0.5667\n",
      "Epoch 49/300\n",
      "120/120 [==============================] - 0s 216us/sample - loss: 0.9276 - accuracy: 0.5500 - val_loss: 0.9194 - val_accuracy: 0.5667\n",
      "Epoch 50/300\n",
      "120/120 [==============================] - 0s 222us/sample - loss: 0.9235 - accuracy: 0.5333 - val_loss: 0.9161 - val_accuracy: 0.5000\n",
      "Epoch 51/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.9195 - accuracy: 0.5333 - val_loss: 0.9127 - val_accuracy: 0.5000\n",
      "Epoch 52/300\n",
      "120/120 [==============================] - 0s 212us/sample - loss: 0.9155 - accuracy: 0.5333 - val_loss: 0.9095 - val_accuracy: 0.5000\n",
      "Epoch 53/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.9114 - accuracy: 0.5333 - val_loss: 0.9062 - val_accuracy: 0.5000\n",
      "Epoch 54/300\n",
      "120/120 [==============================] - 0s 273us/sample - loss: 0.9075 - accuracy: 0.5333 - val_loss: 0.9030 - val_accuracy: 0.5000\n",
      "Epoch 55/300\n",
      "120/120 [==============================] - 0s 257us/sample - loss: 0.9035 - accuracy: 0.5333 - val_loss: 0.8998 - val_accuracy: 0.5333\n",
      "Epoch 56/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 219us/sample - loss: 0.8997 - accuracy: 0.5500 - val_loss: 0.8967 - val_accuracy: 0.5000\n",
      "Epoch 57/300\n",
      "120/120 [==============================] - 0s 218us/sample - loss: 0.8958 - accuracy: 0.5333 - val_loss: 0.8935 - val_accuracy: 0.5000\n",
      "Epoch 58/300\n",
      "120/120 [==============================] - 0s 226us/sample - loss: 0.8919 - accuracy: 0.5333 - val_loss: 0.8904 - val_accuracy: 0.4667\n",
      "Epoch 59/300\n",
      "120/120 [==============================] - 0s 219us/sample - loss: 0.8880 - accuracy: 0.5333 - val_loss: 0.8872 - val_accuracy: 0.4667\n",
      "Epoch 60/300\n",
      "120/120 [==============================] - 0s 222us/sample - loss: 0.8843 - accuracy: 0.5250 - val_loss: 0.8840 - val_accuracy: 0.4667\n",
      "Epoch 61/300\n",
      "120/120 [==============================] - 0s 286us/sample - loss: 0.8805 - accuracy: 0.5083 - val_loss: 0.8810 - val_accuracy: 0.4667\n",
      "Epoch 62/300\n",
      "120/120 [==============================] - 0s 255us/sample - loss: 0.8768 - accuracy: 0.5083 - val_loss: 0.8779 - val_accuracy: 0.4333\n",
      "Epoch 63/300\n",
      "120/120 [==============================] - 0s 212us/sample - loss: 0.8730 - accuracy: 0.5000 - val_loss: 0.8747 - val_accuracy: 0.4333\n",
      "Epoch 64/300\n",
      "120/120 [==============================] - 0s 207us/sample - loss: 0.8693 - accuracy: 0.4917 - val_loss: 0.8716 - val_accuracy: 0.4333\n",
      "Epoch 65/300\n",
      "120/120 [==============================] - 0s 238us/sample - loss: 0.8657 - accuracy: 0.4917 - val_loss: 0.8686 - val_accuracy: 0.4333\n",
      "Epoch 66/300\n",
      "120/120 [==============================] - 0s 205us/sample - loss: 0.8621 - accuracy: 0.4667 - val_loss: 0.8655 - val_accuracy: 0.4333\n",
      "Epoch 67/300\n",
      "120/120 [==============================] - 0s 224us/sample - loss: 0.8584 - accuracy: 0.4500 - val_loss: 0.8625 - val_accuracy: 0.4333\n",
      "Epoch 68/300\n",
      "120/120 [==============================] - 0s 197us/sample - loss: 0.8548 - accuracy: 0.4417 - val_loss: 0.8594 - val_accuracy: 0.4000\n",
      "Epoch 69/300\n",
      "120/120 [==============================] - 0s 238us/sample - loss: 0.8513 - accuracy: 0.4417 - val_loss: 0.8564 - val_accuracy: 0.4000\n",
      "Epoch 70/300\n",
      "120/120 [==============================] - 0s 203us/sample - loss: 0.8479 - accuracy: 0.4500 - val_loss: 0.8535 - val_accuracy: 0.4000\n",
      "Epoch 71/300\n",
      "120/120 [==============================] - 0s 215us/sample - loss: 0.8443 - accuracy: 0.4417 - val_loss: 0.8505 - val_accuracy: 0.4333\n",
      "Epoch 72/300\n",
      "120/120 [==============================] - 0s 220us/sample - loss: 0.8408 - accuracy: 0.4417 - val_loss: 0.8475 - val_accuracy: 0.4000\n",
      "Epoch 73/300\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.8374 - accuracy: 0.4333 - val_loss: 0.8446 - val_accuracy: 0.4000\n",
      "Epoch 74/300\n",
      "120/120 [==============================] - 0s 232us/sample - loss: 0.8341 - accuracy: 0.4167 - val_loss: 0.8418 - val_accuracy: 0.4667\n",
      "Epoch 75/300\n",
      "120/120 [==============================] - 0s 259us/sample - loss: 0.8307 - accuracy: 0.4167 - val_loss: 0.8389 - val_accuracy: 0.4667\n",
      "Epoch 76/300\n",
      "120/120 [==============================] - 0s 760us/sample - loss: 0.8273 - accuracy: 0.4250 - val_loss: 0.8360 - val_accuracy: 0.4667\n",
      "Epoch 77/300\n",
      "120/120 [==============================] - 0s 549us/sample - loss: 0.8240 - accuracy: 0.4250 - val_loss: 0.8332 - val_accuracy: 0.4667\n",
      "Epoch 78/300\n",
      "120/120 [==============================] - 0s 481us/sample - loss: 0.8208 - accuracy: 0.4333 - val_loss: 0.8304 - val_accuracy: 0.5000\n",
      "Epoch 79/300\n",
      "120/120 [==============================] - 0s 471us/sample - loss: 0.8175 - accuracy: 0.4500 - val_loss: 0.8277 - val_accuracy: 0.5000\n",
      "Epoch 80/300\n",
      "120/120 [==============================] - 0s 414us/sample - loss: 0.8144 - accuracy: 0.4417 - val_loss: 0.8250 - val_accuracy: 0.5000\n",
      "Epoch 81/300\n",
      "120/120 [==============================] - 0s 328us/sample - loss: 0.8112 - accuracy: 0.4417 - val_loss: 0.8222 - val_accuracy: 0.5000\n",
      "Epoch 82/300\n",
      "120/120 [==============================] - 0s 464us/sample - loss: 0.8080 - accuracy: 0.4417 - val_loss: 0.8195 - val_accuracy: 0.5000\n",
      "Epoch 83/300\n",
      "120/120 [==============================] - 0s 365us/sample - loss: 0.8050 - accuracy: 0.4583 - val_loss: 0.8167 - val_accuracy: 0.5000\n",
      "Epoch 84/300\n",
      "120/120 [==============================] - 0s 327us/sample - loss: 0.8019 - accuracy: 0.4667 - val_loss: 0.8139 - val_accuracy: 0.5000\n",
      "Epoch 85/300\n",
      "120/120 [==============================] - 0s 355us/sample - loss: 0.7989 - accuracy: 0.4750 - val_loss: 0.8114 - val_accuracy: 0.5333\n",
      "Epoch 86/300\n",
      "120/120 [==============================] - 0s 326us/sample - loss: 0.7957 - accuracy: 0.4750 - val_loss: 0.8087 - val_accuracy: 0.5333\n",
      "Epoch 87/300\n",
      "120/120 [==============================] - 0s 610us/sample - loss: 0.7927 - accuracy: 0.4833 - val_loss: 0.8060 - val_accuracy: 0.5333\n",
      "Epoch 88/300\n",
      "120/120 [==============================] - 0s 578us/sample - loss: 0.7898 - accuracy: 0.5000 - val_loss: 0.8034 - val_accuracy: 0.5333\n",
      "Epoch 89/300\n",
      "120/120 [==============================] - 0s 377us/sample - loss: 0.7869 - accuracy: 0.5250 - val_loss: 0.8008 - val_accuracy: 0.5667\n",
      "Epoch 90/300\n",
      "120/120 [==============================] - 0s 426us/sample - loss: 0.7840 - accuracy: 0.5417 - val_loss: 0.7981 - val_accuracy: 0.5667\n",
      "Epoch 91/300\n",
      "120/120 [==============================] - 0s 247us/sample - loss: 0.7811 - accuracy: 0.5500 - val_loss: 0.7956 - val_accuracy: 0.5667\n",
      "Epoch 92/300\n",
      "120/120 [==============================] - 0s 234us/sample - loss: 0.7783 - accuracy: 0.5583 - val_loss: 0.7930 - val_accuracy: 0.5667\n",
      "Epoch 93/300\n",
      "120/120 [==============================] - 0s 230us/sample - loss: 0.7754 - accuracy: 0.5583 - val_loss: 0.7905 - val_accuracy: 0.5667\n",
      "Epoch 94/300\n",
      "120/120 [==============================] - 0s 300us/sample - loss: 0.7726 - accuracy: 0.5583 - val_loss: 0.7879 - val_accuracy: 0.5667\n",
      "Epoch 95/300\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.7699 - accuracy: 0.5583 - val_loss: 0.7855 - val_accuracy: 0.5667\n",
      "Epoch 96/300\n",
      "120/120 [==============================] - 0s 311us/sample - loss: 0.7671 - accuracy: 0.5750 - val_loss: 0.7830 - val_accuracy: 0.5667\n",
      "Epoch 97/300\n",
      "120/120 [==============================] - 0s 333us/sample - loss: 0.7644 - accuracy: 0.5833 - val_loss: 0.7806 - val_accuracy: 0.5667\n",
      "Epoch 98/300\n",
      "120/120 [==============================] - 0s 389us/sample - loss: 0.7618 - accuracy: 0.5917 - val_loss: 0.7782 - val_accuracy: 0.5667\n",
      "Epoch 99/300\n",
      "120/120 [==============================] - 0s 349us/sample - loss: 0.7591 - accuracy: 0.5917 - val_loss: 0.7759 - val_accuracy: 0.5667\n",
      "Epoch 100/300\n",
      "120/120 [==============================] - 0s 261us/sample - loss: 0.7565 - accuracy: 0.5917 - val_loss: 0.7737 - val_accuracy: 0.6000\n",
      "Epoch 101/300\n",
      "120/120 [==============================] - 0s 471us/sample - loss: 0.7540 - accuracy: 0.6083 - val_loss: 0.7715 - val_accuracy: 0.6000\n",
      "Epoch 102/300\n",
      "120/120 [==============================] - 0s 604us/sample - loss: 0.7514 - accuracy: 0.6250 - val_loss: 0.7692 - val_accuracy: 0.6000\n",
      "Epoch 103/300\n",
      "120/120 [==============================] - 0s 518us/sample - loss: 0.7488 - accuracy: 0.6250 - val_loss: 0.7669 - val_accuracy: 0.6000\n",
      "Epoch 104/300\n",
      "120/120 [==============================] - 0s 303us/sample - loss: 0.7463 - accuracy: 0.6333 - val_loss: 0.7646 - val_accuracy: 0.6000\n",
      "Epoch 105/300\n",
      "120/120 [==============================] - 0s 304us/sample - loss: 0.7438 - accuracy: 0.6333 - val_loss: 0.7624 - val_accuracy: 0.6000\n",
      "Epoch 106/300\n",
      "120/120 [==============================] - 0s 369us/sample - loss: 0.7414 - accuracy: 0.6333 - val_loss: 0.7601 - val_accuracy: 0.6000\n",
      "Epoch 107/300\n",
      "120/120 [==============================] - 0s 312us/sample - loss: 0.7389 - accuracy: 0.6333 - val_loss: 0.7579 - val_accuracy: 0.6000\n",
      "Epoch 108/300\n",
      "120/120 [==============================] - 0s 290us/sample - loss: 0.7366 - accuracy: 0.6333 - val_loss: 0.7558 - val_accuracy: 0.6000\n",
      "Epoch 109/300\n",
      "120/120 [==============================] - 0s 377us/sample - loss: 0.7342 - accuracy: 0.6333 - val_loss: 0.7536 - val_accuracy: 0.6000\n",
      "Epoch 110/300\n",
      "120/120 [==============================] - 0s 293us/sample - loss: 0.7319 - accuracy: 0.6333 - val_loss: 0.7514 - val_accuracy: 0.6000\n",
      "Epoch 111/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 327us/sample - loss: 0.7296 - accuracy: 0.6417 - val_loss: 0.7493 - val_accuracy: 0.6000\n",
      "Epoch 112/300\n",
      "120/120 [==============================] - 0s 269us/sample - loss: 0.7272 - accuracy: 0.6500 - val_loss: 0.7472 - val_accuracy: 0.6000\n",
      "Epoch 113/300\n",
      "120/120 [==============================] - 0s 295us/sample - loss: 0.7250 - accuracy: 0.6583 - val_loss: 0.7451 - val_accuracy: 0.6000\n",
      "Epoch 114/300\n",
      "120/120 [==============================] - 0s 276us/sample - loss: 0.7227 - accuracy: 0.6583 - val_loss: 0.7431 - val_accuracy: 0.6000\n",
      "Epoch 115/300\n",
      "120/120 [==============================] - 0s 330us/sample - loss: 0.7205 - accuracy: 0.6667 - val_loss: 0.7410 - val_accuracy: 0.6000\n",
      "Epoch 116/300\n",
      "120/120 [==============================] - 0s 366us/sample - loss: 0.7184 - accuracy: 0.6833 - val_loss: 0.7389 - val_accuracy: 0.6000\n",
      "Epoch 117/300\n",
      "120/120 [==============================] - 0s 276us/sample - loss: 0.7162 - accuracy: 0.6833 - val_loss: 0.7370 - val_accuracy: 0.6000\n",
      "Epoch 118/300\n",
      "120/120 [==============================] - 0s 354us/sample - loss: 0.7141 - accuracy: 0.6833 - val_loss: 0.7351 - val_accuracy: 0.6000\n",
      "Epoch 119/300\n",
      "120/120 [==============================] - 0s 411us/sample - loss: 0.7120 - accuracy: 0.6833 - val_loss: 0.7331 - val_accuracy: 0.6000\n",
      "Epoch 120/300\n",
      "120/120 [==============================] - 0s 343us/sample - loss: 0.7099 - accuracy: 0.6833 - val_loss: 0.7312 - val_accuracy: 0.6000\n",
      "Epoch 121/300\n",
      "120/120 [==============================] - 0s 398us/sample - loss: 0.7078 - accuracy: 0.6833 - val_loss: 0.7292 - val_accuracy: 0.6000\n",
      "Epoch 122/300\n",
      "120/120 [==============================] - 0s 299us/sample - loss: 0.7058 - accuracy: 0.6833 - val_loss: 0.7272 - val_accuracy: 0.6000\n",
      "Epoch 123/300\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 0.7038 - accuracy: 0.6833 - val_loss: 0.7253 - val_accuracy: 0.6000\n",
      "Epoch 124/300\n",
      "120/120 [==============================] - 0s 316us/sample - loss: 0.7018 - accuracy: 0.6833 - val_loss: 0.7235 - val_accuracy: 0.6000\n",
      "Epoch 125/300\n",
      "120/120 [==============================] - 0s 307us/sample - loss: 0.6999 - accuracy: 0.6833 - val_loss: 0.7218 - val_accuracy: 0.6000\n",
      "Epoch 126/300\n",
      "120/120 [==============================] - 0s 409us/sample - loss: 0.6978 - accuracy: 0.6833 - val_loss: 0.7201 - val_accuracy: 0.6000\n",
      "Epoch 127/300\n",
      "120/120 [==============================] - 0s 376us/sample - loss: 0.6960 - accuracy: 0.6833 - val_loss: 0.7184 - val_accuracy: 0.6000\n",
      "Epoch 128/300\n",
      "120/120 [==============================] - 0s 265us/sample - loss: 0.6940 - accuracy: 0.6833 - val_loss: 0.7167 - val_accuracy: 0.6000\n",
      "Epoch 129/300\n",
      "120/120 [==============================] - 0s 383us/sample - loss: 0.6922 - accuracy: 0.6833 - val_loss: 0.7149 - val_accuracy: 0.6000\n",
      "Epoch 130/300\n",
      "120/120 [==============================] - 0s 555us/sample - loss: 0.6903 - accuracy: 0.6833 - val_loss: 0.7132 - val_accuracy: 0.6000\n",
      "Epoch 131/300\n",
      "120/120 [==============================] - 0s 342us/sample - loss: 0.6886 - accuracy: 0.6833 - val_loss: 0.7116 - val_accuracy: 0.6000\n",
      "Epoch 132/300\n",
      "120/120 [==============================] - 0s 369us/sample - loss: 0.6867 - accuracy: 0.6833 - val_loss: 0.7099 - val_accuracy: 0.6000\n",
      "Epoch 133/300\n",
      "120/120 [==============================] - 0s 343us/sample - loss: 0.6849 - accuracy: 0.6833 - val_loss: 0.7082 - val_accuracy: 0.6000\n",
      "Epoch 134/300\n",
      "120/120 [==============================] - 0s 359us/sample - loss: 0.6831 - accuracy: 0.6833 - val_loss: 0.7066 - val_accuracy: 0.6000\n",
      "Epoch 135/300\n",
      "120/120 [==============================] - 0s 429us/sample - loss: 0.6814 - accuracy: 0.6833 - val_loss: 0.7051 - val_accuracy: 0.6000\n",
      "Epoch 136/300\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 0.6797 - accuracy: 0.6833 - val_loss: 0.7034 - val_accuracy: 0.6000\n",
      "Epoch 137/300\n",
      "120/120 [==============================] - 0s 393us/sample - loss: 0.6780 - accuracy: 0.6833 - val_loss: 0.7018 - val_accuracy: 0.6000\n",
      "Epoch 138/300\n",
      "120/120 [==============================] - 0s 328us/sample - loss: 0.6763 - accuracy: 0.6833 - val_loss: 0.7002 - val_accuracy: 0.6000\n",
      "Epoch 139/300\n",
      "120/120 [==============================] - 0s 318us/sample - loss: 0.6746 - accuracy: 0.6833 - val_loss: 0.6987 - val_accuracy: 0.6000\n",
      "Epoch 140/300\n",
      "120/120 [==============================] - 0s 313us/sample - loss: 0.6730 - accuracy: 0.6833 - val_loss: 0.6971 - val_accuracy: 0.6000\n",
      "Epoch 141/300\n",
      "120/120 [==============================] - 0s 268us/sample - loss: 0.6713 - accuracy: 0.6833 - val_loss: 0.6955 - val_accuracy: 0.6000\n",
      "Epoch 142/300\n",
      "120/120 [==============================] - 0s 318us/sample - loss: 0.6697 - accuracy: 0.6833 - val_loss: 0.6940 - val_accuracy: 0.6000\n",
      "Epoch 143/300\n",
      "120/120 [==============================] - 0s 356us/sample - loss: 0.6681 - accuracy: 0.6833 - val_loss: 0.6924 - val_accuracy: 0.6000\n",
      "Epoch 144/300\n",
      "120/120 [==============================] - 0s 379us/sample - loss: 0.6666 - accuracy: 0.6833 - val_loss: 0.6910 - val_accuracy: 0.6000\n",
      "Epoch 145/300\n",
      "120/120 [==============================] - 0s 317us/sample - loss: 0.6650 - accuracy: 0.6833 - val_loss: 0.6894 - val_accuracy: 0.6000\n",
      "Epoch 146/300\n",
      "120/120 [==============================] - 0s 289us/sample - loss: 0.6634 - accuracy: 0.6833 - val_loss: 0.6880 - val_accuracy: 0.6000\n",
      "Epoch 147/300\n",
      "120/120 [==============================] - 0s 360us/sample - loss: 0.6619 - accuracy: 0.6833 - val_loss: 0.6866 - val_accuracy: 0.6000\n",
      "Epoch 148/300\n",
      "120/120 [==============================] - 0s 375us/sample - loss: 0.6604 - accuracy: 0.6833 - val_loss: 0.6853 - val_accuracy: 0.6000\n",
      "Epoch 149/300\n",
      "120/120 [==============================] - 0s 387us/sample - loss: 0.6589 - accuracy: 0.6833 - val_loss: 0.6837 - val_accuracy: 0.6000\n",
      "Epoch 150/300\n",
      "120/120 [==============================] - 0s 332us/sample - loss: 0.6574 - accuracy: 0.6833 - val_loss: 0.6823 - val_accuracy: 0.6000\n",
      "Epoch 151/300\n",
      "120/120 [==============================] - 0s 373us/sample - loss: 0.6559 - accuracy: 0.6833 - val_loss: 0.6810 - val_accuracy: 0.6000\n",
      "Epoch 152/300\n",
      "120/120 [==============================] - 0s 338us/sample - loss: 0.6545 - accuracy: 0.6833 - val_loss: 0.6797 - val_accuracy: 0.6000\n",
      "Epoch 153/300\n",
      "120/120 [==============================] - 0s 352us/sample - loss: 0.6530 - accuracy: 0.6833 - val_loss: 0.6783 - val_accuracy: 0.6000\n",
      "Epoch 154/300\n",
      "120/120 [==============================] - 0s 270us/sample - loss: 0.6516 - accuracy: 0.6833 - val_loss: 0.6770 - val_accuracy: 0.6000\n",
      "Epoch 155/300\n",
      "120/120 [==============================] - 0s 363us/sample - loss: 0.6502 - accuracy: 0.6833 - val_loss: 0.6758 - val_accuracy: 0.6000\n",
      "Epoch 156/300\n",
      "120/120 [==============================] - 0s 396us/sample - loss: 0.6489 - accuracy: 0.6833 - val_loss: 0.6744 - val_accuracy: 0.6000\n",
      "Epoch 157/300\n",
      "120/120 [==============================] - 0s 316us/sample - loss: 0.6474 - accuracy: 0.6833 - val_loss: 0.6731 - val_accuracy: 0.6000\n",
      "Epoch 158/300\n",
      "120/120 [==============================] - 0s 396us/sample - loss: 0.6461 - accuracy: 0.6833 - val_loss: 0.6718 - val_accuracy: 0.6000\n",
      "Epoch 159/300\n",
      "120/120 [==============================] - 0s 248us/sample - loss: 0.6448 - accuracy: 0.6833 - val_loss: 0.6705 - val_accuracy: 0.6000\n",
      "Epoch 160/300\n",
      "120/120 [==============================] - 0s 342us/sample - loss: 0.6434 - accuracy: 0.6833 - val_loss: 0.6692 - val_accuracy: 0.6000\n",
      "Epoch 161/300\n",
      "120/120 [==============================] - 0s 308us/sample - loss: 0.6421 - accuracy: 0.6833 - val_loss: 0.6680 - val_accuracy: 0.6000\n",
      "Epoch 162/300\n",
      "120/120 [==============================] - 0s 331us/sample - loss: 0.6408 - accuracy: 0.6833 - val_loss: 0.6668 - val_accuracy: 0.6000\n",
      "Epoch 163/300\n",
      "120/120 [==============================] - 0s 365us/sample - loss: 0.6395 - accuracy: 0.6833 - val_loss: 0.6656 - val_accuracy: 0.6000\n",
      "Epoch 164/300\n",
      "120/120 [==============================] - 0s 287us/sample - loss: 0.6382 - accuracy: 0.6833 - val_loss: 0.6643 - val_accuracy: 0.6000\n",
      "Epoch 165/300\n",
      "120/120 [==============================] - 0s 300us/sample - loss: 0.6369 - accuracy: 0.6833 - val_loss: 0.6631 - val_accuracy: 0.6000\n",
      "Epoch 166/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 441us/sample - loss: 0.6357 - accuracy: 0.6833 - val_loss: 0.6618 - val_accuracy: 0.6000\n",
      "Epoch 167/300\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.6344 - accuracy: 0.6833 - val_loss: 0.6606 - val_accuracy: 0.6000\n",
      "Epoch 168/300\n",
      "120/120 [==============================] - 0s 325us/sample - loss: 0.6332 - accuracy: 0.6833 - val_loss: 0.6594 - val_accuracy: 0.6000\n",
      "Epoch 169/300\n",
      "120/120 [==============================] - 0s 316us/sample - loss: 0.6320 - accuracy: 0.6833 - val_loss: 0.6582 - val_accuracy: 0.6000\n",
      "Epoch 170/300\n",
      "120/120 [==============================] - 0s 259us/sample - loss: 0.6308 - accuracy: 0.6833 - val_loss: 0.6571 - val_accuracy: 0.6000\n",
      "Epoch 171/300\n",
      "120/120 [==============================] - 0s 278us/sample - loss: 0.6296 - accuracy: 0.6833 - val_loss: 0.6560 - val_accuracy: 0.6000\n",
      "Epoch 172/300\n",
      "120/120 [==============================] - 0s 333us/sample - loss: 0.6284 - accuracy: 0.6833 - val_loss: 0.6548 - val_accuracy: 0.6000\n",
      "Epoch 173/300\n",
      "120/120 [==============================] - 0s 448us/sample - loss: 0.6272 - accuracy: 0.6833 - val_loss: 0.6536 - val_accuracy: 0.6000\n",
      "Epoch 174/300\n",
      "120/120 [==============================] - 0s 356us/sample - loss: 0.6260 - accuracy: 0.6833 - val_loss: 0.6525 - val_accuracy: 0.6000\n",
      "Epoch 175/300\n",
      "120/120 [==============================] - 0s 292us/sample - loss: 0.6249 - accuracy: 0.6833 - val_loss: 0.6515 - val_accuracy: 0.6000\n",
      "Epoch 176/300\n",
      "120/120 [==============================] - 0s 314us/sample - loss: 0.6237 - accuracy: 0.6833 - val_loss: 0.6504 - val_accuracy: 0.6000\n",
      "Epoch 177/300\n",
      "120/120 [==============================] - 0s 338us/sample - loss: 0.6226 - accuracy: 0.6833 - val_loss: 0.6493 - val_accuracy: 0.6000\n",
      "Epoch 178/300\n",
      "120/120 [==============================] - 0s 331us/sample - loss: 0.6215 - accuracy: 0.6833 - val_loss: 0.6481 - val_accuracy: 0.6000\n",
      "Epoch 179/300\n",
      "120/120 [==============================] - 0s 462us/sample - loss: 0.6203 - accuracy: 0.6833 - val_loss: 0.6470 - val_accuracy: 0.6000\n",
      "Epoch 180/300\n",
      "120/120 [==============================] - 0s 301us/sample - loss: 0.6192 - accuracy: 0.6833 - val_loss: 0.6459 - val_accuracy: 0.6000\n",
      "Epoch 181/300\n",
      "120/120 [==============================] - 0s 400us/sample - loss: 0.6181 - accuracy: 0.6833 - val_loss: 0.6449 - val_accuracy: 0.6000\n",
      "Epoch 182/300\n",
      "120/120 [==============================] - 0s 262us/sample - loss: 0.6170 - accuracy: 0.6833 - val_loss: 0.6437 - val_accuracy: 0.6000\n",
      "Epoch 183/300\n",
      "120/120 [==============================] - 0s 269us/sample - loss: 0.6159 - accuracy: 0.6833 - val_loss: 0.6426 - val_accuracy: 0.6000\n",
      "Epoch 184/300\n",
      "120/120 [==============================] - 0s 297us/sample - loss: 0.6149 - accuracy: 0.6833 - val_loss: 0.6415 - val_accuracy: 0.6000\n",
      "Epoch 185/300\n",
      "120/120 [==============================] - 0s 465us/sample - loss: 0.6138 - accuracy: 0.6833 - val_loss: 0.6405 - val_accuracy: 0.6000\n",
      "Epoch 186/300\n",
      "120/120 [==============================] - 0s 319us/sample - loss: 0.6128 - accuracy: 0.6833 - val_loss: 0.6392 - val_accuracy: 0.6000\n",
      "Epoch 187/300\n",
      "120/120 [==============================] - 0s 294us/sample - loss: 0.6117 - accuracy: 0.6833 - val_loss: 0.6382 - val_accuracy: 0.6000\n",
      "Epoch 188/300\n",
      "120/120 [==============================] - 0s 263us/sample - loss: 0.6107 - accuracy: 0.6833 - val_loss: 0.6371 - val_accuracy: 0.6000\n",
      "Epoch 189/300\n",
      "120/120 [==============================] - 0s 260us/sample - loss: 0.6096 - accuracy: 0.6833 - val_loss: 0.6361 - val_accuracy: 0.6000\n",
      "Epoch 190/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.6086 - accuracy: 0.6833 - val_loss: 0.6351 - val_accuracy: 0.6000\n",
      "Epoch 191/300\n",
      "120/120 [==============================] - 0s 291us/sample - loss: 0.6076 - accuracy: 0.6833 - val_loss: 0.6340 - val_accuracy: 0.6000\n",
      "Epoch 192/300\n",
      "120/120 [==============================] - 0s 246us/sample - loss: 0.6066 - accuracy: 0.6833 - val_loss: 0.6330 - val_accuracy: 0.6000\n",
      "Epoch 193/300\n",
      "120/120 [==============================] - 0s 263us/sample - loss: 0.6056 - accuracy: 0.6833 - val_loss: 0.6320 - val_accuracy: 0.6000\n",
      "Epoch 194/300\n",
      "120/120 [==============================] - 0s 334us/sample - loss: 0.6046 - accuracy: 0.6833 - val_loss: 0.6310 - val_accuracy: 0.6000\n",
      "Epoch 195/300\n",
      "120/120 [==============================] - 0s 303us/sample - loss: 0.6036 - accuracy: 0.6833 - val_loss: 0.6301 - val_accuracy: 0.6000\n",
      "Epoch 196/300\n",
      "120/120 [==============================] - 0s 379us/sample - loss: 0.6026 - accuracy: 0.6833 - val_loss: 0.6292 - val_accuracy: 0.6000\n",
      "Epoch 197/300\n",
      "120/120 [==============================] - 0s 507us/sample - loss: 0.6016 - accuracy: 0.6833 - val_loss: 0.6283 - val_accuracy: 0.6000\n",
      "Epoch 198/300\n",
      "120/120 [==============================] - 0s 304us/sample - loss: 0.6007 - accuracy: 0.6833 - val_loss: 0.6275 - val_accuracy: 0.6000\n",
      "Epoch 199/300\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 0.5997 - accuracy: 0.6833 - val_loss: 0.6265 - val_accuracy: 0.6000\n",
      "Epoch 200/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.5988 - accuracy: 0.6833 - val_loss: 0.6255 - val_accuracy: 0.6000\n",
      "Epoch 201/300\n",
      "120/120 [==============================] - 0s 279us/sample - loss: 0.5978 - accuracy: 0.6833 - val_loss: 0.6245 - val_accuracy: 0.6000\n",
      "Epoch 202/300\n",
      "120/120 [==============================] - 0s 367us/sample - loss: 0.5969 - accuracy: 0.6833 - val_loss: 0.6236 - val_accuracy: 0.6000\n",
      "Epoch 203/300\n",
      "120/120 [==============================] - 0s 322us/sample - loss: 0.5959 - accuracy: 0.6833 - val_loss: 0.6225 - val_accuracy: 0.6000\n",
      "Epoch 204/300\n",
      "120/120 [==============================] - 0s 497us/sample - loss: 0.5950 - accuracy: 0.6833 - val_loss: 0.6217 - val_accuracy: 0.6000\n",
      "Epoch 205/300\n",
      "120/120 [==============================] - 0s 420us/sample - loss: 0.5941 - accuracy: 0.6833 - val_loss: 0.6208 - val_accuracy: 0.6000\n",
      "Epoch 206/300\n",
      "120/120 [==============================] - 0s 480us/sample - loss: 0.5932 - accuracy: 0.6833 - val_loss: 0.6198 - val_accuracy: 0.6000\n",
      "Epoch 207/300\n",
      "120/120 [==============================] - 0s 380us/sample - loss: 0.5922 - accuracy: 0.6833 - val_loss: 0.6189 - val_accuracy: 0.6000\n",
      "Epoch 208/300\n",
      "120/120 [==============================] - 0s 319us/sample - loss: 0.5913 - accuracy: 0.6833 - val_loss: 0.6180 - val_accuracy: 0.6000\n",
      "Epoch 209/300\n",
      "120/120 [==============================] - 0s 304us/sample - loss: 0.5904 - accuracy: 0.6833 - val_loss: 0.6172 - val_accuracy: 0.6000\n",
      "Epoch 210/300\n",
      "120/120 [==============================] - 0s 344us/sample - loss: 0.5896 - accuracy: 0.6833 - val_loss: 0.6164 - val_accuracy: 0.6000\n",
      "Epoch 211/300\n",
      "120/120 [==============================] - 0s 364us/sample - loss: 0.5887 - accuracy: 0.6833 - val_loss: 0.6155 - val_accuracy: 0.6000\n",
      "Epoch 212/300\n",
      "120/120 [==============================] - 0s 342us/sample - loss: 0.5878 - accuracy: 0.6833 - val_loss: 0.6147 - val_accuracy: 0.6000\n",
      "Epoch 213/300\n",
      "120/120 [==============================] - 0s 297us/sample - loss: 0.5869 - accuracy: 0.6833 - val_loss: 0.6137 - val_accuracy: 0.6000\n",
      "Epoch 214/300\n",
      "120/120 [==============================] - 0s 353us/sample - loss: 0.5860 - accuracy: 0.6833 - val_loss: 0.6129 - val_accuracy: 0.6000\n",
      "Epoch 215/300\n",
      "120/120 [==============================] - 0s 399us/sample - loss: 0.5852 - accuracy: 0.6833 - val_loss: 0.6121 - val_accuracy: 0.6000\n",
      "Epoch 216/300\n",
      "120/120 [==============================] - 0s 386us/sample - loss: 0.5843 - accuracy: 0.6833 - val_loss: 0.6113 - val_accuracy: 0.6000\n",
      "Epoch 217/300\n",
      "120/120 [==============================] - 0s 367us/sample - loss: 0.5834 - accuracy: 0.6833 - val_loss: 0.6104 - val_accuracy: 0.6000\n",
      "Epoch 218/300\n",
      "120/120 [==============================] - 0s 304us/sample - loss: 0.5826 - accuracy: 0.6833 - val_loss: 0.6097 - val_accuracy: 0.6000\n",
      "Epoch 219/300\n",
      "120/120 [==============================] - 0s 235us/sample - loss: 0.5817 - accuracy: 0.6833 - val_loss: 0.6089 - val_accuracy: 0.6000\n",
      "Epoch 220/300\n",
      "120/120 [==============================] - 0s 320us/sample - loss: 0.5809 - accuracy: 0.6833 - val_loss: 0.6081 - val_accuracy: 0.6000\n",
      "Epoch 221/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 347us/sample - loss: 0.5800 - accuracy: 0.6833 - val_loss: 0.6073 - val_accuracy: 0.6000\n",
      "Epoch 222/300\n",
      "120/120 [==============================] - 0s 333us/sample - loss: 0.5792 - accuracy: 0.6833 - val_loss: 0.6064 - val_accuracy: 0.6000\n",
      "Epoch 223/300\n",
      "120/120 [==============================] - 0s 318us/sample - loss: 0.5784 - accuracy: 0.6833 - val_loss: 0.6056 - val_accuracy: 0.6000\n",
      "Epoch 224/300\n",
      "120/120 [==============================] - 0s 437us/sample - loss: 0.5775 - accuracy: 0.6833 - val_loss: 0.6048 - val_accuracy: 0.6000\n",
      "Epoch 225/300\n",
      "120/120 [==============================] - 0s 305us/sample - loss: 0.5767 - accuracy: 0.6833 - val_loss: 0.6040 - val_accuracy: 0.6000\n",
      "Epoch 226/300\n",
      "120/120 [==============================] - 0s 332us/sample - loss: 0.5759 - accuracy: 0.6833 - val_loss: 0.6032 - val_accuracy: 0.6000\n",
      "Epoch 227/300\n",
      "120/120 [==============================] - 0s 302us/sample - loss: 0.5750 - accuracy: 0.6833 - val_loss: 0.6025 - val_accuracy: 0.6000\n",
      "Epoch 228/300\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.5742 - accuracy: 0.6833 - val_loss: 0.6017 - val_accuracy: 0.6000\n",
      "Epoch 229/300\n",
      "120/120 [==============================] - 0s 248us/sample - loss: 0.5734 - accuracy: 0.6833 - val_loss: 0.6009 - val_accuracy: 0.6000\n",
      "Epoch 230/300\n",
      "120/120 [==============================] - 0s 294us/sample - loss: 0.5726 - accuracy: 0.6833 - val_loss: 0.6002 - val_accuracy: 0.6000\n",
      "Epoch 231/300\n",
      "120/120 [==============================] - 0s 290us/sample - loss: 0.5718 - accuracy: 0.6833 - val_loss: 0.5996 - val_accuracy: 0.6000\n",
      "Epoch 232/300\n",
      "120/120 [==============================] - 0s 285us/sample - loss: 0.5709 - accuracy: 0.6833 - val_loss: 0.5988 - val_accuracy: 0.6000\n",
      "Epoch 233/300\n",
      "120/120 [==============================] - 0s 411us/sample - loss: 0.5701 - accuracy: 0.6833 - val_loss: 0.5981 - val_accuracy: 0.6000\n",
      "Epoch 234/300\n",
      "120/120 [==============================] - 0s 259us/sample - loss: 0.5693 - accuracy: 0.6833 - val_loss: 0.5974 - val_accuracy: 0.6000\n",
      "Epoch 235/300\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.5685 - accuracy: 0.6833 - val_loss: 0.5967 - val_accuracy: 0.6000\n",
      "Epoch 236/300\n",
      "120/120 [==============================] - 0s 291us/sample - loss: 0.5678 - accuracy: 0.6833 - val_loss: 0.5961 - val_accuracy: 0.6000\n",
      "Epoch 237/300\n",
      "120/120 [==============================] - 0s 407us/sample - loss: 0.5669 - accuracy: 0.6833 - val_loss: 0.5954 - val_accuracy: 0.6000\n",
      "Epoch 238/300\n",
      "120/120 [==============================] - 0s 291us/sample - loss: 0.5662 - accuracy: 0.6833 - val_loss: 0.5947 - val_accuracy: 0.6000\n",
      "Epoch 239/300\n",
      "120/120 [==============================] - 0s 327us/sample - loss: 0.5653 - accuracy: 0.6833 - val_loss: 0.5940 - val_accuracy: 0.6000\n",
      "Epoch 240/300\n",
      "120/120 [==============================] - 0s 262us/sample - loss: 0.5646 - accuracy: 0.6833 - val_loss: 0.5934 - val_accuracy: 0.6000\n",
      "Epoch 241/300\n",
      "120/120 [==============================] - 0s 272us/sample - loss: 0.5638 - accuracy: 0.6833 - val_loss: 0.5926 - val_accuracy: 0.6000\n",
      "Epoch 242/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.5630 - accuracy: 0.6833 - val_loss: 0.5919 - val_accuracy: 0.6000\n",
      "Epoch 243/300\n",
      "120/120 [==============================] - 0s 239us/sample - loss: 0.5622 - accuracy: 0.6833 - val_loss: 0.5912 - val_accuracy: 0.6000\n",
      "Epoch 244/300\n",
      "120/120 [==============================] - 0s 309us/sample - loss: 0.5614 - accuracy: 0.6833 - val_loss: 0.5905 - val_accuracy: 0.6000\n",
      "Epoch 245/300\n",
      "120/120 [==============================] - 0s 378us/sample - loss: 0.5607 - accuracy: 0.6833 - val_loss: 0.5899 - val_accuracy: 0.6000\n",
      "Epoch 246/300\n",
      "120/120 [==============================] - 0s 355us/sample - loss: 0.5599 - accuracy: 0.6833 - val_loss: 0.5891 - val_accuracy: 0.6000\n",
      "Epoch 247/300\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.5591 - accuracy: 0.6833 - val_loss: 0.5884 - val_accuracy: 0.6000\n",
      "Epoch 248/300\n",
      "120/120 [==============================] - 0s 264us/sample - loss: 0.5583 - accuracy: 0.6833 - val_loss: 0.5877 - val_accuracy: 0.6000\n",
      "Epoch 249/300\n",
      "120/120 [==============================] - 0s 271us/sample - loss: 0.5576 - accuracy: 0.6833 - val_loss: 0.5871 - val_accuracy: 0.6000\n",
      "Epoch 250/300\n",
      "120/120 [==============================] - 0s 232us/sample - loss: 0.5568 - accuracy: 0.6833 - val_loss: 0.5865 - val_accuracy: 0.6000\n",
      "Epoch 251/300\n",
      "120/120 [==============================] - 0s 295us/sample - loss: 0.5560 - accuracy: 0.6833 - val_loss: 0.5859 - val_accuracy: 0.6000\n",
      "Epoch 252/300\n",
      "120/120 [==============================] - 0s 271us/sample - loss: 0.5553 - accuracy: 0.6833 - val_loss: 0.5853 - val_accuracy: 0.6000\n",
      "Epoch 253/300\n",
      "120/120 [==============================] - 0s 362us/sample - loss: 0.5545 - accuracy: 0.6833 - val_loss: 0.5846 - val_accuracy: 0.6000\n",
      "Epoch 254/300\n",
      "120/120 [==============================] - 0s 279us/sample - loss: 0.5538 - accuracy: 0.6833 - val_loss: 0.5840 - val_accuracy: 0.6000\n",
      "Epoch 255/300\n",
      "120/120 [==============================] - 0s 349us/sample - loss: 0.5530 - accuracy: 0.6833 - val_loss: 0.5833 - val_accuracy: 0.6000\n",
      "Epoch 256/300\n",
      "120/120 [==============================] - 0s 289us/sample - loss: 0.5522 - accuracy: 0.6833 - val_loss: 0.5827 - val_accuracy: 0.6000\n",
      "Epoch 257/300\n",
      "120/120 [==============================] - 0s 321us/sample - loss: 0.5515 - accuracy: 0.6833 - val_loss: 0.5821 - val_accuracy: 0.6000\n",
      "Epoch 258/300\n",
      "120/120 [==============================] - 0s 375us/sample - loss: 0.5507 - accuracy: 0.6833 - val_loss: 0.5815 - val_accuracy: 0.6000\n",
      "Epoch 259/300\n",
      "120/120 [==============================] - 0s 474us/sample - loss: 0.5500 - accuracy: 0.6833 - val_loss: 0.5809 - val_accuracy: 0.6000\n",
      "Epoch 260/300\n",
      "120/120 [==============================] - 0s 332us/sample - loss: 0.5492 - accuracy: 0.6833 - val_loss: 0.5802 - val_accuracy: 0.6000\n",
      "Epoch 261/300\n",
      "120/120 [==============================] - 0s 324us/sample - loss: 0.5484 - accuracy: 0.6833 - val_loss: 0.5796 - val_accuracy: 0.6000\n",
      "Epoch 262/300\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 0.5477 - accuracy: 0.6833 - val_loss: 0.5791 - val_accuracy: 0.6000\n",
      "Epoch 263/300\n",
      "120/120 [==============================] - 0s 322us/sample - loss: 0.5469 - accuracy: 0.6833 - val_loss: 0.5785 - val_accuracy: 0.6000\n",
      "Epoch 264/300\n",
      "120/120 [==============================] - 0s 347us/sample - loss: 0.5462 - accuracy: 0.6833 - val_loss: 0.5779 - val_accuracy: 0.6000\n",
      "Epoch 265/300\n",
      "120/120 [==============================] - 0s 331us/sample - loss: 0.5454 - accuracy: 0.6833 - val_loss: 0.5774 - val_accuracy: 0.6000\n",
      "Epoch 266/300\n",
      "120/120 [==============================] - 0s 415us/sample - loss: 0.5448 - accuracy: 0.6833 - val_loss: 0.5769 - val_accuracy: 0.6000\n",
      "Epoch 267/300\n",
      "120/120 [==============================] - 0s 336us/sample - loss: 0.5440 - accuracy: 0.6833 - val_loss: 0.5763 - val_accuracy: 0.6000\n",
      "Epoch 268/300\n",
      "120/120 [==============================] - 0s 343us/sample - loss: 0.5432 - accuracy: 0.6833 - val_loss: 0.5757 - val_accuracy: 0.6000\n",
      "Epoch 269/300\n",
      "120/120 [==============================] - 0s 325us/sample - loss: 0.5425 - accuracy: 0.6833 - val_loss: 0.5751 - val_accuracy: 0.6000\n",
      "Epoch 270/300\n",
      "120/120 [==============================] - 0s 370us/sample - loss: 0.5417 - accuracy: 0.6833 - val_loss: 0.5745 - val_accuracy: 0.6000\n",
      "Epoch 271/300\n",
      "120/120 [==============================] - 0s 362us/sample - loss: 0.5410 - accuracy: 0.6833 - val_loss: 0.5739 - val_accuracy: 0.6000\n",
      "Epoch 272/300\n",
      "120/120 [==============================] - 0s 287us/sample - loss: 0.5403 - accuracy: 0.6833 - val_loss: 0.5733 - val_accuracy: 0.6000\n",
      "Epoch 273/300\n",
      "120/120 [==============================] - 0s 350us/sample - loss: 0.5396 - accuracy: 0.6833 - val_loss: 0.5728 - val_accuracy: 0.6000\n",
      "Epoch 274/300\n",
      "120/120 [==============================] - 0s 346us/sample - loss: 0.5388 - accuracy: 0.6833 - val_loss: 0.5720 - val_accuracy: 0.6000\n",
      "Epoch 275/300\n",
      "120/120 [==============================] - 0s 288us/sample - loss: 0.5381 - accuracy: 0.6833 - val_loss: 0.5714 - val_accuracy: 0.6000\n",
      "Epoch 276/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 363us/sample - loss: 0.5373 - accuracy: 0.6833 - val_loss: 0.5708 - val_accuracy: 0.6000\n",
      "Epoch 277/300\n",
      "120/120 [==============================] - 0s 379us/sample - loss: 0.5366 - accuracy: 0.6833 - val_loss: 0.5701 - val_accuracy: 0.6000\n",
      "Epoch 278/300\n",
      "120/120 [==============================] - 0s 381us/sample - loss: 0.5359 - accuracy: 0.6833 - val_loss: 0.5695 - val_accuracy: 0.6000\n",
      "Epoch 279/300\n",
      "120/120 [==============================] - 0s 409us/sample - loss: 0.5352 - accuracy: 0.6833 - val_loss: 0.5689 - val_accuracy: 0.6000\n",
      "Epoch 280/300\n",
      "120/120 [==============================] - 0s 297us/sample - loss: 0.5344 - accuracy: 0.6833 - val_loss: 0.5684 - val_accuracy: 0.6000\n",
      "Epoch 281/300\n",
      "120/120 [==============================] - 0s 297us/sample - loss: 0.5337 - accuracy: 0.6833 - val_loss: 0.5677 - val_accuracy: 0.6000\n",
      "Epoch 282/300\n",
      "120/120 [==============================] - 0s 308us/sample - loss: 0.5330 - accuracy: 0.6833 - val_loss: 0.5672 - val_accuracy: 0.6000\n",
      "Epoch 283/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.5322 - accuracy: 0.6833 - val_loss: 0.5666 - val_accuracy: 0.6000\n",
      "Epoch 284/300\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 0.5315 - accuracy: 0.6833 - val_loss: 0.5661 - val_accuracy: 0.6000\n",
      "Epoch 285/300\n",
      "120/120 [==============================] - 0s 227us/sample - loss: 0.5308 - accuracy: 0.6833 - val_loss: 0.5655 - val_accuracy: 0.6000\n",
      "Epoch 286/300\n",
      "120/120 [==============================] - 0s 232us/sample - loss: 0.5301 - accuracy: 0.6833 - val_loss: 0.5649 - val_accuracy: 0.6000\n",
      "Epoch 287/300\n",
      "120/120 [==============================] - 0s 277us/sample - loss: 0.5293 - accuracy: 0.6833 - val_loss: 0.5644 - val_accuracy: 0.6000\n",
      "Epoch 288/300\n",
      "120/120 [==============================] - 0s 315us/sample - loss: 0.5286 - accuracy: 0.6833 - val_loss: 0.5639 - val_accuracy: 0.6000\n",
      "Epoch 289/300\n",
      "120/120 [==============================] - 0s 298us/sample - loss: 0.5279 - accuracy: 0.6833 - val_loss: 0.5633 - val_accuracy: 0.6000\n",
      "Epoch 290/300\n",
      "120/120 [==============================] - 0s 364us/sample - loss: 0.5272 - accuracy: 0.6833 - val_loss: 0.5628 - val_accuracy: 0.6000\n",
      "Epoch 291/300\n",
      "120/120 [==============================] - 0s 397us/sample - loss: 0.5265 - accuracy: 0.6833 - val_loss: 0.5623 - val_accuracy: 0.6000\n",
      "Epoch 292/300\n",
      "120/120 [==============================] - 0s 353us/sample - loss: 0.5257 - accuracy: 0.6833 - val_loss: 0.5618 - val_accuracy: 0.6000\n",
      "Epoch 293/300\n",
      "120/120 [==============================] - 0s 296us/sample - loss: 0.5250 - accuracy: 0.6833 - val_loss: 0.5612 - val_accuracy: 0.6000\n",
      "Epoch 294/300\n",
      "120/120 [==============================] - 0s 246us/sample - loss: 0.5243 - accuracy: 0.6833 - val_loss: 0.5606 - val_accuracy: 0.6000\n",
      "Epoch 295/300\n",
      "120/120 [==============================] - 0s 334us/sample - loss: 0.5236 - accuracy: 0.6833 - val_loss: 0.5601 - val_accuracy: 0.6000\n",
      "Epoch 296/300\n",
      "120/120 [==============================] - 0s 279us/sample - loss: 0.5229 - accuracy: 0.6833 - val_loss: 0.5595 - val_accuracy: 0.6000\n",
      "Epoch 297/300\n",
      "120/120 [==============================] - 0s 381us/sample - loss: 0.5222 - accuracy: 0.6833 - val_loss: 0.5591 - val_accuracy: 0.6000\n",
      "Epoch 298/300\n",
      "120/120 [==============================] - 0s 459us/sample - loss: 0.5214 - accuracy: 0.6833 - val_loss: 0.5586 - val_accuracy: 0.6000\n",
      "Epoch 299/300\n",
      "120/120 [==============================] - 0s 246us/sample - loss: 0.5207 - accuracy: 0.6833 - val_loss: 0.5580 - val_accuracy: 0.6000\n",
      "Epoch 300/300\n",
      "120/120 [==============================] - 0s 317us/sample - loss: 0.5200 - accuracy: 0.6833 - val_loss: 0.5574 - val_accuracy: 0.6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1361e1650>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_X_train,y=y_train,epochs=300,\n",
    "         validation_data=(scaled_X_test,y_test),callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.216938</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>1.123787</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.207302</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.117243</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.198503</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.110673</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.189757</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.104187</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.181321</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.097850</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.522856</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.559537</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.522246</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.559131</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.521434</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.558571</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.520746</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.558011</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.520006</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.557414</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy  val_loss  val_accuracy\n",
       "0    1.216938  0.325000  1.123787      0.333333\n",
       "1    1.207302  0.333333  1.117243      0.333333\n",
       "2    1.198503  0.333333  1.110673      0.333333\n",
       "3    1.189757  0.333333  1.104187      0.333333\n",
       "4    1.181321  0.333333  1.097850      0.333333\n",
       "..        ...       ...       ...           ...\n",
       "295  0.522856  0.683333  0.559537      0.600000\n",
       "296  0.522246  0.683333  0.559131      0.600000\n",
       "297  0.521434  0.683333  0.558571      0.600000\n",
       "298  0.520746  0.683333  0.558011      0.600000\n",
       "299  0.520006  0.683333  0.557414      0.600000\n",
       "\n",
       "[300 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1376ffc10>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd3xUVf7/8ddJJ6SHhHSSUEILoYQiCoqNoogNESyoICq2Vdevurq7rKs/3bWurmUtiCIg2LGBCigqNUBICIFQAiGNFEihpM75/XEnECBlQiaZyfB5Ph55TLkncz93x31zcu655yqtNUIIITo+J1sXIIQQwjok0IUQwkFIoAshhIOQQBdCCAchgS6EEA7CxVY77tKli46OjrbV7oUQokPatGlTkdY6qKFtNgv06OhokpKSbLV7IYTokJRS+xvbJkMuQgjhICTQhRDCQUigCyGEg7DZGLoQ4txUXV1NdnY2FRUVti7Frnl4eBAREYGrq6vFvyOBLoRoV9nZ2Xh7exMdHY1Sytbl2CWtNcXFxWRnZxMTE2Px78mQixCiXVVUVBAYGChh3gSlFIGBgS3+K0YCXQjR7iTMm3c2/xvZLNALyitttWshhHBINgv0g2UV7C8+aqvdCyHOYV5eXrYuoU3YLNAV8NHaRi94EkII0ULNBrpSaq5SqkApta2R7TcppVKUUqlKqTVKqQRLduzTyZUlSQc4WlnT0pqFEMIqtNY8+uij9O/fn/j4eBYvXgxAXl4eo0ePZuDAgfTv35/ffvuN2tpabrvtthNtX3nlFRtXfyZLpi3OA/4LfNTI9kzgQq31YaXUeOAdYHhzH9rFy53yihq+2JLDLSO6WVqvEMKB/OObNLbnlln1M/uG+fD3if0savvFF1+QnJzM1q1bKSoqYujQoYwePZqFCxcyduxYnnzySWprazl27BjJycnk5OSwbZvRty0pKbFq3dbQbA9da70aONTE9jVa68Pml+uACEt27OnmTHy4Lx+u2Yfc11QIYQu///47U6dOxdnZma5du3LhhReyceNGhg4dygcffMCcOXNITU3F29ub2NhY9u7dy/3338+yZcvw8fGxdflnsPaFRTOAHxrbqJSaBcwCiIqK4omR0Tzy6VZW7yriwl4NrgYphHBglvak29vo0aNZvXo13333HbfddhsPP/wwt956K1u3bmX58uW8/fbbLFmyhLlz59q61FNY7aSoUmoMRqA/1lgbrfU7WutErXViUFAQExPC6Orjzjur91irDCGEsNioUaNYvHgxtbW1FBYWsnr1aoYNG8b+/fvp2rUrd955JzNnzmTz5s0UFRVhMpm47rrreOaZZ9i8ebOtyz+DVXroSqkBwHvAeK11saW/5+bixO3nx/D8DzvYllNK/3Bfa5QjhBAWueaaa1i7di0JCQkopfj3v/9NSEgIH374IS+88AKurq54eXnx0UcfkZOTw+23347JZALgueees3H1Z1KWjF8rpaKBb7XW/RvYFgWsBG7VWq+xdMeJiYk6KSmJsopqRj63kjG9g3l96iDLKxdCdEjp6en06dPH1mV0CA39b6WU2qS1TmyovSXTFhcBa4E4pVS2UmqGUupupdTd5iZ/AwKBN5VSyUqpFt2GyMfDlWnDo/g+NY8Dh4615FeFEELU0+yQi9Z6ajPbZwIzW1PE7edH88Efmbz/eyZzrrLPkyRCCGHv7GJxrlDfTlyVEM7ijQc4fLTK1uUIIUSHZBeBDjBrdCzHq2v5eJ0sByCEEGfDbgI9LsSbMXFBzFuzj4rqWluXI4QQHY7dBDrArNHdKT5axeebs21dihBCdDh2FegjYgNIiPDlvd8yqTXJcgBCCNESdhXoSilmje5OZtFRftqeb+tyhBCiybXT9+3bR//+Z1yeYzN2FegA4/qHEBXgyVu/7JFFu4QQogWsvThXqzk7Ke4d053HPk9lRXoBl/btauuShBBt5YfHIT/Vup8ZEg/jn2908+OPP05kZCT33nsvAHPmzMHFxYVVq1Zx+PBhqqureeaZZ5g0aVKLdltRUcE999xDUlISLi4uvPzyy4wZM4a0tDRuv/12qqqqMJlMfP7554SFhXHDDTeQnZ1NbW0tf/3rX5kyZUqrDhvssIcOcO3gCKIDPXnppwxMMpYuhLCiKVOmsGTJkhOvlyxZwvTp0/nyyy/ZvHkzq1at4pFHHmnxCMEbb7yBUorU1FQWLVrE9OnTqaio4O233+bBBx8kOTmZpKQkIiIiWLZsGWFhYWzdupVt27Yxbtw4qxyb3fXQAVydnfjTpb340+JkftiWzxUDQm1dkhCiLTTRk24rgwYNoqCggNzcXAoLC/H39yckJISHHnqI1atX4+TkRE5ODgcPHiQkJMTiz/3999+5//77AejduzfdunUjIyOD8847j2effZbs7GyuvfZaevbsSXx8PI888giPPfYYV155JaNGjbLKsdllDx1gYkIYPYO9ePmnnTLjRQhhVZMnT+azzz5j8eLFTJkyhQULFlBYWMimTZtITk6ma9euVFRUWGVf06ZNY+nSpXTq1IkJEyawcuVKevXqxebNm4mPj+epp57i6aeftsq+7DbQnZ0UD1/Wiz2FR/k6OcfW5QghHMiUKVP45JNP+Oyzz5g8eTKlpaUEBwfj6urKqlWr2L+/5Vesjxo1igULFgCQkZFBVlYWcXFx7N27l9jYWB544AEmTZpESkoKubm5eHp6cvPNN/Poo49abW11uxxyqTO2Xwj9wnz4z4pdTEwIw9XZbv/9EUJ0IP369aO8vJzw8HBCQ0O56aabmDhxIvHx8SQmJtK7d+8Wf+bs2bO55557iI+Px8XFhXnz5uHu7s6SJUuYP38+rq6uhISE8Je//IWNGzfy6KOP4uTkhKurK2+99ZZVjsui9dDbQt166M1ZueMgd8xL4vlr47lxWFQ7VCaEaEuyHrrlrL4eepupqbSo2Zi4YAZF+fHail1U1sgaL0II0RjbBXpRBhw/3GwzpRR/vjyO3NIKPtlwoB0KE0KIU6WmpjJw4MBTfoYPH27rss5guzF0Uy2seBqufKXZpiO7BzI8JoD/rtrNDYmRdHJzbocChRBtRWuNUsrWZVgsPj6e5OTkdt3n2QyH266H7hUESR9AdvPj6Eop/jw2jsLySub+kdkOxQkh2oqHhwfFxcWytEcTtNYUFxfj4eHRot+zXQ/dOxS8j8G3f4I7fwHnpksZGh3AuH4h/Hflbq4dHE6ob6f2qVMIYVURERFkZ2dTWFho61LsmoeHBxERES36nWYDXSk1F7gSKNBan7GsmFKqN/ABMBh4Umv9okV7Vk4w7nn4dDpsfBdG3NPsrzx5RR9W7izg+R928J8bB1m0GyGEfXF1dSUmJsbWZTgkS4Zc5gFNLTRwCHgAsCzI6+s7CXpcCiufhbK8ZptHBnhy9+hYvk7OZeO+Qy3enRBCOLJmA11rvRojtBvbXqC13ghUt3jvSsGEF8BUDcufsOhX7rmoB2G+HsxZmiZLAgghRD3telJUKTVLKZWklEo6MX4WEAujHoG0L2H3imY/o5ObM09M6ENabhmLN8o0RiGEqNOuga61fkdrnai1TgwKCjq54fwHIbAHfPcIVB9v9nOuHBDKsJgAXli+g9JjLf/DQAghHJF9LI7i4g5XvASHM2H1C802V0oxZ2I/So9X88rPGe1QoBBC2D/7CHSA2Itg4M3w+yuQtb7Z5n3DfLhpeDfmr9vPzvzyNi9PCCHsXbOBrpRaBKwF4pRS2UqpGUqpu5VSd5u3hyilsoGHgafMbXzOqppxz4FvJHw5CyqbD+mHL+uFl7sLc5amyUUKQohzniWzXKZqrUO11q5a6wit9fta67e11m+bt+eb3/fRWvuZn5edVTUePnDtO1CSBcseb7a5f2c3Hh0bx9q9xXy+WdZMF0Kc2+xnyKVO1Ai44GHY8jFsX9ps82nDokjs5s8/v91OYbllKzgKIYQjsr9AB7jocQgdCN88YPTWm+DkpHj+ugEcr6plzjdp7VSgEELYH/sMdGdXuH6usSLjkunNrp3eI9iLBy7pwXcpefyYlt9ORQohhH2xz0AHCOwOV78JuZth+V+abX7Xhd3pHeLNX7/eRlmFzE0XQpx77DfQAfpMhJH3w8b3YPP8Jpu6Ojvx7+sHUFheyT+Wbm+nAoUQwn7Yd6ADXDIHYsfAtw/B/rVNNh0Q4cd9Y3rw+eZsfkhtfrEvIYRwJPYf6M4uMPkD8IuCxTfD4f1NNr//kp7Eh/vyly9TKSiraKcihRDC9uw/0AE6+cO0xVBbDYumQuWRRpu6OjvxypSBHKuq5f8+T5ELjoQQ54yOEegAXXoaPfXCdPhiFphMjTbtEezFXyb04ZedhSxY3/S0RyGEcBQdJ9ABelwCY5+Dnd/Bin802fSWEd0Y1bMLz36Xzt7Cxnv0QgjhKDpWoAMMvwsS74A/XoX1/2u0mZOT4oXrE3BzceKhJVupqW28Ry+EEI6g4wW6UjD+BYi7An54zLgxRiNCfD149pr+bD1Qwn9X7W7HIoUQov11vEAHY+bL9e9D5DBjPD3zt0abXjkgjKsHhvH6yt1s2i/3IRVCOK6OGegArp1g6ifgHwOfTIPcLY02ffrq/oT7deKBRcmUHKtqxyKFEKL9dNxAB/AMgFu+AA8/mH8NHGz4ClEfD1denzqIg2UVPCZTGYUQDqpjBzqAbwRM/xpcPOCjSVC8p8FmCZF+PDauN8vTDvLxuqYvThJCiI6o4wc6QEAs3Po1aBN8eFWjS+7OuCCGi+KC+Od36WzLKW3nIoUQom05RqADBMXBLV9CVbkR6mVnruXi5KR4aXICAZ5uzF6wmdLjsiqjEMJxOE6gA4QOgJu/gKOFxvDL0aIzmgR6ufPGTYPJLTnOI0uSMZlkPF0I4RgcK9ABIhKNdV9KsuDDiXCk8IwmQ7r58+QVffg5vYC3Vzc85i6EEB1Ns4GulJqrlCpQSm1rZLtSSr2mlNqtlEpRSg22fpktFH2BEeqH98G8K6D8zLsY3TYymisHhPLi8p2s2X1mT14IIToaS3ro84BxTWwfD/Q0/8wC3mp9WVYQeyHc9BmUZsMHE6A055TNSin+dd0AYoO8uH/RFvJLZaldIUTH1myga61XA01dYjkJ+Egb1gF+SqlQaxXYKtHnGydKjxTAvAlnzH7p7O7C2zcP5nh1Lfcs2ERlTa2NChVCiNazxhh6OHCg3uts83tnUErNUkolKaWSCgvPHNtuE1HDjSmNxw8bPfVDmads7hHszQvXJ7Alq4S/f50mFx0JITqsdj0pqrV+R2udqLVODAoKar8dRwyBW5dC1REj1AszTtl8xYBQ7h3TnU82HuBjWT9dCNFBWSPQc4DIeq8jzO/Zl7CBMP1bMNXA3LGQs+mUzQ9fFseYuCD+sTSN9XuLbVSkEEKcPWsE+lLgVvNslxFAqdbaPu/QHNIf7lgG7t4wbyLsWXVik7OT4tUbBxEV4MnsBZvJLTluw0KFEKLlLJm2uAhYC8QppbKVUjOUUncrpe42N/ke2AvsBt4FZrdZtdYQ2B1m/Aj+0bDwBkj76sQm306uvHPrECprTMyan0RFtZwkFUJ0HMpWJwETExN1UlKSTfYNGCdJF06BAxvgylcg8fYTm37efpA75ycxoX8or08dhJOTsl2dQghRj1Jqk9Y6saFtjnelqKU6+cMtX0GPS+HbP8HqF8H8j9ulfbvyxPjefJeax8s/ZTTzQUIIYR/O3UAHcPOEqYsg/gZY+U9Y/iSYjHuP3jkqlhuHRvLfVbv5bFO2jQsVQojmudi6AJtzdoVr/mf02Ne9AceK4arXUS5u/PPq/mQdOsYTX6QQ4d+JEbGBtq5WCCEadW730Os4OcH4f8GYJyHlE1g4GSpKcXV24q2bhhAV4MndH28is+iorSsVQohGSaDXUQou/D+Y9Abs+x3mjofSHHw9XZl721CclOL2DzZQfKTS1pUKIUSDJNBPN+hmY1Gvkix47xLIS6FbYGfevTWRvNIK7vgwiWNVNbauUgghziCB3pDuY2DGclBO8MF42P0zQ7r58/rUQaRml3Dfwi1U15psXaUQQpxCAr0xXfvBzJ/BPwYW3ACbP+LyfiE8Pak/K3cU8NhnKXK3IyGEXZFZLk3xCYPbv4dPb4Ol98Phfdw85ikOHa3i5Z8y8O/sxlNX9EEpufBICGF7EujN8fAx7n703SPw20tQlMH9V7/NoaNVvP97JgGd3bh3TA9bVymEEBLoFnF2hYn/gaDe8OOTqA/G8bcpiyg5FsYLy3fi7+nGtOFRtq5SCHGOkzF0SykF582GaUvg8H6c3ruYF8+rYkxcEE9+lcr3qfa5wKQQ4twhgd5SPS+DGT+BmycuH03kfwl7GRLlz4OfbOG3Xe10FyYhhGiABPrZCO4Nd66CyGG4Lb2Lj2OW06OLJ3d+lMSa3UW2rk4IcY6SQD9bngFw8xcweDoe617l66C3ifN34o4PN7JO7ngkhLABCfTWcHEzTpaO+xdue5bzufs/GOx7lNs/2MiGzEO2rk4IcY6RQG8tpWDE3XDTp7iUZfOx6TEu9d7HbR9sYOM+CXUhRPuRQLeWHpfCzJ9x8vDhtcq/ckuntdw2dwOb9kuoCyHahwS6NQX1gpkrUFEjeKLyVZ50X8ztc9ezOeuwrSsTQpwDLAp0pdQ4pdROpdRupdTjDWzvppRaoZRKUUr9opSKsH6pHUTdydLEO5hW/QVvurzMPe//SvKBEltXJoRwcM0GulLKGXgDGA/0BaYqpfqe1uxF4COt9QDgaeA5axfaoTi7whUvw/gXON+0iYVOf+P/3v+WlGwJdSFE27Gkhz4M2K213qu1rgI+ASad1qYvsNL8fFUD2889SsHwWaibPyPG9TCLeYIX3/uQbTmltq5MCOGgLAn0cOBAvdfZ5vfq2wpca35+DeCtlDrjBpxKqVlKqSSlVFJh4TlyVWX3i3GatRIvvy68z9N88u7zMvwihGgT1jop+mfgQqXUFuBCIAeoPb2R1vodrXWi1joxKCjISrvuALr0xPWuldRGnsczvMmW9+5jU+Y58g+aEKLdWBLoOUBkvdcR5vdO0Frnaq2v1VoPAp40vyfd0Po6+eNx25ccTbid29U3HJk3maQdmbauSgjhQCwJ9I1AT6VUjFLKDbgRWFq/gVKqi1Kq7rOeAOZat0wH4exK52tepfySf3G+SqHLonFsSfrD1lUJIRxEs4Guta4B7gOWA+nAEq11mlLqaaXUVeZmFwE7lVIZQFfg2Taq1yF4j7qbI1O/wsepkl7fXEPaT/NsXZIQwgEorW1zX8zExESdlJRkk33bi5KDWeS+ewN9a9LZ22sGsVP+Dc5yzxEhROOUUpu01okNbZMrRW3Ir2sU4Q+uYFmnK4jNeJ/8NyfAUVl+VwhxdiTQbczXuzOjH/qI9wIfwb9oM0deGwkHNti6LCFEBySBbgc83VyYPvspXot5g0PHTdTOHYde+ybYaDhMCNExSaDbCVdnJx659QYWJMxnRc1A1PInMC2ZDhVlti5NCNFBSKDbEScnxePXjmD76Lf4f9VT0enfYHrnIsjfZuvShBAdgAS6nVFK8afL4gi/4nFurHyK0pLD6PcugS0LbF2aEMLOSaDbqekjo7l5yo2Mq3iWFHrB17Ph6/ug+ritSxNC2CmZ9GzHJg0Mx8fjUqYu8OUvHl9y85b5kJsMN3wIgd1tXZ4Qws5ID93OjekdzEczzuPF2ht4wOkv1JQcgHcugrSvbF2aEMLOSKB3AInRAXxxz0hSOg3j0qP/5LBnNHw6Hb55EKqO2bo8IYSdkEDvIGKDvPhi9vkERfRgaN6f2RQ5HTbNM3rrB9NsXZ4Qwg5IoHcgAZ3d+HjmcK4cGMV1u8bybvRL6IoSeGcMbHhXLkQS4hwngd7BuLs488qUgTx4SU+e3RHKbO/XqO42Cr7/MyyYDOUHbV2iEMJGJNA7IKUUD13Wi5cmJ/Bzlonxhfdz+MJnYd9v8OYISP/G1iUKIWxAAr0Du25IBPNnDKfwSBWX/RHH9qu+Bd8IWHwzfHUvVJbbukQhRDuSQO/gRsQG8sXskXi6uXDNkiJ+OO9jGPUIbF0Ib50PWetsXaIQop1IoDuA7kFefDl7JP3Dfbln0TZe1Tdimv69sfGD8bDin1BbbdsihRBtTgLdQQR6ubNg5nCuGxzBqz/v4q7VrpTf/gskTIPfXoT3LoXCDFuXKYRoQxLoDsTD1ZkXJw/g7xP7snJHAVe/l8Ke8/8FN8yHkix4+wL47WXprQvhoCwKdKXUOKXUTqXUbqXU4w1sj1JKrVJKbVFKpSilJli/VGEJpRS3nx/DxzOGc/hYNVf/9w9WqOEwex30Ggsr/gHvXgx5W21dqhDCypoNdKWUM/AGMB7oC0xVSvU9rdlTwBKt9SDgRuBNaxcqWua87oF8c/8FdOviycyPkvjP+jJMkz8yeutHDhoXI/08R1ZvFMKBWNJDHwbs1lrv1VpXAZ8Ak05rowEf83NfINd6JYqzFe7Xic/uHsk1A8N55ecM7vhwI4e7jYN718PAqfD7K8ZMmH1/2LpUIYQVWBLo4cCBeq+zze/VNwe4WSmVDXwP3G+V6kSrebg689INCTxzdX/W7C7mytd/J7lIwaQ34JavwFQD8ybAtw/L7e6E6OCsdVJ0KjBPax0BTADmK6XO+Gyl1CylVJJSKqmwsNBKuxbNUUpx84hufHbPeQBMfnsN89fuQ8deBLPXwnn3waYPjKtMM5bbslQhRCtYEug5QGS91xHm9+qbASwB0FqvBTyALqd/kNb6Ha11otY6MSgo6OwqFmdtQIQf3z1wAaN6BvHXr9N48JNkjmh3GPsszPgJ3H1g4Q3w2Qw4WmTrcoUQLWRJoG8EeiqlYpRSbhgnPZee1iYLuARAKdUHI9ClC26H/DzdeO/WRB4dG8e3Kblc+dpvbD1QAhGJcNdquOgvsP1r+O9QSFkiKzgK0YE0G+ha6xrgPmA5kI4xmyVNKfW0Uuoqc7NHgDuVUluBRcBtWksS2CsnJ8W9Y3qw6M4RVNWYuO6tNbz96x5MTq5w0WNw92/GLe6+uNPosZdm27pkIYQFlK1yNzExUSclJdlk3+Kk0mPVPPFlCt+n5jOyeyAv3zCQEF8PMNXChndgxdOgnODSOZA4A5zkWjQhbEkptUlrndjQNvl/5znO19OVN6YN5t/XDWBLVgnj/7OaH9PywckZRtxjnDSNGGqst/7+pXBgg61LFkI0QgJdoJTihqGRfPvABYT7d2LW/E089VUqx6tqwT8abvkSrvkflObA+5cZJ01lGEYIuyNDLuIUVTUmXvpxJ/9bvZeewV68NnUQfULN14xVHoE//gNrXgMUnP8AnP8guHW2ac1CnEtkyEVYzM3FiScm9GH+jGGUHK9m0ht/8L9f91Br0uDuBRc/CfclQe8J8Ou/4PUhsPUTMJlsXboQ5zwJdNGgUT2DWPbgKMbEBfHcDzu49q017DpovgOSXyRcPxfu+BG8Q+HLu+C9SyBrvW2LFuIcJ4EuGhXo5c7bNw/h9amDyCo+yhWv/c6bv+ymptbcG48aDjNXGOPr5Xkw93L47A5jqV4hRLuTMXRhkcLySv729TZ+2JZPQoQvL0xOoFdX75MN6o+vaxMMvdO4FV7nQNsVLYQDamoMXQJdtMh3KXn89ettHKmo4cFLe3LX6FhcnOv9oVeaDb88B8kLwbWzceJ0xGxj/F0I0WoS6MKqio9U8relaXyXkkd8uC/PXRtP/3DfUxsV7ICV/4Qd30LnYLjw/2DwdHBxs03RQjgICXTRJn5IzeOvX6dx6Gglt42M4eHLe+Hl7nJqowMbjRtp7P/dmNM+5inof51ccSrEWZJAF22m9Hg1Ly7fycfr99PV24O/T+zLuP4hKKVONtIadv8MP/8DDqZCSDxcMgd6XAL12wkhmiWBLtrclqzDPPnlNrbnlTEmLoinJ/UnMsDz1EYmE2z7DFY+AyX7Ieo8GPVnCXYhWkACXbSLmloTH67dz8s/7qTGpLnrwu7cc2F3Ork5n9awCjbNgz9ehbIcCE0wZsT0nihDMUI0QwJdtKv80gr+3/fpLN2aS7hfJ568og/jTx+GASPYUxYb9zY9tAe69IILHoL4yeDsapvihbBzEujCJtbvLebvS9PYkV/OyO6BzLmq36lz1+uYao2bavz2sjHG7htprBEz6GZw7dT+hQthxyTQhc3U1JpYtCGLF3/M4EhlDVOHRfLgJb0I8nY/s7HWsOsn+O1FOLDemO543r2QeAd4+LR/8ULYIQl0YXOHjlbxyk8ZLNyQhYeLE3dd2J2Zo2LwdHM5s7HWsP8P+O0l2LMSPHyNK08T7wDf8PYvXgg7IoEu7MaewiO8sGwny9LyCfZ25+HLenH9kIhTrzatL2cz/P4ypH9r3Dmpz5VGuEdfIDNjxDlJAl3YnU37D/Hsd+lsziqhZ7AXj4/vzcW9g888cVrn8D7Y+D5smQ/HD0NQHxg2EwbcKMsKiHOKBLqwS1prlqfl869lO8ksOsrgKD/+fHkcI3t0afyXqo/Dts+N+53mbQV3Hxg4DYbOhC492694IWyk1YGulBoH/AdwBt7TWj9/2vZXgDHml55AsNbar6nPlEAXdaprTXyalM3rK3eRV1rByO6BPHJ5L4Z0C2j8l7SG7CQj2NO+BFM1xI6BYbOg11jjnqhCOKBWBbpSyhnIAC4DsoGNwFSt9fZG2t8PDNJa39HU50qgi9NVVNeycH0Wb/6ym6IjVYyJC+Khy3oxIKLJvgEcKYDNH8LGuVCeC75RMPQOGHSrLN8rHE5rA/08YI7Weqz59RMAWuvnGmm/Bvi71vqnpj5XAl005lhVDR+u2c/bv+6h9Hg1o3p2YfZFPRgRG9D4GDtAbQ3s/A42vAv7fgNnd+Mk6sBpRu9deu3CAbQ20K8HxmmtZ5pf3wIM11rf10DbbsA6IEJrXdvA9lnALICoqKgh+/fvb+mxiHNIeUU1C9Zn8d5vmRQdqWRQlB/3XtSDi3sH4+TUzAyXgnTjJGrqp1BRAt5hkHAjDLwJuvRonwMQog20Z6A/hhHm9zdXlPTQhaUqqmv5dFM2//t1D9mHjxPX1be8nc4AABNFSURBVJvZY7pzRXxo49Md69RUws4fIHmBseKjNkHkcKPX3u8aY467EB1Iuw25KKW2APdqrdc0V5QEumip6loT36bk8uaqPewqOEJUgCd3XRjLdYMj8HC1YDilPB+2fmLcTaloJ7h0gj4TjXCPuVAWBhMdQmsD3QXjpOglQA7GSdFpWuu009r1BpYBMdqCqTMS6OJsmUyan9MP8sYve9h6oIRgb3fuuCCGG4dG4udpwR2RtDYuWEpeYCznW1EKPhEwcCokTIXA7m1/EEKcJWtMW5wAvIoxbXGu1vpZpdTTQJLWeqm5zRzAQ2v9uCVFSaCL1tJas2ZPMW/+sps/dhfj4erENYMiuP386IYXAWtIdYVxIjV5obHMQN2QTN+roe8kWWpA2B25sEg4vPS8Mub9sY+vknOorDFxQY8u3DYy2rITqHXKco0hmW2fw8FtxnsS7sLOSKCLc8aho1Us2pDF/LX7yS+roFugJ7eeF83kxAh8PFqwxnrRbtj+JaR9bSzpCxAxzDiRKuEubEgCXZxzqmtNLE/LZ94f+0jaf5hOrs5MTAhl2vBuJET4Nj2f/XSNhntdzz2ibQ5CiAZIoItzWmp2KQs37Ofr5FyOVdXSN9SHacOjuHpQOF7uDSzf25Si3bD9K0j76mS4hwyA3ldA3HjjuawCKdqQBLoQGBcqfZWcy8L1WaTnleHp5sykgWFMToxkUKRfy3rtAMV7IH0p7Fxm3JADDT7hRrDHjYfoUeDSwI08hGgFCXQh6tFak3yghIXrs/gmJZeKahOxXTpz3ZAIrhkUTpjfWdz27kgh7PoRdn5vzJapPgZuXtDjEoibAD0vB88mFhsTwkIS6EI0oryimh9S8/lsczYbMg+hFIzsHsh1gyMY1z+k4TsqNaf6OGT+ZkyH3LkMjuSDcoao84yee8/LjaV+ZWhGnAUJdCEskFV8jC+2ZPP55mwOHDpOZzdnxseHct3gCIbHBFg+/bE+kwnythjLD+z84eR0SN8o6Hkp9LgUYkaDu4Xz5sU5TwJdiBYwmTQb9x3i883ZfJ+az5HKGiL8OzExIYwrB4TSN9Sn5ePtdUqyjDVldv0Mmb9C1RFwcoWoEdDzMiPgg/tK7100SgJdiLN0vKqW5Wn5fL45mzV7iqk1aWK7dObKAaFcmRBm+RWpDampggPrTgZ8gXk1Da8Q6D4Gul8MsReBV7A1DkU4CAl0Iayg+Egly9Ly+XZrHusyi9EaenX14soBRs89NqiV9zYtzYE9K2DPKtj7Cxw/ZLzfNR66X2QEfNR54HoWJ22Fw5BAF8LKCsor+CE1n29Tctm47zAAfUN9GN8/hLH9Q+gZ7HX2wzJgjL3nbzXCfc9KyFpn3GbPxcMI9boefHA/WSXyHCOBLkQbyis9zncpeXyXmseWrBIAYrp05vJ+XRnbL4SBEX5nd0K1vqqjsH+NEe57VkFhuvF+5yDjbkx1wzM+oa3bj7B7EuhCtJODZRX8uP0gP6bls3ZPMTUmTVcfdy7ra4T78JhA3Fys0KMuyzWGZfasNB6PFhrvB/Uxgr3bSKMn7xXU+n0JuyKBLoQNlB6rZuXOgyzfdpBfMwo5Xl1LZzdnRvUM4uLewVzUO4hgb4/W78hkMqZD7q03PFNTYWwL7GEEe13A+0fLDJoOTgJdCBurqK7l911FrNxZwMr0AvLLjMAdEOHLxb2Dubh3MP3DfFs/NAPG7Jm8ZGOIJmsdZK017qsKxgyaqBFGuEeNgK79wfksLp4SNiOBLoQd0VqTnlfOyh0HWbmjgC0HStAagrzdGRMXxOheQVzQo4tld1+yhMkEhTsgaw3sX2usO1N6wNjm5gURQ08GfEQiuHW2zn5Fm5BAF8KOFR+p5NeMQlbsKGB1RiHlFTU4KRgQ4cfoXkFc2KsLCRF+zd8QuyVKDhjBnrXW6MUfTAO0sURBaIIR7pHDIDzRWB5YhmnshgS6EB1ETa2Jrdkl/JpRxOqMQlKySzBp8PFw4fweXRjVM4jhsQHEduncummRpzteAtkbzUM06yAn6eQ4vFdXI9jDBxs9+LBB4OFrvX2LFpFAF6KDKjlWxe+7jXBfnVF0Yuw9yNudYTEBjIgNZERMAD1aO+/9dDVVxnrv2ZsgZ5MR8MW7zRsVdOllBHzYYOOxa39wtcIJXtEsa9wkehzwH4ybRL+ntX6+gTY3AHMADWzVWk9r6jMl0IVoGa01e4uOsn7vIdZnFrNubzEHyyoBCOzsxrCYAIbHBDA8NpC4rt7WOcFa3/HDkLPZ/JNkBH3ddEknF2MNmvDBRg8+bDAE9wHnFtz2T1ikVYGulHIGMoDLgGxgIzBVa729XpuewBLgYq31YaVUsNa6oKnPlUAXonW01uwvPsb6zGJzyB8ip+Q4AH6ergyNNnrww2MC6BPqg7O1A15rKMsxAj53C+SaHytKje0uHtC1n3EXp9ABxmNwX3DztG4d55jWBvp5wByt9Vjz6ycAtNbP1WvzbyBDa/2epUVJoAthfQcOHWN95iHW7S1mfWYxBw4ZAe/t4cKw6ACGxwYwPCaQfmE+1j3JWkdrOLTXCPaczZCfYvzUhbxygsCeJwM+JN746dzF+rU4qKYC3ZIJqOHAgXqvs4Hhp7XpZd7RHxjDMnO01ssaKGQWMAsgKirKgl0LIVoiMsCTyABPrh9i3Lg6t+T4KT34FTuMP5y93F1IjPZneEwgw2MDiA/3xdUaAa8UBHY3fuKvN97T2lg2OD8F8lIgP9WYI5/66cnf8+xiDNEE94Xg3sZjUG/o5Nf6ms4hlvTQrwfGaa1nml/fAgzXWt9Xr823QDVwAxABrAbitdYljX2u9NCFaH8HyypYn3mI9XuLWZ95iN0FRwDwdHNmSDf/E2PwAyJ8cXdxbttijhYbIV+QDgXbjcfCHcYa8XV8wo1grx/2Qb3P6bnyre2h5wCR9V5HmN+rLxtYr7WuBjKVUhlAT4zxdiGEnejq48FVCWFclRAGQGF5JRsyD53oxb/4YwYA7i5ODIz0Y2CUHwMjjMcQHw/rzqTpHGheNXLMyfdMJijLPjXkC9Jhw+9QW2lupMC/m7FuzYmg72Pc1u8cvym3JT10F4yTopdgBPlGYJrWOq1em3EYJ0qnK6W6AFuAgVrr4sY+V3roQtifQ0erTgT85v2H2Z5XRnWtkRHB3u4kRPoZQR/pR3yELz4e7TSLxVQLhzKNkC/ccTLsi3eDqcZoo5yNoZ7gPvXCvg/4x4CLla66tQPWmLY4AXgVY3x8rtb6WaXU00CS1nqpMv7ZfgkYB9QCz2qtP2nqMyXQhbB/FdW1pOeVsfVACckHStiaXUpm0VHAGC7vHuRFQoQfAyN9GRjpT1yIt3VWk7RUTZUR6vV784XpRvhjzjblbPToA3sai5V16XHyuXdIh7sKVi4sEkJYTcmxKlKyS42ANwd98dEqANxcnOgX5nOiF58Q4Ue3QE/rDtVYouoYFO2Ewp1QtAuKd0HxHiP8666ABXDzNnr1XcwBH9jDeB7QHdxbeQeqNiKBLoRoM1prsg8fZ2v2yYBPzSmlotoEGHPiEyL8SIj0Y1CkHwMifAn0stFYd90YffFuKNptDnrz89IDnOjVA3iHnRn2gT3Ar5tNV6iUQBdCtKuaWhMZB4+wNbuE5KwStmaXkHGwHJM5biIDOjEw0p+ECF8GRvrRP9wXD9c2nlXTnOrjxhz603v0RbtOLj8M4ORqBH1QnDHjpu4xsEe7nJSVQBdC2NzRyhpSc0rZeqDkRNDnlhrDH85Oit4h3qecdO0e5GX9q1vP1tFiI9yLzb36wgzj5OzhTNDGXyIoJ/CNNMI+wDwXP7AHBMRatVcvgS6EsEsFZRVszS6td9K1hPIKY9aKl7sL8eG+xEf40i/Mh/hwX6IDO1t/jZrWqK4wQr5wBxRlGL36Q3uMx8qyk+2UM/hFQUCMMesmIMYIev8Y4y5SLVgOQQJdCNEhmEyazOKjJ4Zpth4oIT2/nKoaoxfc2c2ZfmG+9Av3oX+YL/3Dfeke1LltljFoDa3haNHJXv3hTGM451Cm8bxuKYQ6XiGnhnz94PcMOKWpBLoQosOqrjWx6+ARtuWWkpZTyrbcMrbnlnG8uhYAD1cn+oT60C/Mh76hRm8+LsTb9mPyTTl2yBzymSdDvu6xPO/Uth6+p/Tq1aV/l0AXQjiOWpMms+gIqTmlbMspY1tOKdvzyk4M1zg7KboHdaZvqA99w3zoF+ZL31Af/Dt3gAuMqo5Byf5Te/R1jyVZqL8fkkAXQji2uumTabmlbM8tIy23jO15ZeSVnpx3HubrQd8wH/qaA75fmA8R/p3af5782aqtQbm4tmotFyGEsHtKqROrTY7rH3ri/eIjlaTnlRtBn2cE/codBSemUHp7uJjD3dfcm/ehR7CXdVaftLZmZspIoAshHFqglzsX9HTngp4n11w/XlXLzoPlp/TmF27Yf+JiKDdnJ3qFeJ0S9L1DvPFur7VrzpIEuhDinNPJzfnEfPc6dePyaeaTrtvzyvg5vYAlSdkn2kQHep4yJt8vzIcgb3e7GbKRQBdCCIwTqT2CvekR7M2kgeGAMS5/sKyS7XmlpOUYIb8tp4zvU/NP/F4XL7cTY/J1QzbRgZ1tclGUBLoQQjRCKUWIrwchvh5c3LvriffLKqpJN/fi63r07+/Ze2KpYU83Z3qHeNMn1Mf8401ciA9e7m0buTLLRQghrKCqxsSugvKTM2xyy0jPPzmVEqBboOcpQd83tOWzbFp7xyIhhBDNMJYO9qVfmC+Tze9prckpOU56XjnpeWXsyC8jPa+cH7cfpK4v7eXuciLke4eaH0O88XRreTxLoAshRBtRShHh70mEvyeX9T05ZHOsqoad+eWnBP1XW3IoX1dj/j3oFuB5oidfF/gR/p2a3J8EuhBCtDNPNxcGRfkzKMr/xHt1F0Ztzytjhznot+eV8cO2kydgvT1kHroQQti9+hdGje0XcuL9o5U17Mg3Aj49r4xtTXyGBLoQQtixzu4uDOnmz5BuRm/+/zXR1qJrW5VS45RSO5VSu5VSjzew/TalVKFSKtn8M/PsShdCCHG2mu2hK6WcgTeAy4BsYKNSaqnWevtpTRdrre9rgxqFEEJYwJIe+jBgt9Z6r9a6CvgEmNS2ZQkhhGgpSwI9HDhQ73W2+b3TXaeUSlFKfaaUirRKdUIIISxmrfUhvwGitdYDgJ+ADxtqpJSapZRKUkolFRYWWmnXQgghwLJAzwHq97gjzO+doLUu1lpXml++Bwxp6IO01u9orRO11olBQUFnU68QQohGWBLoG4GeSqkYpZQbcCOwtH4DpVRovZdXAenWK1EIIYQlmp3lorWuUUrdBywHnIG5Wus0pdTTQJLWeinwgFLqKqAGOATc1oY1CyGEaIDNVltUSpUDO22y8/bRBSiydRFtSI6vY5Pj67i6aa0bHLO25ZWiOxtbAtIRKKWS5Pg6Ljm+js3Rj68xdngXVCGEEGdDAl0IIRyELQP9HRvuuz3I8XVscnwdm6MfX4NsdlJUCCGEdcmQixBCOAgJdCGEcBA2CfTm1lfviJRS+5RSqeb14JPM7wUopX5SSu0yP/o39zn2Qik1VylVoJTaVu+9Bo9HGV4zf58pSqnBtqvcMo0c3xylVE69df0n1Nv2hPn4diqlxtqmassopSKVUquUUtuVUmlKqQfN7zvE99fE8TnE99cqWut2/cG42nQPEAu4AVuBvu1dRxsc1z6gy2nv/Rt43Pz8ceBftq6zBcczGhgMbGvueIAJwA+AAkYA621d/1ke3xzgzw207Wv+79QdiDH/9+ts62No4thCgcHm595AhvkYHOL7a+L4HOL7a82PLXro59L66pM4ufLkh8DVNqylRbTWqzGWcaivseOZBHykDesAv9PW97E7jRxfYyYBn2itK7XWmcBujP+O7ZLWOk9rvdn8vBxjbaVwHOT7a+L4GtOhvr/WsEWgW7q+ekejgR+VUpuUUrPM73XVWueZn+cDXW1TmtU0djyO9J3eZx52mFtviKzDHp9SKhoYBKzHAb+/044PHOz7ayk5KWo9F2itBwPjgXuVUqPrb9TG334OM0fU0Y7H7C2gOzAQyANesm05raOU8gI+B/6ktS6rv80Rvr8Gjs+hvr+zYYtAb3Z99Y5Ia51jfiwAvsT4k+5g3Z+u5scC21VoFY0dj0N8p1rrg1rrWq21CXiXk3+Wd7jjU0q5YoTdAq31F+a3Heb7a+j4HOn7O1u2CPRm11fvaJRSnZVS3nXPgcuBbRjHNd3cbDrwtW0qtJrGjmcpcKt5tsQIoLTen/YdxmnjxtdgfIdgHN+NSil3pVQM0BPY0N71WUoppYD3gXSt9cv1NjnE99fY8TnK99cqtjgTi3FWPQPjbPOTtj4zbIXjicU4i74VSKs7JiAQWAHsAn4GAmxdawuOaRHGn63VGGOOMxo7HozZEW+Yv89UINHW9Z/l8c0315+CEQKh9do/aT6+ncB4W9ffzLFdgDGckgIkm38mOMr318TxOcT315ofufRfCCEchJwUFUIIByGBLoQQDkICXQghHIQEuhBCOAgJdCGEcBAS6EII4SAk0IUQwkH8f/9SeiYqbTNzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13987cdd0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['accuracy','val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
