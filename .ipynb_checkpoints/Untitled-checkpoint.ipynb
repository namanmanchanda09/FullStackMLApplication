{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.drop('species',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=iris['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4,activation='relu',input_shape=[4,]))\n",
    "model.add(Dense(3,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/1000\n",
      "120/120 [==============================] - 1s 6ms/sample - loss: 1.2516 - accuracy: 0.3333 - val_loss: 1.2091 - val_accuracy: 0.3333\n",
      "Epoch 2/1000\n",
      "120/120 [==============================] - 0s 545us/sample - loss: 1.2438 - accuracy: 0.3333 - val_loss: 1.2042 - val_accuracy: 0.3333\n",
      "Epoch 3/1000\n",
      "120/120 [==============================] - 0s 500us/sample - loss: 1.2366 - accuracy: 0.3333 - val_loss: 1.1992 - val_accuracy: 0.3333\n",
      "Epoch 4/1000\n",
      "120/120 [==============================] - 0s 282us/sample - loss: 1.2289 - accuracy: 0.3333 - val_loss: 1.1946 - val_accuracy: 0.3333\n",
      "Epoch 5/1000\n",
      "120/120 [==============================] - 0s 330us/sample - loss: 1.2224 - accuracy: 0.3333 - val_loss: 1.1901 - val_accuracy: 0.3000\n",
      "Epoch 6/1000\n",
      "120/120 [==============================] - 0s 337us/sample - loss: 1.2157 - accuracy: 0.3333 - val_loss: 1.1855 - val_accuracy: 0.3000\n",
      "Epoch 7/1000\n",
      "120/120 [==============================] - 0s 323us/sample - loss: 1.2093 - accuracy: 0.3333 - val_loss: 1.1812 - val_accuracy: 0.3000\n",
      "Epoch 8/1000\n",
      "120/120 [==============================] - 0s 380us/sample - loss: 1.2033 - accuracy: 0.3333 - val_loss: 1.1769 - val_accuracy: 0.3000\n",
      "Epoch 9/1000\n",
      "120/120 [==============================] - 0s 410us/sample - loss: 1.1968 - accuracy: 0.3333 - val_loss: 1.1727 - val_accuracy: 0.3000\n",
      "Epoch 10/1000\n",
      "120/120 [==============================] - 0s 641us/sample - loss: 1.1904 - accuracy: 0.3333 - val_loss: 1.1688 - val_accuracy: 0.3000\n",
      "Epoch 11/1000\n",
      "120/120 [==============================] - 0s 473us/sample - loss: 1.1847 - accuracy: 0.3333 - val_loss: 1.1648 - val_accuracy: 0.3000\n",
      "Epoch 12/1000\n",
      "120/120 [==============================] - 0s 328us/sample - loss: 1.1790 - accuracy: 0.3333 - val_loss: 1.1609 - val_accuracy: 0.3000\n",
      "Epoch 13/1000\n",
      "120/120 [==============================] - 0s 314us/sample - loss: 1.1730 - accuracy: 0.3333 - val_loss: 1.1572 - val_accuracy: 0.3000\n",
      "Epoch 14/1000\n",
      "120/120 [==============================] - 0s 311us/sample - loss: 1.1673 - accuracy: 0.3333 - val_loss: 1.1535 - val_accuracy: 0.3000\n",
      "Epoch 15/1000\n",
      "120/120 [==============================] - 0s 350us/sample - loss: 1.1611 - accuracy: 0.3333 - val_loss: 1.1498 - val_accuracy: 0.3000\n",
      "Epoch 16/1000\n",
      "120/120 [==============================] - 0s 369us/sample - loss: 1.1555 - accuracy: 0.3333 - val_loss: 1.1459 - val_accuracy: 0.3000\n",
      "Epoch 17/1000\n",
      "120/120 [==============================] - 0s 386us/sample - loss: 1.1492 - accuracy: 0.3333 - val_loss: 1.1422 - val_accuracy: 0.3000\n",
      "Epoch 18/1000\n",
      "120/120 [==============================] - 0s 313us/sample - loss: 1.1442 - accuracy: 0.3417 - val_loss: 1.1386 - val_accuracy: 0.3000\n",
      "Epoch 19/1000\n",
      "120/120 [==============================] - 0s 385us/sample - loss: 1.1383 - accuracy: 0.3417 - val_loss: 1.1350 - val_accuracy: 0.3000\n",
      "Epoch 20/1000\n",
      "120/120 [==============================] - 0s 374us/sample - loss: 1.1327 - accuracy: 0.3417 - val_loss: 1.1314 - val_accuracy: 0.3333\n",
      "Epoch 21/1000\n",
      "120/120 [==============================] - 0s 351us/sample - loss: 1.1270 - accuracy: 0.3417 - val_loss: 1.1279 - val_accuracy: 0.3333\n",
      "Epoch 22/1000\n",
      "120/120 [==============================] - 0s 375us/sample - loss: 1.1217 - accuracy: 0.3417 - val_loss: 1.1244 - val_accuracy: 0.3333\n",
      "Epoch 23/1000\n",
      "120/120 [==============================] - 0s 349us/sample - loss: 1.1165 - accuracy: 0.3417 - val_loss: 1.1209 - val_accuracy: 0.3333\n",
      "Epoch 24/1000\n",
      "120/120 [==============================] - 0s 348us/sample - loss: 1.1114 - accuracy: 0.3417 - val_loss: 1.1175 - val_accuracy: 0.3333\n",
      "Epoch 25/1000\n",
      "120/120 [==============================] - 0s 442us/sample - loss: 1.1062 - accuracy: 0.3500 - val_loss: 1.1140 - val_accuracy: 0.3333\n",
      "Epoch 26/1000\n",
      "120/120 [==============================] - 0s 492us/sample - loss: 1.1016 - accuracy: 0.3583 - val_loss: 1.1106 - val_accuracy: 0.3333\n",
      "Epoch 27/1000\n",
      "120/120 [==============================] - 0s 332us/sample - loss: 1.0967 - accuracy: 0.3917 - val_loss: 1.1071 - val_accuracy: 0.3333\n",
      "Epoch 28/1000\n",
      "120/120 [==============================] - 0s 376us/sample - loss: 1.0923 - accuracy: 0.3917 - val_loss: 1.1037 - val_accuracy: 0.3667\n",
      "Epoch 29/1000\n",
      "120/120 [==============================] - 0s 379us/sample - loss: 1.0878 - accuracy: 0.4250 - val_loss: 1.1003 - val_accuracy: 0.3667\n",
      "Epoch 30/1000\n",
      "120/120 [==============================] - 0s 358us/sample - loss: 1.0835 - accuracy: 0.4583 - val_loss: 1.0970 - val_accuracy: 0.4333\n",
      "Epoch 31/1000\n",
      "120/120 [==============================] - 0s 355us/sample - loss: 1.0793 - accuracy: 0.4750 - val_loss: 1.0935 - val_accuracy: 0.5000\n",
      "Epoch 32/1000\n",
      "120/120 [==============================] - 0s 345us/sample - loss: 1.0753 - accuracy: 0.4917 - val_loss: 1.0900 - val_accuracy: 0.5000\n",
      "Epoch 33/1000\n",
      "120/120 [==============================] - 0s 338us/sample - loss: 1.0716 - accuracy: 0.5250 - val_loss: 1.0866 - val_accuracy: 0.5667\n",
      "Epoch 34/1000\n",
      "120/120 [==============================] - 0s 392us/sample - loss: 1.0681 - accuracy: 0.5750 - val_loss: 1.0836 - val_accuracy: 0.6000\n",
      "Epoch 35/1000\n",
      "120/120 [==============================] - 0s 357us/sample - loss: 1.0645 - accuracy: 0.6000 - val_loss: 1.0804 - val_accuracy: 0.6000\n",
      "Epoch 36/1000\n",
      "120/120 [==============================] - 0s 388us/sample - loss: 1.0611 - accuracy: 0.6083 - val_loss: 1.0772 - val_accuracy: 0.6000\n",
      "Epoch 37/1000\n",
      "120/120 [==============================] - 0s 391us/sample - loss: 1.0580 - accuracy: 0.6250 - val_loss: 1.0741 - val_accuracy: 0.6333\n",
      "Epoch 38/1000\n",
      "120/120 [==============================] - 0s 447us/sample - loss: 1.0544 - accuracy: 0.6417 - val_loss: 1.0710 - val_accuracy: 0.6333\n",
      "Epoch 39/1000\n",
      "120/120 [==============================] - 0s 395us/sample - loss: 1.0511 - accuracy: 0.6500 - val_loss: 1.0681 - val_accuracy: 0.6333\n",
      "Epoch 40/1000\n",
      "120/120 [==============================] - 0s 326us/sample - loss: 1.0480 - accuracy: 0.6667 - val_loss: 1.0652 - val_accuracy: 0.6333\n",
      "Epoch 41/1000\n",
      "120/120 [==============================] - 0s 342us/sample - loss: 1.0448 - accuracy: 0.6750 - val_loss: 1.0624 - val_accuracy: 0.6333\n",
      "Epoch 42/1000\n",
      "120/120 [==============================] - 0s 407us/sample - loss: 1.0419 - accuracy: 0.6917 - val_loss: 1.0596 - val_accuracy: 0.6000\n",
      "Epoch 43/1000\n",
      "120/120 [==============================] - 0s 317us/sample - loss: 1.0388 - accuracy: 0.6917 - val_loss: 1.0568 - val_accuracy: 0.6000\n",
      "Epoch 44/1000\n",
      "120/120 [==============================] - 0s 284us/sample - loss: 1.0358 - accuracy: 0.7000 - val_loss: 1.0541 - val_accuracy: 0.6000\n",
      "Epoch 45/1000\n",
      "120/120 [==============================] - 0s 259us/sample - loss: 1.0327 - accuracy: 0.7083 - val_loss: 1.0515 - val_accuracy: 0.6000\n",
      "Epoch 46/1000\n",
      "120/120 [==============================] - 0s 406us/sample - loss: 1.0296 - accuracy: 0.7083 - val_loss: 1.0489 - val_accuracy: 0.6000\n",
      "Epoch 47/1000\n",
      "120/120 [==============================] - 0s 389us/sample - loss: 1.0266 - accuracy: 0.7083 - val_loss: 1.0462 - val_accuracy: 0.6000\n",
      "Epoch 48/1000\n",
      "120/120 [==============================] - 0s 372us/sample - loss: 1.0236 - accuracy: 0.7083 - val_loss: 1.0436 - val_accuracy: 0.6000\n",
      "Epoch 49/1000\n",
      "120/120 [==============================] - 0s 319us/sample - loss: 1.0207 - accuracy: 0.7167 - val_loss: 1.0409 - val_accuracy: 0.5667\n",
      "Epoch 50/1000\n",
      "120/120 [==============================] - 0s 279us/sample - loss: 1.0174 - accuracy: 0.7167 - val_loss: 1.0382 - val_accuracy: 0.6000\n",
      "Epoch 51/1000\n",
      "120/120 [==============================] - 0s 239us/sample - loss: 1.0143 - accuracy: 0.7167 - val_loss: 1.0353 - val_accuracy: 0.6000\n",
      "Epoch 52/1000\n",
      "120/120 [==============================] - 0s 256us/sample - loss: 1.0112 - accuracy: 0.7083 - val_loss: 1.0326 - val_accuracy: 0.6000\n",
      "Epoch 53/1000\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 1.0081 - accuracy: 0.7167 - val_loss: 1.0298 - val_accuracy: 0.6000\n",
      "Epoch 54/1000\n",
      "120/120 [==============================] - 0s 222us/sample - loss: 1.0051 - accuracy: 0.7167 - val_loss: 1.0269 - val_accuracy: 0.6000\n",
      "Epoch 55/1000\n",
      "120/120 [==============================] - 0s 320us/sample - loss: 1.0020 - accuracy: 0.7167 - val_loss: 1.0240 - val_accuracy: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/1000\n",
      "120/120 [==============================] - 0s 439us/sample - loss: 0.9987 - accuracy: 0.7167 - val_loss: 1.0211 - val_accuracy: 0.6000\n",
      "Epoch 57/1000\n",
      "120/120 [==============================] - 0s 362us/sample - loss: 0.9956 - accuracy: 0.7000 - val_loss: 1.0182 - val_accuracy: 0.6000\n",
      "Epoch 58/1000\n",
      "120/120 [==============================] - 0s 372us/sample - loss: 0.9924 - accuracy: 0.7000 - val_loss: 1.0154 - val_accuracy: 0.6000\n",
      "Epoch 59/1000\n",
      "120/120 [==============================] - 0s 340us/sample - loss: 0.9894 - accuracy: 0.7000 - val_loss: 1.0124 - val_accuracy: 0.6000\n",
      "Epoch 60/1000\n",
      "120/120 [==============================] - 0s 387us/sample - loss: 0.9861 - accuracy: 0.6917 - val_loss: 1.0095 - val_accuracy: 0.6000\n",
      "Epoch 61/1000\n",
      "120/120 [==============================] - 0s 271us/sample - loss: 0.9829 - accuracy: 0.6917 - val_loss: 1.0066 - val_accuracy: 0.6000\n",
      "Epoch 62/1000\n",
      "120/120 [==============================] - 0s 282us/sample - loss: 0.9796 - accuracy: 0.7000 - val_loss: 1.0036 - val_accuracy: 0.6000\n",
      "Epoch 63/1000\n",
      "120/120 [==============================] - 0s 375us/sample - loss: 0.9764 - accuracy: 0.7000 - val_loss: 1.0006 - val_accuracy: 0.6000\n",
      "Epoch 64/1000\n",
      "120/120 [==============================] - 0s 411us/sample - loss: 0.9731 - accuracy: 0.7000 - val_loss: 0.9974 - val_accuracy: 0.6000\n",
      "Epoch 65/1000\n",
      "120/120 [==============================] - 0s 379us/sample - loss: 0.9700 - accuracy: 0.6917 - val_loss: 0.9942 - val_accuracy: 0.6000\n",
      "Epoch 66/1000\n",
      "120/120 [==============================] - 0s 362us/sample - loss: 0.9667 - accuracy: 0.7000 - val_loss: 0.9911 - val_accuracy: 0.5667\n",
      "Epoch 67/1000\n",
      "120/120 [==============================] - 0s 342us/sample - loss: 0.9633 - accuracy: 0.6917 - val_loss: 0.9879 - val_accuracy: 0.5667\n",
      "Epoch 68/1000\n",
      "120/120 [==============================] - 0s 307us/sample - loss: 0.9602 - accuracy: 0.6833 - val_loss: 0.9848 - val_accuracy: 0.5667\n",
      "Epoch 69/1000\n",
      "120/120 [==============================] - 0s 340us/sample - loss: 0.9570 - accuracy: 0.6833 - val_loss: 0.9817 - val_accuracy: 0.5333\n",
      "Epoch 70/1000\n",
      "120/120 [==============================] - 0s 319us/sample - loss: 0.9538 - accuracy: 0.6833 - val_loss: 0.9786 - val_accuracy: 0.5333\n",
      "Epoch 71/1000\n",
      "120/120 [==============================] - 0s 375us/sample - loss: 0.9505 - accuracy: 0.6750 - val_loss: 0.9755 - val_accuracy: 0.5333\n",
      "Epoch 72/1000\n",
      "120/120 [==============================] - 0s 362us/sample - loss: 0.9472 - accuracy: 0.6750 - val_loss: 0.9724 - val_accuracy: 0.5333\n",
      "Epoch 73/1000\n",
      "120/120 [==============================] - 0s 314us/sample - loss: 0.9440 - accuracy: 0.6750 - val_loss: 0.9693 - val_accuracy: 0.5333\n",
      "Epoch 74/1000\n",
      "120/120 [==============================] - 0s 364us/sample - loss: 0.9408 - accuracy: 0.6750 - val_loss: 0.9661 - val_accuracy: 0.5333\n",
      "Epoch 75/1000\n",
      "120/120 [==============================] - 0s 364us/sample - loss: 0.9376 - accuracy: 0.6750 - val_loss: 0.9630 - val_accuracy: 0.5333\n",
      "Epoch 76/1000\n",
      "120/120 [==============================] - 0s 354us/sample - loss: 0.9342 - accuracy: 0.6750 - val_loss: 0.9599 - val_accuracy: 0.5333\n",
      "Epoch 77/1000\n",
      "120/120 [==============================] - 0s 464us/sample - loss: 0.9309 - accuracy: 0.6750 - val_loss: 0.9568 - val_accuracy: 0.5333\n",
      "Epoch 78/1000\n",
      "120/120 [==============================] - 0s 346us/sample - loss: 0.9277 - accuracy: 0.6833 - val_loss: 0.9537 - val_accuracy: 0.5333\n",
      "Epoch 79/1000\n",
      "120/120 [==============================] - 0s 374us/sample - loss: 0.9244 - accuracy: 0.6833 - val_loss: 0.9506 - val_accuracy: 0.5333\n",
      "Epoch 80/1000\n",
      "120/120 [==============================] - 0s 455us/sample - loss: 0.9211 - accuracy: 0.6833 - val_loss: 0.9475 - val_accuracy: 0.5333\n",
      "Epoch 81/1000\n",
      "120/120 [==============================] - 0s 411us/sample - loss: 0.9179 - accuracy: 0.6833 - val_loss: 0.9444 - val_accuracy: 0.5333\n",
      "Epoch 82/1000\n",
      "120/120 [==============================] - 0s 369us/sample - loss: 0.9145 - accuracy: 0.6833 - val_loss: 0.9413 - val_accuracy: 0.5333\n",
      "Epoch 83/1000\n",
      "120/120 [==============================] - 0s 322us/sample - loss: 0.9114 - accuracy: 0.6833 - val_loss: 0.9382 - val_accuracy: 0.5333\n",
      "Epoch 84/1000\n",
      "120/120 [==============================] - 0s 338us/sample - loss: 0.9081 - accuracy: 0.6917 - val_loss: 0.9351 - val_accuracy: 0.5333\n",
      "Epoch 85/1000\n",
      "120/120 [==============================] - 0s 276us/sample - loss: 0.9049 - accuracy: 0.7000 - val_loss: 0.9320 - val_accuracy: 0.5333\n",
      "Epoch 86/1000\n",
      "120/120 [==============================] - 0s 230us/sample - loss: 0.9017 - accuracy: 0.7000 - val_loss: 0.9288 - val_accuracy: 0.5333\n",
      "Epoch 87/1000\n",
      "120/120 [==============================] - 0s 262us/sample - loss: 0.8984 - accuracy: 0.7083 - val_loss: 0.9257 - val_accuracy: 0.5333\n",
      "Epoch 88/1000\n",
      "120/120 [==============================] - 0s 314us/sample - loss: 0.8954 - accuracy: 0.7083 - val_loss: 0.9226 - val_accuracy: 0.5333\n",
      "Epoch 89/1000\n",
      "120/120 [==============================] - 0s 229us/sample - loss: 0.8919 - accuracy: 0.7083 - val_loss: 0.9195 - val_accuracy: 0.5333\n",
      "Epoch 90/1000\n",
      "120/120 [==============================] - 0s 322us/sample - loss: 0.8886 - accuracy: 0.7083 - val_loss: 0.9164 - val_accuracy: 0.5333\n",
      "Epoch 91/1000\n",
      "120/120 [==============================] - 0s 330us/sample - loss: 0.8854 - accuracy: 0.7167 - val_loss: 0.9134 - val_accuracy: 0.5333\n",
      "Epoch 92/1000\n",
      "120/120 [==============================] - 0s 371us/sample - loss: 0.8824 - accuracy: 0.7167 - val_loss: 0.9102 - val_accuracy: 0.5333\n",
      "Epoch 93/1000\n",
      "120/120 [==============================] - 0s 456us/sample - loss: 0.8790 - accuracy: 0.7333 - val_loss: 0.9071 - val_accuracy: 0.5333\n",
      "Epoch 94/1000\n",
      "120/120 [==============================] - 0s 374us/sample - loss: 0.8759 - accuracy: 0.7417 - val_loss: 0.9041 - val_accuracy: 0.5667\n",
      "Epoch 95/1000\n",
      "120/120 [==============================] - 0s 327us/sample - loss: 0.8727 - accuracy: 0.7417 - val_loss: 0.9011 - val_accuracy: 0.5667\n",
      "Epoch 96/1000\n",
      "120/120 [==============================] - 0s 292us/sample - loss: 0.8695 - accuracy: 0.7417 - val_loss: 0.8981 - val_accuracy: 0.6000\n",
      "Epoch 97/1000\n",
      "120/120 [==============================] - 0s 291us/sample - loss: 0.8662 - accuracy: 0.7500 - val_loss: 0.8951 - val_accuracy: 0.6667\n",
      "Epoch 98/1000\n",
      "120/120 [==============================] - 0s 340us/sample - loss: 0.8630 - accuracy: 0.7583 - val_loss: 0.8921 - val_accuracy: 0.6667\n",
      "Epoch 99/1000\n",
      "120/120 [==============================] - 0s 308us/sample - loss: 0.8598 - accuracy: 0.7583 - val_loss: 0.8891 - val_accuracy: 0.6667\n",
      "Epoch 100/1000\n",
      "120/120 [==============================] - 0s 318us/sample - loss: 0.8567 - accuracy: 0.7583 - val_loss: 0.8861 - val_accuracy: 0.6667\n",
      "Epoch 101/1000\n",
      "120/120 [==============================] - 0s 360us/sample - loss: 0.8535 - accuracy: 0.7583 - val_loss: 0.8831 - val_accuracy: 0.6667\n",
      "Epoch 102/1000\n",
      "120/120 [==============================] - 0s 307us/sample - loss: 0.8503 - accuracy: 0.7583 - val_loss: 0.8802 - val_accuracy: 0.6667\n",
      "Epoch 103/1000\n",
      "120/120 [==============================] - 0s 299us/sample - loss: 0.8472 - accuracy: 0.7750 - val_loss: 0.8772 - val_accuracy: 0.6667\n",
      "Epoch 104/1000\n",
      "120/120 [==============================] - 0s 303us/sample - loss: 0.8441 - accuracy: 0.7750 - val_loss: 0.8743 - val_accuracy: 0.7000\n",
      "Epoch 105/1000\n",
      "120/120 [==============================] - 0s 282us/sample - loss: 0.8409 - accuracy: 0.7750 - val_loss: 0.8714 - val_accuracy: 0.7000\n",
      "Epoch 106/1000\n",
      "120/120 [==============================] - 0s 337us/sample - loss: 0.8377 - accuracy: 0.7750 - val_loss: 0.8685 - val_accuracy: 0.7000\n",
      "Epoch 107/1000\n",
      "120/120 [==============================] - 0s 343us/sample - loss: 0.8347 - accuracy: 0.7833 - val_loss: 0.8655 - val_accuracy: 0.7000\n",
      "Epoch 108/1000\n",
      "120/120 [==============================] - 0s 420us/sample - loss: 0.8316 - accuracy: 0.7833 - val_loss: 0.8626 - val_accuracy: 0.7000\n",
      "Epoch 109/1000\n",
      "120/120 [==============================] - 0s 399us/sample - loss: 0.8285 - accuracy: 0.7917 - val_loss: 0.8597 - val_accuracy: 0.7000\n",
      "Epoch 110/1000\n",
      "120/120 [==============================] - 0s 430us/sample - loss: 0.8255 - accuracy: 0.7833 - val_loss: 0.8568 - val_accuracy: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/1000\n",
      "120/120 [==============================] - 0s 413us/sample - loss: 0.8224 - accuracy: 0.7833 - val_loss: 0.8539 - val_accuracy: 0.7000\n",
      "Epoch 112/1000\n",
      "120/120 [==============================] - 0s 380us/sample - loss: 0.8194 - accuracy: 0.7917 - val_loss: 0.8511 - val_accuracy: 0.7000\n",
      "Epoch 113/1000\n",
      "120/120 [==============================] - 0s 349us/sample - loss: 0.8162 - accuracy: 0.8000 - val_loss: 0.8483 - val_accuracy: 0.7000\n",
      "Epoch 114/1000\n",
      "120/120 [==============================] - 0s 308us/sample - loss: 0.8133 - accuracy: 0.8000 - val_loss: 0.8455 - val_accuracy: 0.7000\n",
      "Epoch 115/1000\n",
      "120/120 [==============================] - 0s 293us/sample - loss: 0.8103 - accuracy: 0.8000 - val_loss: 0.8428 - val_accuracy: 0.7000\n",
      "Epoch 116/1000\n",
      "120/120 [==============================] - 0s 295us/sample - loss: 0.8075 - accuracy: 0.8000 - val_loss: 0.8401 - val_accuracy: 0.7000\n",
      "Epoch 117/1000\n",
      "120/120 [==============================] - 0s 259us/sample - loss: 0.8045 - accuracy: 0.8000 - val_loss: 0.8374 - val_accuracy: 0.7000\n",
      "Epoch 118/1000\n",
      "120/120 [==============================] - 0s 272us/sample - loss: 0.8016 - accuracy: 0.8000 - val_loss: 0.8347 - val_accuracy: 0.7000\n",
      "Epoch 119/1000\n",
      "120/120 [==============================] - 0s 306us/sample - loss: 0.7987 - accuracy: 0.8000 - val_loss: 0.8319 - val_accuracy: 0.7000\n",
      "Epoch 120/1000\n",
      "120/120 [==============================] - 0s 314us/sample - loss: 0.7958 - accuracy: 0.8083 - val_loss: 0.8292 - val_accuracy: 0.7000\n",
      "Epoch 121/1000\n",
      "120/120 [==============================] - 0s 287us/sample - loss: 0.7929 - accuracy: 0.8083 - val_loss: 0.8266 - val_accuracy: 0.7000\n",
      "Epoch 122/1000\n",
      "120/120 [==============================] - 0s 285us/sample - loss: 0.7901 - accuracy: 0.8083 - val_loss: 0.8239 - val_accuracy: 0.7667\n",
      "Epoch 123/1000\n",
      "120/120 [==============================] - 0s 320us/sample - loss: 0.7873 - accuracy: 0.8083 - val_loss: 0.8212 - val_accuracy: 0.7667\n",
      "Epoch 124/1000\n",
      "120/120 [==============================] - 0s 376us/sample - loss: 0.7844 - accuracy: 0.8083 - val_loss: 0.8186 - val_accuracy: 0.7667\n",
      "Epoch 125/1000\n",
      "120/120 [==============================] - 0s 420us/sample - loss: 0.7816 - accuracy: 0.8083 - val_loss: 0.8159 - val_accuracy: 0.7667\n",
      "Epoch 126/1000\n",
      "120/120 [==============================] - 0s 273us/sample - loss: 0.7789 - accuracy: 0.8083 - val_loss: 0.8133 - val_accuracy: 0.7667\n",
      "Epoch 127/1000\n",
      "120/120 [==============================] - 0s 262us/sample - loss: 0.7762 - accuracy: 0.8083 - val_loss: 0.8108 - val_accuracy: 0.7667\n",
      "Epoch 128/1000\n",
      "120/120 [==============================] - 0s 243us/sample - loss: 0.7734 - accuracy: 0.8083 - val_loss: 0.8082 - val_accuracy: 0.7667\n",
      "Epoch 129/1000\n",
      "120/120 [==============================] - 0s 232us/sample - loss: 0.7707 - accuracy: 0.8083 - val_loss: 0.8057 - val_accuracy: 0.7667\n",
      "Epoch 130/1000\n",
      "120/120 [==============================] - 0s 214us/sample - loss: 0.7680 - accuracy: 0.8083 - val_loss: 0.8032 - val_accuracy: 0.7667\n",
      "Epoch 131/1000\n",
      "120/120 [==============================] - 0s 320us/sample - loss: 0.7653 - accuracy: 0.8083 - val_loss: 0.8007 - val_accuracy: 0.7667\n",
      "Epoch 132/1000\n",
      "120/120 [==============================] - 0s 255us/sample - loss: 0.7627 - accuracy: 0.8083 - val_loss: 0.7982 - val_accuracy: 0.7667\n",
      "Epoch 133/1000\n",
      "120/120 [==============================] - 0s 229us/sample - loss: 0.7600 - accuracy: 0.8083 - val_loss: 0.7957 - val_accuracy: 0.7667\n",
      "Epoch 134/1000\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.7574 - accuracy: 0.8083 - val_loss: 0.7933 - val_accuracy: 0.7667\n",
      "Epoch 135/1000\n",
      "120/120 [==============================] - 0s 300us/sample - loss: 0.7548 - accuracy: 0.8083 - val_loss: 0.7907 - val_accuracy: 0.7667\n",
      "Epoch 136/1000\n",
      "120/120 [==============================] - 0s 268us/sample - loss: 0.7522 - accuracy: 0.8083 - val_loss: 0.7883 - val_accuracy: 0.7667\n",
      "Epoch 137/1000\n",
      "120/120 [==============================] - 0s 215us/sample - loss: 0.7496 - accuracy: 0.8167 - val_loss: 0.7859 - val_accuracy: 0.7667\n",
      "Epoch 138/1000\n",
      "120/120 [==============================] - 0s 255us/sample - loss: 0.7471 - accuracy: 0.8250 - val_loss: 0.7835 - val_accuracy: 0.7667\n",
      "Epoch 139/1000\n",
      "120/120 [==============================] - 0s 376us/sample - loss: 0.7446 - accuracy: 0.8250 - val_loss: 0.7811 - val_accuracy: 0.7667\n",
      "Epoch 140/1000\n",
      "120/120 [==============================] - 0s 298us/sample - loss: 0.7420 - accuracy: 0.8250 - val_loss: 0.7788 - val_accuracy: 0.7667\n",
      "Epoch 141/1000\n",
      "120/120 [==============================] - 0s 251us/sample - loss: 0.7395 - accuracy: 0.8250 - val_loss: 0.7765 - val_accuracy: 0.7667\n",
      "Epoch 142/1000\n",
      "120/120 [==============================] - 0s 349us/sample - loss: 0.7371 - accuracy: 0.8250 - val_loss: 0.7743 - val_accuracy: 0.7667\n",
      "Epoch 143/1000\n",
      "120/120 [==============================] - 0s 282us/sample - loss: 0.7346 - accuracy: 0.8250 - val_loss: 0.7720 - val_accuracy: 0.7667\n",
      "Epoch 144/1000\n",
      "120/120 [==============================] - 0s 438us/sample - loss: 0.7322 - accuracy: 0.8250 - val_loss: 0.7697 - val_accuracy: 0.7667\n",
      "Epoch 145/1000\n",
      "120/120 [==============================] - 0s 286us/sample - loss: 0.7297 - accuracy: 0.8250 - val_loss: 0.7675 - val_accuracy: 0.8000\n",
      "Epoch 146/1000\n",
      "120/120 [==============================] - 0s 297us/sample - loss: 0.7273 - accuracy: 0.8333 - val_loss: 0.7652 - val_accuracy: 0.8333\n",
      "Epoch 147/1000\n",
      "120/120 [==============================] - 0s 300us/sample - loss: 0.7250 - accuracy: 0.8333 - val_loss: 0.7630 - val_accuracy: 0.8333\n",
      "Epoch 148/1000\n",
      "120/120 [==============================] - 0s 451us/sample - loss: 0.7226 - accuracy: 0.8333 - val_loss: 0.7608 - val_accuracy: 0.8333\n",
      "Epoch 149/1000\n",
      "120/120 [==============================] - 0s 314us/sample - loss: 0.7203 - accuracy: 0.8333 - val_loss: 0.7586 - val_accuracy: 0.8333\n",
      "Epoch 150/1000\n",
      "120/120 [==============================] - 0s 328us/sample - loss: 0.7179 - accuracy: 0.8333 - val_loss: 0.7564 - val_accuracy: 0.8333\n",
      "Epoch 151/1000\n",
      "120/120 [==============================] - 0s 247us/sample - loss: 0.7156 - accuracy: 0.8333 - val_loss: 0.7542 - val_accuracy: 0.8667\n",
      "Epoch 152/1000\n",
      "120/120 [==============================] - 0s 306us/sample - loss: 0.7133 - accuracy: 0.8333 - val_loss: 0.7521 - val_accuracy: 0.8667\n",
      "Epoch 153/1000\n",
      "120/120 [==============================] - 0s 262us/sample - loss: 0.7110 - accuracy: 0.8417 - val_loss: 0.7499 - val_accuracy: 0.8667\n",
      "Epoch 154/1000\n",
      "120/120 [==============================] - 0s 304us/sample - loss: 0.7088 - accuracy: 0.8417 - val_loss: 0.7478 - val_accuracy: 0.8667\n",
      "Epoch 155/1000\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 0.7066 - accuracy: 0.8417 - val_loss: 0.7457 - val_accuracy: 0.8667\n",
      "Epoch 156/1000\n",
      "120/120 [==============================] - 0s 252us/sample - loss: 0.7043 - accuracy: 0.8333 - val_loss: 0.7435 - val_accuracy: 0.9000\n",
      "Epoch 157/1000\n",
      "120/120 [==============================] - 0s 280us/sample - loss: 0.7022 - accuracy: 0.8333 - val_loss: 0.7414 - val_accuracy: 0.9000\n",
      "Epoch 158/1000\n",
      "120/120 [==============================] - 0s 253us/sample - loss: 0.6999 - accuracy: 0.8417 - val_loss: 0.7393 - val_accuracy: 0.9000\n",
      "Epoch 159/1000\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.6977 - accuracy: 0.8500 - val_loss: 0.7372 - val_accuracy: 0.9000\n",
      "Epoch 160/1000\n",
      "120/120 [==============================] - 0s 281us/sample - loss: 0.6956 - accuracy: 0.8583 - val_loss: 0.7351 - val_accuracy: 0.9000\n",
      "Epoch 161/1000\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 0.6934 - accuracy: 0.8583 - val_loss: 0.7330 - val_accuracy: 0.9000\n",
      "Epoch 162/1000\n",
      "120/120 [==============================] - 0s 333us/sample - loss: 0.6915 - accuracy: 0.8500 - val_loss: 0.7308 - val_accuracy: 0.9000\n",
      "Epoch 163/1000\n",
      "120/120 [==============================] - 0s 349us/sample - loss: 0.6892 - accuracy: 0.8500 - val_loss: 0.7288 - val_accuracy: 0.9000\n",
      "Epoch 164/1000\n",
      "120/120 [==============================] - 0s 331us/sample - loss: 0.6871 - accuracy: 0.8500 - val_loss: 0.7268 - val_accuracy: 0.9000\n",
      "Epoch 165/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 475us/sample - loss: 0.6851 - accuracy: 0.8583 - val_loss: 0.7248 - val_accuracy: 0.9000\n",
      "Epoch 166/1000\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 0.6830 - accuracy: 0.8583 - val_loss: 0.7228 - val_accuracy: 0.9000\n",
      "Epoch 167/1000\n",
      "120/120 [==============================] - 0s 305us/sample - loss: 0.6810 - accuracy: 0.8583 - val_loss: 0.7209 - val_accuracy: 0.9000\n",
      "Epoch 168/1000\n",
      "120/120 [==============================] - 0s 334us/sample - loss: 0.6789 - accuracy: 0.8583 - val_loss: 0.7189 - val_accuracy: 0.9000\n",
      "Epoch 169/1000\n",
      "120/120 [==============================] - 0s 350us/sample - loss: 0.6769 - accuracy: 0.8667 - val_loss: 0.7169 - val_accuracy: 0.9000\n",
      "Epoch 170/1000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.6914 - accuracy: 0.81 - 0s 323us/sample - loss: 0.6749 - accuracy: 0.8667 - val_loss: 0.7149 - val_accuracy: 0.9000\n",
      "Epoch 171/1000\n",
      "120/120 [==============================] - 0s 324us/sample - loss: 0.6730 - accuracy: 0.8667 - val_loss: 0.7129 - val_accuracy: 0.8667\n",
      "Epoch 172/1000\n",
      "120/120 [==============================] - 0s 364us/sample - loss: 0.6710 - accuracy: 0.8667 - val_loss: 0.7109 - val_accuracy: 0.8667\n",
      "Epoch 173/1000\n",
      "120/120 [==============================] - 0s 300us/sample - loss: 0.6691 - accuracy: 0.8667 - val_loss: 0.7090 - val_accuracy: 0.8667\n",
      "Epoch 174/1000\n",
      "120/120 [==============================] - 0s 292us/sample - loss: 0.6671 - accuracy: 0.8667 - val_loss: 0.7071 - val_accuracy: 0.8667\n",
      "Epoch 175/1000\n",
      "120/120 [==============================] - 0s 306us/sample - loss: 0.6652 - accuracy: 0.8667 - val_loss: 0.7051 - val_accuracy: 0.8667\n",
      "Epoch 176/1000\n",
      "120/120 [==============================] - 0s 302us/sample - loss: 0.6633 - accuracy: 0.8667 - val_loss: 0.7032 - val_accuracy: 0.8667\n",
      "Epoch 177/1000\n",
      "120/120 [==============================] - 0s 334us/sample - loss: 0.6614 - accuracy: 0.8667 - val_loss: 0.7013 - val_accuracy: 0.8667\n",
      "Epoch 178/1000\n",
      "120/120 [==============================] - 0s 237us/sample - loss: 0.6595 - accuracy: 0.8667 - val_loss: 0.6995 - val_accuracy: 0.9000\n",
      "Epoch 179/1000\n",
      "120/120 [==============================] - 0s 286us/sample - loss: 0.6576 - accuracy: 0.8667 - val_loss: 0.6977 - val_accuracy: 0.9000\n",
      "Epoch 180/1000\n",
      "120/120 [==============================] - 0s 375us/sample - loss: 0.6558 - accuracy: 0.8667 - val_loss: 0.6958 - val_accuracy: 0.8667\n",
      "Epoch 181/1000\n",
      "120/120 [==============================] - 0s 302us/sample - loss: 0.6540 - accuracy: 0.8667 - val_loss: 0.6940 - val_accuracy: 0.8667\n",
      "Epoch 182/1000\n",
      "120/120 [==============================] - 0s 311us/sample - loss: 0.6521 - accuracy: 0.8667 - val_loss: 0.6922 - val_accuracy: 0.9000\n",
      "Epoch 183/1000\n",
      "120/120 [==============================] - 0s 318us/sample - loss: 0.6503 - accuracy: 0.8667 - val_loss: 0.6903 - val_accuracy: 0.9000\n",
      "Epoch 184/1000\n",
      "120/120 [==============================] - 0s 212us/sample - loss: 0.6485 - accuracy: 0.8750 - val_loss: 0.6885 - val_accuracy: 0.9000\n",
      "Epoch 185/1000\n",
      "120/120 [==============================] - 0s 227us/sample - loss: 0.6467 - accuracy: 0.8833 - val_loss: 0.6867 - val_accuracy: 0.9000\n",
      "Epoch 186/1000\n",
      "120/120 [==============================] - 0s 226us/sample - loss: 0.6449 - accuracy: 0.8833 - val_loss: 0.6850 - val_accuracy: 0.9000\n",
      "Epoch 187/1000\n",
      "120/120 [==============================] - 0s 319us/sample - loss: 0.6431 - accuracy: 0.8833 - val_loss: 0.6832 - val_accuracy: 0.9000\n",
      "Epoch 188/1000\n",
      "120/120 [==============================] - 0s 228us/sample - loss: 0.6413 - accuracy: 0.8833 - val_loss: 0.6814 - val_accuracy: 0.9000\n",
      "Epoch 189/1000\n",
      "120/120 [==============================] - 0s 210us/sample - loss: 0.6396 - accuracy: 0.8833 - val_loss: 0.6797 - val_accuracy: 0.9000\n",
      "Epoch 190/1000\n",
      "120/120 [==============================] - 0s 408us/sample - loss: 0.6379 - accuracy: 0.8833 - val_loss: 0.6779 - val_accuracy: 0.9000\n",
      "Epoch 191/1000\n",
      "120/120 [==============================] - 0s 282us/sample - loss: 0.6362 - accuracy: 0.8833 - val_loss: 0.6762 - val_accuracy: 0.9333\n",
      "Epoch 192/1000\n",
      "120/120 [==============================] - 0s 358us/sample - loss: 0.6345 - accuracy: 0.8833 - val_loss: 0.6745 - val_accuracy: 0.9333\n",
      "Epoch 193/1000\n",
      "120/120 [==============================] - 0s 244us/sample - loss: 0.6328 - accuracy: 0.8833 - val_loss: 0.6729 - val_accuracy: 0.9333\n",
      "Epoch 194/1000\n",
      "120/120 [==============================] - 0s 287us/sample - loss: 0.6311 - accuracy: 0.8917 - val_loss: 0.6712 - val_accuracy: 0.9000\n",
      "Epoch 195/1000\n",
      "120/120 [==============================] - 0s 304us/sample - loss: 0.6294 - accuracy: 0.8917 - val_loss: 0.6696 - val_accuracy: 0.9333\n",
      "Epoch 196/1000\n",
      "120/120 [==============================] - 0s 333us/sample - loss: 0.6277 - accuracy: 0.8917 - val_loss: 0.6680 - val_accuracy: 0.9000\n",
      "Epoch 197/1000\n",
      "120/120 [==============================] - 0s 290us/sample - loss: 0.6261 - accuracy: 0.8917 - val_loss: 0.6663 - val_accuracy: 0.9000\n",
      "Epoch 198/1000\n",
      "120/120 [==============================] - 0s 418us/sample - loss: 0.6245 - accuracy: 0.8917 - val_loss: 0.6647 - val_accuracy: 0.9000\n",
      "Epoch 199/1000\n",
      "120/120 [==============================] - 0s 336us/sample - loss: 0.6229 - accuracy: 0.8917 - val_loss: 0.6631 - val_accuracy: 0.9333\n",
      "Epoch 200/1000\n",
      "120/120 [==============================] - 0s 293us/sample - loss: 0.6213 - accuracy: 0.9000 - val_loss: 0.6616 - val_accuracy: 0.9333\n",
      "Epoch 201/1000\n",
      "120/120 [==============================] - 0s 347us/sample - loss: 0.6196 - accuracy: 0.9000 - val_loss: 0.6599 - val_accuracy: 0.9333\n",
      "Epoch 202/1000\n",
      "120/120 [==============================] - 0s 279us/sample - loss: 0.6181 - accuracy: 0.9000 - val_loss: 0.6583 - val_accuracy: 0.9333\n",
      "Epoch 203/1000\n",
      "120/120 [==============================] - 0s 386us/sample - loss: 0.6166 - accuracy: 0.9000 - val_loss: 0.6566 - val_accuracy: 0.9000\n",
      "Epoch 204/1000\n",
      "120/120 [==============================] - 0s 315us/sample - loss: 0.6149 - accuracy: 0.9000 - val_loss: 0.6550 - val_accuracy: 0.9333\n",
      "Epoch 205/1000\n",
      "120/120 [==============================] - 0s 386us/sample - loss: 0.6134 - accuracy: 0.9000 - val_loss: 0.6534 - val_accuracy: 0.9333\n",
      "Epoch 206/1000\n",
      "120/120 [==============================] - 0s 332us/sample - loss: 0.6118 - accuracy: 0.9000 - val_loss: 0.6519 - val_accuracy: 0.9333\n",
      "Epoch 207/1000\n",
      "120/120 [==============================] - 0s 337us/sample - loss: 0.6103 - accuracy: 0.9000 - val_loss: 0.6502 - val_accuracy: 0.9333\n",
      "Epoch 208/1000\n",
      "120/120 [==============================] - 0s 330us/sample - loss: 0.6087 - accuracy: 0.9000 - val_loss: 0.6486 - val_accuracy: 0.9333\n",
      "Epoch 209/1000\n",
      "120/120 [==============================] - 0s 368us/sample - loss: 0.6072 - accuracy: 0.9000 - val_loss: 0.6471 - val_accuracy: 0.9333\n",
      "Epoch 210/1000\n",
      "120/120 [==============================] - 0s 328us/sample - loss: 0.6057 - accuracy: 0.9083 - val_loss: 0.6455 - val_accuracy: 0.9333\n",
      "Epoch 211/1000\n",
      "120/120 [==============================] - 0s 311us/sample - loss: 0.6042 - accuracy: 0.9000 - val_loss: 0.6440 - val_accuracy: 0.9333\n",
      "Epoch 212/1000\n",
      "120/120 [==============================] - 0s 295us/sample - loss: 0.6027 - accuracy: 0.9000 - val_loss: 0.6424 - val_accuracy: 0.9333\n",
      "Epoch 213/1000\n",
      "120/120 [==============================] - 0s 339us/sample - loss: 0.6012 - accuracy: 0.9167 - val_loss: 0.6409 - val_accuracy: 0.9333\n",
      "Epoch 214/1000\n",
      "120/120 [==============================] - 0s 321us/sample - loss: 0.5997 - accuracy: 0.9167 - val_loss: 0.6394 - val_accuracy: 0.9333\n",
      "Epoch 215/1000\n",
      "120/120 [==============================] - 0s 240us/sample - loss: 0.5982 - accuracy: 0.9167 - val_loss: 0.6379 - val_accuracy: 0.9333\n",
      "Epoch 216/1000\n",
      "120/120 [==============================] - 0s 280us/sample - loss: 0.5967 - accuracy: 0.9167 - val_loss: 0.6364 - val_accuracy: 0.9333\n",
      "Epoch 217/1000\n",
      "120/120 [==============================] - 0s 357us/sample - loss: 0.5953 - accuracy: 0.9250 - val_loss: 0.6349 - val_accuracy: 0.9333\n",
      "Epoch 218/1000\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.5939 - accuracy: 0.9250 - val_loss: 0.6334 - val_accuracy: 0.9333\n",
      "Epoch 219/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 299us/sample - loss: 0.5924 - accuracy: 0.9250 - val_loss: 0.6319 - val_accuracy: 0.9333\n",
      "Epoch 220/1000\n",
      "120/120 [==============================] - 0s 254us/sample - loss: 0.5910 - accuracy: 0.9250 - val_loss: 0.6304 - val_accuracy: 0.9333\n",
      "Epoch 221/1000\n",
      "120/120 [==============================] - 0s 319us/sample - loss: 0.5895 - accuracy: 0.9250 - val_loss: 0.6289 - val_accuracy: 0.9333\n",
      "Epoch 222/1000\n",
      "120/120 [==============================] - 0s 261us/sample - loss: 0.5881 - accuracy: 0.9250 - val_loss: 0.6275 - val_accuracy: 0.9333\n",
      "Epoch 223/1000\n",
      "120/120 [==============================] - 0s 270us/sample - loss: 0.5867 - accuracy: 0.9250 - val_loss: 0.6261 - val_accuracy: 0.9333\n",
      "Epoch 224/1000\n",
      "120/120 [==============================] - 0s 262us/sample - loss: 0.5853 - accuracy: 0.9250 - val_loss: 0.6247 - val_accuracy: 0.9333\n",
      "Epoch 225/1000\n",
      "120/120 [==============================] - 0s 252us/sample - loss: 0.5839 - accuracy: 0.9250 - val_loss: 0.6232 - val_accuracy: 0.9333\n",
      "Epoch 226/1000\n",
      "120/120 [==============================] - 0s 265us/sample - loss: 0.5825 - accuracy: 0.9250 - val_loss: 0.6218 - val_accuracy: 0.9333\n",
      "Epoch 227/1000\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.5812 - accuracy: 0.9250 - val_loss: 0.6204 - val_accuracy: 0.9333\n",
      "Epoch 228/1000\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.5798 - accuracy: 0.9333 - val_loss: 0.6190 - val_accuracy: 0.9333\n",
      "Epoch 229/1000\n",
      "120/120 [==============================] - 0s 255us/sample - loss: 0.5784 - accuracy: 0.9333 - val_loss: 0.6176 - val_accuracy: 0.9333\n",
      "Epoch 230/1000\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.5771 - accuracy: 0.9333 - val_loss: 0.6163 - val_accuracy: 0.9333\n",
      "Epoch 231/1000\n",
      "120/120 [==============================] - 0s 238us/sample - loss: 0.5757 - accuracy: 0.9333 - val_loss: 0.6149 - val_accuracy: 0.9333\n",
      "Epoch 232/1000\n",
      "120/120 [==============================] - 0s 273us/sample - loss: 0.5744 - accuracy: 0.9333 - val_loss: 0.6135 - val_accuracy: 0.9333\n",
      "Epoch 233/1000\n",
      "120/120 [==============================] - 0s 252us/sample - loss: 0.5731 - accuracy: 0.9333 - val_loss: 0.6120 - val_accuracy: 0.9333\n",
      "Epoch 234/1000\n",
      "120/120 [==============================] - 0s 280us/sample - loss: 0.5717 - accuracy: 0.9333 - val_loss: 0.6106 - val_accuracy: 0.9333\n",
      "Epoch 235/1000\n",
      "120/120 [==============================] - 0s 271us/sample - loss: 0.5704 - accuracy: 0.9250 - val_loss: 0.6092 - val_accuracy: 0.9333\n",
      "Epoch 236/1000\n",
      "120/120 [==============================] - 0s 282us/sample - loss: 0.5691 - accuracy: 0.9250 - val_loss: 0.6078 - val_accuracy: 0.9333\n",
      "Epoch 237/1000\n",
      "120/120 [==============================] - 0s 295us/sample - loss: 0.5677 - accuracy: 0.9250 - val_loss: 0.6064 - val_accuracy: 0.9333\n",
      "Epoch 238/1000\n",
      "120/120 [==============================] - 0s 262us/sample - loss: 0.5664 - accuracy: 0.9333 - val_loss: 0.6051 - val_accuracy: 0.9333\n",
      "Epoch 239/1000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.5232 - accuracy: 0.93 - 0s 244us/sample - loss: 0.5651 - accuracy: 0.9333 - val_loss: 0.6037 - val_accuracy: 0.9333\n",
      "Epoch 240/1000\n",
      "120/120 [==============================] - 0s 272us/sample - loss: 0.5638 - accuracy: 0.9333 - val_loss: 0.6024 - val_accuracy: 0.9333\n",
      "Epoch 241/1000\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.5626 - accuracy: 0.9333 - val_loss: 0.6011 - val_accuracy: 0.9333\n",
      "Epoch 242/1000\n",
      "120/120 [==============================] - 0s 293us/sample - loss: 0.5613 - accuracy: 0.9333 - val_loss: 0.5998 - val_accuracy: 0.9333\n",
      "Epoch 243/1000\n",
      "120/120 [==============================] - 0s 261us/sample - loss: 0.5601 - accuracy: 0.9417 - val_loss: 0.5984 - val_accuracy: 0.9333\n",
      "Epoch 244/1000\n",
      "120/120 [==============================] - 0s 255us/sample - loss: 0.5587 - accuracy: 0.9417 - val_loss: 0.5972 - val_accuracy: 0.9333\n",
      "Epoch 245/1000\n",
      "120/120 [==============================] - 0s 295us/sample - loss: 0.5575 - accuracy: 0.9417 - val_loss: 0.5958 - val_accuracy: 0.9333\n",
      "Epoch 246/1000\n",
      "120/120 [==============================] - 0s 240us/sample - loss: 0.5562 - accuracy: 0.9417 - val_loss: 0.5946 - val_accuracy: 0.9333\n",
      "Epoch 247/1000\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.5550 - accuracy: 0.9417 - val_loss: 0.5933 - val_accuracy: 0.9333\n",
      "Epoch 248/1000\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 0.5538 - accuracy: 0.9417 - val_loss: 0.5919 - val_accuracy: 0.9333\n",
      "Epoch 249/1000\n",
      "120/120 [==============================] - 0s 295us/sample - loss: 0.5525 - accuracy: 0.9417 - val_loss: 0.5907 - val_accuracy: 0.9333\n",
      "Epoch 250/1000\n",
      "120/120 [==============================] - 0s 294us/sample - loss: 0.5513 - accuracy: 0.9417 - val_loss: 0.5894 - val_accuracy: 0.9000\n",
      "Epoch 251/1000\n",
      "120/120 [==============================] - 0s 236us/sample - loss: 0.5500 - accuracy: 0.9417 - val_loss: 0.5881 - val_accuracy: 0.9000\n",
      "Epoch 252/1000\n",
      "120/120 [==============================] - 0s 273us/sample - loss: 0.5489 - accuracy: 0.9417 - val_loss: 0.5867 - val_accuracy: 0.9000\n",
      "Epoch 253/1000\n",
      "120/120 [==============================] - 0s 257us/sample - loss: 0.5476 - accuracy: 0.9417 - val_loss: 0.5855 - val_accuracy: 0.9000\n",
      "Epoch 254/1000\n",
      "120/120 [==============================] - 0s 301us/sample - loss: 0.5464 - accuracy: 0.9333 - val_loss: 0.5841 - val_accuracy: 0.9000\n",
      "Epoch 255/1000\n",
      "120/120 [==============================] - 0s 230us/sample - loss: 0.5452 - accuracy: 0.9333 - val_loss: 0.5828 - val_accuracy: 0.9000\n",
      "Epoch 256/1000\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.5440 - accuracy: 0.9417 - val_loss: 0.5816 - val_accuracy: 0.9000\n",
      "Epoch 257/1000\n",
      "120/120 [==============================] - 0s 265us/sample - loss: 0.5428 - accuracy: 0.9500 - val_loss: 0.5803 - val_accuracy: 0.9000\n",
      "Epoch 258/1000\n",
      "120/120 [==============================] - 0s 237us/sample - loss: 0.5416 - accuracy: 0.9500 - val_loss: 0.5789 - val_accuracy: 0.9000\n",
      "Epoch 259/1000\n",
      "120/120 [==============================] - 0s 301us/sample - loss: 0.5404 - accuracy: 0.9500 - val_loss: 0.5776 - val_accuracy: 0.9000\n",
      "Epoch 260/1000\n",
      "120/120 [==============================] - 0s 243us/sample - loss: 0.5392 - accuracy: 0.9500 - val_loss: 0.5764 - val_accuracy: 0.9000\n",
      "Epoch 261/1000\n",
      "120/120 [==============================] - 0s 304us/sample - loss: 0.5380 - accuracy: 0.9417 - val_loss: 0.5751 - val_accuracy: 0.9000\n",
      "Epoch 262/1000\n",
      "120/120 [==============================] - 0s 270us/sample - loss: 0.5368 - accuracy: 0.9417 - val_loss: 0.5738 - val_accuracy: 0.9000\n",
      "Epoch 263/1000\n",
      "120/120 [==============================] - 0s 263us/sample - loss: 0.5356 - accuracy: 0.9417 - val_loss: 0.5725 - val_accuracy: 0.9000\n",
      "Epoch 264/1000\n",
      "120/120 [==============================] - 0s 231us/sample - loss: 0.5344 - accuracy: 0.9417 - val_loss: 0.5712 - val_accuracy: 0.9000\n",
      "Epoch 265/1000\n",
      "120/120 [==============================] - 0s 255us/sample - loss: 0.5333 - accuracy: 0.9500 - val_loss: 0.5699 - val_accuracy: 0.9000\n",
      "Epoch 266/1000\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 0.5321 - accuracy: 0.9500 - val_loss: 0.5686 - val_accuracy: 0.9000\n",
      "Epoch 267/1000\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.5309 - accuracy: 0.9500 - val_loss: 0.5673 - val_accuracy: 0.9000\n",
      "Epoch 268/1000\n",
      "120/120 [==============================] - 0s 236us/sample - loss: 0.5298 - accuracy: 0.9500 - val_loss: 0.5661 - val_accuracy: 0.9000\n",
      "Epoch 269/1000\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 0.5286 - accuracy: 0.9500 - val_loss: 0.5648 - val_accuracy: 0.9000\n",
      "Epoch 270/1000\n",
      "120/120 [==============================] - 0s 284us/sample - loss: 0.5274 - accuracy: 0.9500 - val_loss: 0.5636 - val_accuracy: 0.9000\n",
      "Epoch 271/1000\n",
      "120/120 [==============================] - 0s 293us/sample - loss: 0.5264 - accuracy: 0.9500 - val_loss: 0.5623 - val_accuracy: 0.9333\n",
      "Epoch 272/1000\n",
      "120/120 [==============================] - 0s 284us/sample - loss: 0.5251 - accuracy: 0.9500 - val_loss: 0.5611 - val_accuracy: 0.9333\n",
      "Epoch 273/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 385us/sample - loss: 0.5240 - accuracy: 0.9500 - val_loss: 0.5599 - val_accuracy: 0.9333\n",
      "Epoch 274/1000\n",
      "120/120 [==============================] - 0s 338us/sample - loss: 0.5228 - accuracy: 0.9500 - val_loss: 0.5587 - val_accuracy: 0.9333\n",
      "Epoch 275/1000\n",
      "120/120 [==============================] - 0s 359us/sample - loss: 0.5217 - accuracy: 0.9500 - val_loss: 0.5576 - val_accuracy: 0.9333\n",
      "Epoch 276/1000\n",
      "120/120 [==============================] - 0s 307us/sample - loss: 0.5206 - accuracy: 0.9500 - val_loss: 0.5563 - val_accuracy: 0.9333\n",
      "Epoch 277/1000\n",
      "120/120 [==============================] - 0s 280us/sample - loss: 0.5194 - accuracy: 0.9500 - val_loss: 0.5552 - val_accuracy: 0.9333\n",
      "Epoch 278/1000\n",
      "120/120 [==============================] - 0s 251us/sample - loss: 0.5183 - accuracy: 0.9500 - val_loss: 0.5540 - val_accuracy: 0.9333\n",
      "Epoch 279/1000\n",
      "120/120 [==============================] - 0s 294us/sample - loss: 0.5172 - accuracy: 0.9500 - val_loss: 0.5528 - val_accuracy: 0.9333\n",
      "Epoch 280/1000\n",
      "120/120 [==============================] - 0s 269us/sample - loss: 0.5161 - accuracy: 0.9500 - val_loss: 0.5517 - val_accuracy: 0.9333\n",
      "Epoch 281/1000\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.5150 - accuracy: 0.9500 - val_loss: 0.5505 - val_accuracy: 0.9333\n",
      "Epoch 282/1000\n",
      "120/120 [==============================] - 0s 260us/sample - loss: 0.5139 - accuracy: 0.9500 - val_loss: 0.5493 - val_accuracy: 0.9333\n",
      "Epoch 283/1000\n",
      "120/120 [==============================] - 0s 280us/sample - loss: 0.5127 - accuracy: 0.9500 - val_loss: 0.5481 - val_accuracy: 0.9333\n",
      "Epoch 284/1000\n",
      "120/120 [==============================] - 0s 259us/sample - loss: 0.5116 - accuracy: 0.9500 - val_loss: 0.5469 - val_accuracy: 0.9333\n",
      "Epoch 285/1000\n",
      "120/120 [==============================] - 0s 280us/sample - loss: 0.5105 - accuracy: 0.9500 - val_loss: 0.5457 - val_accuracy: 0.9333\n",
      "Epoch 286/1000\n",
      "120/120 [==============================] - 0s 312us/sample - loss: 0.5093 - accuracy: 0.9500 - val_loss: 0.5445 - val_accuracy: 0.9333\n",
      "Epoch 287/1000\n",
      "120/120 [==============================] - 0s 257us/sample - loss: 0.5082 - accuracy: 0.9500 - val_loss: 0.5434 - val_accuracy: 0.9000\n",
      "Epoch 288/1000\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.5071 - accuracy: 0.9500 - val_loss: 0.5422 - val_accuracy: 0.9000\n",
      "Epoch 289/1000\n",
      "120/120 [==============================] - 0s 301us/sample - loss: 0.5060 - accuracy: 0.9500 - val_loss: 0.5411 - val_accuracy: 0.9000\n",
      "Epoch 290/1000\n",
      "120/120 [==============================] - 0s 305us/sample - loss: 0.5049 - accuracy: 0.9500 - val_loss: 0.5399 - val_accuracy: 0.9000\n",
      "Epoch 291/1000\n",
      "120/120 [==============================] - 0s 254us/sample - loss: 0.5038 - accuracy: 0.9500 - val_loss: 0.5387 - val_accuracy: 0.9000\n",
      "Epoch 292/1000\n",
      "120/120 [==============================] - 0s 282us/sample - loss: 0.5027 - accuracy: 0.9500 - val_loss: 0.5375 - val_accuracy: 0.9000\n",
      "Epoch 293/1000\n",
      "120/120 [==============================] - 0s 377us/sample - loss: 0.5017 - accuracy: 0.9500 - val_loss: 0.5364 - val_accuracy: 0.9000\n",
      "Epoch 294/1000\n",
      "120/120 [==============================] - 0s 292us/sample - loss: 0.5006 - accuracy: 0.9500 - val_loss: 0.5353 - val_accuracy: 0.9000\n",
      "Epoch 295/1000\n",
      "120/120 [==============================] - 0s 223us/sample - loss: 0.4994 - accuracy: 0.9500 - val_loss: 0.5342 - val_accuracy: 0.9000\n",
      "Epoch 296/1000\n",
      "120/120 [==============================] - 0s 247us/sample - loss: 0.4984 - accuracy: 0.9500 - val_loss: 0.5332 - val_accuracy: 0.9000\n",
      "Epoch 297/1000\n",
      "120/120 [==============================] - 0s 268us/sample - loss: 0.4973 - accuracy: 0.9500 - val_loss: 0.5321 - val_accuracy: 0.9000\n",
      "Epoch 298/1000\n",
      "120/120 [==============================] - 0s 256us/sample - loss: 0.4963 - accuracy: 0.9500 - val_loss: 0.5310 - val_accuracy: 0.9000\n",
      "Epoch 299/1000\n",
      "120/120 [==============================] - 0s 265us/sample - loss: 0.4952 - accuracy: 0.9500 - val_loss: 0.5300 - val_accuracy: 0.9000\n",
      "Epoch 300/1000\n",
      "120/120 [==============================] - 0s 291us/sample - loss: 0.4941 - accuracy: 0.9500 - val_loss: 0.5289 - val_accuracy: 0.9000\n",
      "Epoch 301/1000\n",
      "120/120 [==============================] - 0s 276us/sample - loss: 0.4931 - accuracy: 0.9500 - val_loss: 0.5278 - val_accuracy: 0.9000\n",
      "Epoch 302/1000\n",
      "120/120 [==============================] - 0s 224us/sample - loss: 0.4920 - accuracy: 0.9500 - val_loss: 0.5267 - val_accuracy: 0.9000\n",
      "Epoch 303/1000\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.4910 - accuracy: 0.9500 - val_loss: 0.5256 - val_accuracy: 0.9000\n",
      "Epoch 304/1000\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 0.4899 - accuracy: 0.9500 - val_loss: 0.5245 - val_accuracy: 0.9000\n",
      "Epoch 305/1000\n",
      "120/120 [==============================] - 0s 289us/sample - loss: 0.4888 - accuracy: 0.9583 - val_loss: 0.5234 - val_accuracy: 0.9000\n",
      "Epoch 306/1000\n",
      "120/120 [==============================] - 0s 230us/sample - loss: 0.4878 - accuracy: 0.9500 - val_loss: 0.5224 - val_accuracy: 0.9000\n",
      "Epoch 307/1000\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.4867 - accuracy: 0.9500 - val_loss: 0.5213 - val_accuracy: 0.9000\n",
      "Epoch 308/1000\n",
      "120/120 [==============================] - 0s 248us/sample - loss: 0.4857 - accuracy: 0.9500 - val_loss: 0.5202 - val_accuracy: 0.9000\n",
      "Epoch 309/1000\n",
      "120/120 [==============================] - 0s 319us/sample - loss: 0.4847 - accuracy: 0.9500 - val_loss: 0.5192 - val_accuracy: 0.9000\n",
      "Epoch 310/1000\n",
      "120/120 [==============================] - 0s 296us/sample - loss: 0.4836 - accuracy: 0.9500 - val_loss: 0.5181 - val_accuracy: 0.9000\n",
      "Epoch 311/1000\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.4826 - accuracy: 0.9500 - val_loss: 0.5171 - val_accuracy: 0.9000\n",
      "Epoch 312/1000\n",
      "120/120 [==============================] - 0s 253us/sample - loss: 0.4817 - accuracy: 0.9500 - val_loss: 0.5161 - val_accuracy: 0.9000\n",
      "Epoch 313/1000\n",
      "120/120 [==============================] - 0s 322us/sample - loss: 0.4806 - accuracy: 0.9500 - val_loss: 0.5150 - val_accuracy: 0.9000\n",
      "Epoch 314/1000\n",
      "120/120 [==============================] - 0s 221us/sample - loss: 0.4796 - accuracy: 0.9500 - val_loss: 0.5139 - val_accuracy: 0.9000\n",
      "Epoch 315/1000\n",
      "120/120 [==============================] - 0s 244us/sample - loss: 0.4786 - accuracy: 0.9500 - val_loss: 0.5128 - val_accuracy: 0.9000\n",
      "Epoch 316/1000\n",
      "120/120 [==============================] - 0s 320us/sample - loss: 0.4775 - accuracy: 0.9500 - val_loss: 0.5117 - val_accuracy: 0.9000\n",
      "Epoch 317/1000\n",
      "120/120 [==============================] - 0s 213us/sample - loss: 0.4766 - accuracy: 0.9500 - val_loss: 0.5106 - val_accuracy: 0.9000\n",
      "Epoch 318/1000\n",
      "120/120 [==============================] - 0s 272us/sample - loss: 0.4756 - accuracy: 0.9583 - val_loss: 0.5095 - val_accuracy: 0.9000\n",
      "Epoch 319/1000\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.4746 - accuracy: 0.9583 - val_loss: 0.5085 - val_accuracy: 0.9000\n",
      "Epoch 320/1000\n",
      "120/120 [==============================] - 0s 337us/sample - loss: 0.4735 - accuracy: 0.9583 - val_loss: 0.5074 - val_accuracy: 0.9000\n",
      "Epoch 321/1000\n",
      "120/120 [==============================] - 0s 243us/sample - loss: 0.4725 - accuracy: 0.9583 - val_loss: 0.5064 - val_accuracy: 0.9000\n",
      "Epoch 322/1000\n",
      "120/120 [==============================] - 0s 259us/sample - loss: 0.4716 - accuracy: 0.9583 - val_loss: 0.5053 - val_accuracy: 0.9000\n",
      "Epoch 323/1000\n",
      "120/120 [==============================] - 0s 238us/sample - loss: 0.4705 - accuracy: 0.9583 - val_loss: 0.5042 - val_accuracy: 0.9000\n",
      "Epoch 324/1000\n",
      "120/120 [==============================] - 0s 307us/sample - loss: 0.4696 - accuracy: 0.9583 - val_loss: 0.5031 - val_accuracy: 0.9000\n",
      "Epoch 325/1000\n",
      "120/120 [==============================] - 0s 232us/sample - loss: 0.4686 - accuracy: 0.9583 - val_loss: 0.5021 - val_accuracy: 0.9000\n",
      "Epoch 326/1000\n",
      "120/120 [==============================] - 0s 288us/sample - loss: 0.4676 - accuracy: 0.9583 - val_loss: 0.5011 - val_accuracy: 0.9000\n",
      "Epoch 327/1000\n",
      "120/120 [==============================] - 0s 236us/sample - loss: 0.4666 - accuracy: 0.9583 - val_loss: 0.5001 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 328/1000\n",
      "120/120 [==============================] - 0s 295us/sample - loss: 0.4656 - accuracy: 0.9583 - val_loss: 0.4991 - val_accuracy: 0.9000\n",
      "Epoch 329/1000\n",
      "120/120 [==============================] - 0s 284us/sample - loss: 0.4646 - accuracy: 0.9583 - val_loss: 0.4980 - val_accuracy: 0.9000\n",
      "Epoch 330/1000\n",
      "120/120 [==============================] - 0s 281us/sample - loss: 0.4637 - accuracy: 0.9583 - val_loss: 0.4970 - val_accuracy: 0.9000\n",
      "Epoch 331/1000\n",
      "120/120 [==============================] - 0s 218us/sample - loss: 0.4628 - accuracy: 0.9583 - val_loss: 0.4959 - val_accuracy: 0.9000\n",
      "Epoch 332/1000\n",
      "120/120 [==============================] - 0s 277us/sample - loss: 0.4618 - accuracy: 0.9500 - val_loss: 0.4950 - val_accuracy: 0.9000\n",
      "Epoch 333/1000\n",
      "120/120 [==============================] - 0s 335us/sample - loss: 0.4608 - accuracy: 0.9500 - val_loss: 0.4940 - val_accuracy: 0.9000\n",
      "Epoch 334/1000\n",
      "120/120 [==============================] - 0s 247us/sample - loss: 0.4597 - accuracy: 0.9500 - val_loss: 0.4930 - val_accuracy: 0.9000\n",
      "Epoch 335/1000\n",
      "120/120 [==============================] - 0s 248us/sample - loss: 0.4588 - accuracy: 0.9500 - val_loss: 0.4919 - val_accuracy: 0.9000\n",
      "Epoch 336/1000\n",
      "120/120 [==============================] - 0s 259us/sample - loss: 0.4578 - accuracy: 0.9583 - val_loss: 0.4908 - val_accuracy: 0.9000\n",
      "Epoch 337/1000\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.4569 - accuracy: 0.9583 - val_loss: 0.4898 - val_accuracy: 0.9000\n",
      "Epoch 338/1000\n",
      "120/120 [==============================] - 0s 273us/sample - loss: 0.4559 - accuracy: 0.9583 - val_loss: 0.4888 - val_accuracy: 0.9000\n",
      "Epoch 339/1000\n",
      "120/120 [==============================] - 0s 270us/sample - loss: 0.4549 - accuracy: 0.9583 - val_loss: 0.4877 - val_accuracy: 0.9000\n",
      "Epoch 340/1000\n",
      "120/120 [==============================] - 0s 288us/sample - loss: 0.4540 - accuracy: 0.9583 - val_loss: 0.4867 - val_accuracy: 0.9000\n",
      "Epoch 341/1000\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 0.4530 - accuracy: 0.9583 - val_loss: 0.4857 - val_accuracy: 0.9000\n",
      "Epoch 342/1000\n",
      "120/120 [==============================] - 0s 281us/sample - loss: 0.4520 - accuracy: 0.9583 - val_loss: 0.4846 - val_accuracy: 0.9000\n",
      "Epoch 343/1000\n",
      "120/120 [==============================] - 0s 268us/sample - loss: 0.4512 - accuracy: 0.9583 - val_loss: 0.4836 - val_accuracy: 0.9000\n",
      "Epoch 344/1000\n",
      "120/120 [==============================] - 0s 310us/sample - loss: 0.4501 - accuracy: 0.9583 - val_loss: 0.4825 - val_accuracy: 0.9000\n",
      "Epoch 345/1000\n",
      "120/120 [==============================] - 0s 269us/sample - loss: 0.4491 - accuracy: 0.9583 - val_loss: 0.4816 - val_accuracy: 0.9000\n",
      "Epoch 346/1000\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.4482 - accuracy: 0.9583 - val_loss: 0.4806 - val_accuracy: 0.9000\n",
      "Epoch 347/1000\n",
      "120/120 [==============================] - 0s 273us/sample - loss: 0.4473 - accuracy: 0.9583 - val_loss: 0.4796 - val_accuracy: 0.9000\n",
      "Epoch 348/1000\n",
      "120/120 [==============================] - 0s 373us/sample - loss: 0.4464 - accuracy: 0.9583 - val_loss: 0.4785 - val_accuracy: 0.9000\n",
      "Epoch 349/1000\n",
      "120/120 [==============================] - 0s 261us/sample - loss: 0.4453 - accuracy: 0.9667 - val_loss: 0.4776 - val_accuracy: 0.9000\n",
      "Epoch 350/1000\n",
      "120/120 [==============================] - 0s 247us/sample - loss: 0.4444 - accuracy: 0.9667 - val_loss: 0.4767 - val_accuracy: 0.9000\n",
      "Epoch 351/1000\n",
      "120/120 [==============================] - 0s 269us/sample - loss: 0.4435 - accuracy: 0.9667 - val_loss: 0.4756 - val_accuracy: 0.9000\n",
      "Epoch 352/1000\n",
      "120/120 [==============================] - 0s 310us/sample - loss: 0.4425 - accuracy: 0.9667 - val_loss: 0.4747 - val_accuracy: 0.9000\n",
      "Epoch 353/1000\n",
      "120/120 [==============================] - 0s 265us/sample - loss: 0.4416 - accuracy: 0.9667 - val_loss: 0.4737 - val_accuracy: 0.9000\n",
      "Epoch 354/1000\n",
      "120/120 [==============================] - 0s 287us/sample - loss: 0.4407 - accuracy: 0.9667 - val_loss: 0.4727 - val_accuracy: 0.9000\n",
      "Epoch 355/1000\n",
      "120/120 [==============================] - 0s 257us/sample - loss: 0.4396 - accuracy: 0.9667 - val_loss: 0.4718 - val_accuracy: 0.9000\n",
      "Epoch 356/1000\n",
      "120/120 [==============================] - 0s 277us/sample - loss: 0.4387 - accuracy: 0.9667 - val_loss: 0.4708 - val_accuracy: 0.9000\n",
      "Epoch 357/1000\n",
      "120/120 [==============================] - 0s 280us/sample - loss: 0.4378 - accuracy: 0.9667 - val_loss: 0.4699 - val_accuracy: 0.9000\n",
      "Epoch 358/1000\n",
      "120/120 [==============================] - 0s 296us/sample - loss: 0.4368 - accuracy: 0.9667 - val_loss: 0.4689 - val_accuracy: 0.9000\n",
      "Epoch 359/1000\n",
      "120/120 [==============================] - 0s 279us/sample - loss: 0.4359 - accuracy: 0.9667 - val_loss: 0.4680 - val_accuracy: 0.9000\n",
      "Epoch 360/1000\n",
      "120/120 [==============================] - 0s 265us/sample - loss: 0.4349 - accuracy: 0.9667 - val_loss: 0.4671 - val_accuracy: 0.9000\n",
      "Epoch 361/1000\n",
      "120/120 [==============================] - 0s 261us/sample - loss: 0.4340 - accuracy: 0.9667 - val_loss: 0.4662 - val_accuracy: 0.9000\n",
      "Epoch 362/1000\n",
      "120/120 [==============================] - 0s 257us/sample - loss: 0.4332 - accuracy: 0.9667 - val_loss: 0.4652 - val_accuracy: 0.9000\n",
      "Epoch 363/1000\n",
      "120/120 [==============================] - 0s 269us/sample - loss: 0.4322 - accuracy: 0.9667 - val_loss: 0.4643 - val_accuracy: 0.9000\n",
      "Epoch 364/1000\n",
      "120/120 [==============================] - 0s 273us/sample - loss: 0.4313 - accuracy: 0.9667 - val_loss: 0.4634 - val_accuracy: 0.9000\n",
      "Epoch 365/1000\n",
      "120/120 [==============================] - 0s 279us/sample - loss: 0.4303 - accuracy: 0.9667 - val_loss: 0.4624 - val_accuracy: 0.9000\n",
      "Epoch 366/1000\n",
      "120/120 [==============================] - 0s 282us/sample - loss: 0.4294 - accuracy: 0.9667 - val_loss: 0.4615 - val_accuracy: 0.9000\n",
      "Epoch 367/1000\n",
      "120/120 [==============================] - 0s 279us/sample - loss: 0.4285 - accuracy: 0.9667 - val_loss: 0.4606 - val_accuracy: 0.9000\n",
      "Epoch 368/1000\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.4275 - accuracy: 0.9667 - val_loss: 0.4597 - val_accuracy: 0.9000\n",
      "Epoch 369/1000\n",
      "120/120 [==============================] - 0s 299us/sample - loss: 0.4266 - accuracy: 0.9667 - val_loss: 0.4587 - val_accuracy: 0.9000\n",
      "Epoch 370/1000\n",
      "120/120 [==============================] - 0s 220us/sample - loss: 0.4257 - accuracy: 0.9667 - val_loss: 0.4578 - val_accuracy: 0.9000\n",
      "Epoch 371/1000\n",
      "120/120 [==============================] - 0s 273us/sample - loss: 0.4247 - accuracy: 0.9667 - val_loss: 0.4569 - val_accuracy: 0.9000\n",
      "Epoch 372/1000\n",
      "120/120 [==============================] - 0s 318us/sample - loss: 0.4238 - accuracy: 0.9667 - val_loss: 0.4560 - val_accuracy: 0.9000\n",
      "Epoch 373/1000\n",
      "120/120 [==============================] - 0s 216us/sample - loss: 0.4229 - accuracy: 0.9667 - val_loss: 0.4551 - val_accuracy: 0.9000\n",
      "Epoch 374/1000\n",
      "120/120 [==============================] - 0s 290us/sample - loss: 0.4221 - accuracy: 0.9667 - val_loss: 0.4542 - val_accuracy: 0.9000\n",
      "Epoch 375/1000\n",
      "120/120 [==============================] - 0s 257us/sample - loss: 0.4211 - accuracy: 0.9667 - val_loss: 0.4533 - val_accuracy: 0.9000\n",
      "Epoch 376/1000\n",
      "120/120 [==============================] - 0s 230us/sample - loss: 0.4203 - accuracy: 0.9667 - val_loss: 0.4525 - val_accuracy: 0.9000\n",
      "Epoch 377/1000\n",
      "120/120 [==============================] - 0s 349us/sample - loss: 0.4192 - accuracy: 0.9667 - val_loss: 0.4516 - val_accuracy: 0.9000\n",
      "Epoch 378/1000\n",
      "120/120 [==============================] - 0s 247us/sample - loss: 0.4185 - accuracy: 0.9667 - val_loss: 0.4507 - val_accuracy: 0.9000\n",
      "Epoch 379/1000\n",
      "120/120 [==============================] - 0s 270us/sample - loss: 0.4174 - accuracy: 0.9667 - val_loss: 0.4498 - val_accuracy: 0.9000\n",
      "Epoch 380/1000\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.4165 - accuracy: 0.9667 - val_loss: 0.4489 - val_accuracy: 0.9000\n",
      "Epoch 381/1000\n",
      "120/120 [==============================] - 0s 257us/sample - loss: 0.4156 - accuracy: 0.9667 - val_loss: 0.4480 - val_accuracy: 0.9000\n",
      "Epoch 382/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 298us/sample - loss: 0.4147 - accuracy: 0.9667 - val_loss: 0.4471 - val_accuracy: 0.9000\n",
      "Epoch 383/1000\n",
      "120/120 [==============================] - 0s 252us/sample - loss: 0.4139 - accuracy: 0.9667 - val_loss: 0.4463 - val_accuracy: 0.9000\n",
      "Epoch 384/1000\n",
      "120/120 [==============================] - 0s 254us/sample - loss: 0.4129 - accuracy: 0.9667 - val_loss: 0.4454 - val_accuracy: 0.9000\n",
      "Epoch 385/1000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.4079 - accuracy: 1.00 - 0s 248us/sample - loss: 0.4120 - accuracy: 0.9667 - val_loss: 0.4445 - val_accuracy: 0.9000\n",
      "Epoch 386/1000\n",
      "120/120 [==============================] - 0s 299us/sample - loss: 0.4111 - accuracy: 0.9667 - val_loss: 0.4437 - val_accuracy: 0.9000\n",
      "Epoch 387/1000\n",
      "120/120 [==============================] - 0s 294us/sample - loss: 0.4102 - accuracy: 0.9667 - val_loss: 0.4428 - val_accuracy: 0.9000\n",
      "Epoch 388/1000\n",
      "120/120 [==============================] - 0s 244us/sample - loss: 0.4093 - accuracy: 0.9667 - val_loss: 0.4420 - val_accuracy: 0.9000\n",
      "Epoch 389/1000\n",
      "120/120 [==============================] - 0s 276us/sample - loss: 0.4084 - accuracy: 0.9667 - val_loss: 0.4412 - val_accuracy: 0.9000\n",
      "Epoch 390/1000\n",
      "120/120 [==============================] - 0s 264us/sample - loss: 0.4076 - accuracy: 0.9667 - val_loss: 0.4403 - val_accuracy: 0.9000\n",
      "Epoch 391/1000\n",
      "120/120 [==============================] - 0s 264us/sample - loss: 0.4068 - accuracy: 0.9750 - val_loss: 0.4393 - val_accuracy: 0.9000\n",
      "Epoch 392/1000\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.4058 - accuracy: 0.9667 - val_loss: 0.4384 - val_accuracy: 0.9000\n",
      "Epoch 393/1000\n",
      "120/120 [==============================] - 0s 284us/sample - loss: 0.4049 - accuracy: 0.9667 - val_loss: 0.4375 - val_accuracy: 0.9000\n",
      "Epoch 394/1000\n",
      "120/120 [==============================] - 0s 280us/sample - loss: 0.4040 - accuracy: 0.9667 - val_loss: 0.4366 - val_accuracy: 0.9000\n",
      "Epoch 395/1000\n",
      "120/120 [==============================] - 0s 254us/sample - loss: 0.4032 - accuracy: 0.9667 - val_loss: 0.4357 - val_accuracy: 0.9000\n",
      "Epoch 396/1000\n",
      "120/120 [==============================] - 0s 265us/sample - loss: 0.4024 - accuracy: 0.9667 - val_loss: 0.4348 - val_accuracy: 0.9000\n",
      "Epoch 397/1000\n",
      "120/120 [==============================] - 0s 251us/sample - loss: 0.4015 - accuracy: 0.9667 - val_loss: 0.4339 - val_accuracy: 0.9000\n",
      "Epoch 398/1000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.3515 - accuracy: 1.00 - 0s 282us/sample - loss: 0.4005 - accuracy: 0.9667 - val_loss: 0.4331 - val_accuracy: 0.9000\n",
      "Epoch 399/1000\n",
      "120/120 [==============================] - 0s 273us/sample - loss: 0.3998 - accuracy: 0.9667 - val_loss: 0.4322 - val_accuracy: 0.9000\n",
      "Epoch 400/1000\n",
      "120/120 [==============================] - 0s 238us/sample - loss: 0.3989 - accuracy: 0.9667 - val_loss: 0.4314 - val_accuracy: 0.9000\n",
      "Epoch 401/1000\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 0.3981 - accuracy: 0.9667 - val_loss: 0.4306 - val_accuracy: 0.9000\n",
      "Epoch 402/1000\n",
      "120/120 [==============================] - 0s 245us/sample - loss: 0.3971 - accuracy: 0.9667 - val_loss: 0.4297 - val_accuracy: 0.9000\n",
      "Epoch 403/1000\n",
      "120/120 [==============================] - 0s 281us/sample - loss: 0.3963 - accuracy: 0.9667 - val_loss: 0.4289 - val_accuracy: 0.9000\n",
      "Epoch 404/1000\n",
      "120/120 [==============================] - 0s 255us/sample - loss: 0.3954 - accuracy: 0.9667 - val_loss: 0.4280 - val_accuracy: 0.9000\n",
      "Epoch 405/1000\n",
      "120/120 [==============================] - 0s 277us/sample - loss: 0.3946 - accuracy: 0.9667 - val_loss: 0.4272 - val_accuracy: 0.9000\n",
      "Epoch 406/1000\n",
      "120/120 [==============================] - 0s 272us/sample - loss: 0.3938 - accuracy: 0.9667 - val_loss: 0.4263 - val_accuracy: 0.9000\n",
      "Epoch 407/1000\n",
      "120/120 [==============================] - 0s 289us/sample - loss: 0.3930 - accuracy: 0.9667 - val_loss: 0.4255 - val_accuracy: 0.9000\n",
      "Epoch 408/1000\n",
      "120/120 [==============================] - 0s 280us/sample - loss: 0.3921 - accuracy: 0.9667 - val_loss: 0.4246 - val_accuracy: 0.9000\n",
      "Epoch 409/1000\n",
      "120/120 [==============================] - 0s 276us/sample - loss: 0.3913 - accuracy: 0.9667 - val_loss: 0.4238 - val_accuracy: 0.9000\n",
      "Epoch 410/1000\n",
      "120/120 [==============================] - 0s 218us/sample - loss: 0.3905 - accuracy: 0.9667 - val_loss: 0.4229 - val_accuracy: 0.9000\n",
      "Epoch 411/1000\n",
      "120/120 [==============================] - 0s 277us/sample - loss: 0.3896 - accuracy: 0.9667 - val_loss: 0.4221 - val_accuracy: 0.9000\n",
      "Epoch 412/1000\n",
      "120/120 [==============================] - 0s 292us/sample - loss: 0.3888 - accuracy: 0.9667 - val_loss: 0.4213 - val_accuracy: 0.9000\n",
      "Epoch 413/1000\n",
      "120/120 [==============================] - 0s 234us/sample - loss: 0.3880 - accuracy: 0.9667 - val_loss: 0.4205 - val_accuracy: 0.9000\n",
      "Epoch 414/1000\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 0.3872 - accuracy: 0.9667 - val_loss: 0.4196 - val_accuracy: 0.9000\n",
      "Epoch 415/1000\n",
      "120/120 [==============================] - 0s 279us/sample - loss: 0.3863 - accuracy: 0.9667 - val_loss: 0.4188 - val_accuracy: 0.9000\n",
      "Epoch 416/1000\n",
      "120/120 [==============================] - 0s 235us/sample - loss: 0.3855 - accuracy: 0.9667 - val_loss: 0.4180 - val_accuracy: 0.9000\n",
      "Epoch 417/1000\n",
      "120/120 [==============================] - 0s 284us/sample - loss: 0.3847 - accuracy: 0.9667 - val_loss: 0.4172 - val_accuracy: 0.9000\n",
      "Epoch 418/1000\n",
      "120/120 [==============================] - 0s 292us/sample - loss: 0.3839 - accuracy: 0.9750 - val_loss: 0.4163 - val_accuracy: 0.9000\n",
      "Epoch 419/1000\n",
      "120/120 [==============================] - 0s 240us/sample - loss: 0.3830 - accuracy: 0.9667 - val_loss: 0.4155 - val_accuracy: 0.9000\n",
      "Epoch 420/1000\n",
      "120/120 [==============================] - 0s 271us/sample - loss: 0.3823 - accuracy: 0.9667 - val_loss: 0.4147 - val_accuracy: 0.9000\n",
      "Epoch 421/1000\n",
      "120/120 [==============================] - 0s 238us/sample - loss: 0.3814 - accuracy: 0.9667 - val_loss: 0.4138 - val_accuracy: 0.9000\n",
      "Epoch 422/1000\n",
      "120/120 [==============================] - 0s 295us/sample - loss: 0.3806 - accuracy: 0.9667 - val_loss: 0.4130 - val_accuracy: 0.9000\n",
      "Epoch 423/1000\n",
      "120/120 [==============================] - 0s 231us/sample - loss: 0.3799 - accuracy: 0.9667 - val_loss: 0.4121 - val_accuracy: 0.9000\n",
      "Epoch 424/1000\n",
      "120/120 [==============================] - 0s 277us/sample - loss: 0.3791 - accuracy: 0.9667 - val_loss: 0.4114 - val_accuracy: 0.9000\n",
      "Epoch 425/1000\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.3782 - accuracy: 0.9667 - val_loss: 0.4105 - val_accuracy: 0.9000\n",
      "Epoch 426/1000\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.3775 - accuracy: 0.9667 - val_loss: 0.4097 - val_accuracy: 0.9000\n",
      "Epoch 427/1000\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.3766 - accuracy: 0.9667 - val_loss: 0.4089 - val_accuracy: 0.9000\n",
      "Epoch 428/1000\n",
      "120/120 [==============================] - 0s 308us/sample - loss: 0.3758 - accuracy: 0.9667 - val_loss: 0.4081 - val_accuracy: 0.9000\n",
      "Epoch 429/1000\n",
      "120/120 [==============================] - 0s 284us/sample - loss: 0.3750 - accuracy: 0.9667 - val_loss: 0.4073 - val_accuracy: 0.9000\n",
      "Epoch 430/1000\n",
      "120/120 [==============================] - 0s 282us/sample - loss: 0.3743 - accuracy: 0.9667 - val_loss: 0.4065 - val_accuracy: 0.9000\n",
      "Epoch 431/1000\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.3734 - accuracy: 0.9667 - val_loss: 0.4057 - val_accuracy: 0.9000\n",
      "Epoch 432/1000\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.3726 - accuracy: 0.9667 - val_loss: 0.4049 - val_accuracy: 0.9000\n",
      "Epoch 433/1000\n",
      "120/120 [==============================] - 0s 228us/sample - loss: 0.3719 - accuracy: 0.9667 - val_loss: 0.4041 - val_accuracy: 0.9000\n",
      "Epoch 434/1000\n",
      "120/120 [==============================] - 0s 322us/sample - loss: 0.3711 - accuracy: 0.9750 - val_loss: 0.4033 - val_accuracy: 0.9000\n",
      "Epoch 435/1000\n",
      "120/120 [==============================] - 0s 230us/sample - loss: 0.3703 - accuracy: 0.9750 - val_loss: 0.4025 - val_accuracy: 0.9000\n",
      "Epoch 436/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 270us/sample - loss: 0.3696 - accuracy: 0.9667 - val_loss: 0.4017 - val_accuracy: 0.9000\n",
      "Epoch 437/1000\n",
      "120/120 [==============================] - 0s 307us/sample - loss: 0.3688 - accuracy: 0.9667 - val_loss: 0.4009 - val_accuracy: 0.9000\n",
      "Epoch 438/1000\n",
      "120/120 [==============================] - 0s 271us/sample - loss: 0.3680 - accuracy: 0.9667 - val_loss: 0.4001 - val_accuracy: 0.9000\n",
      "Epoch 439/1000\n",
      "120/120 [==============================] - 0s 281us/sample - loss: 0.3672 - accuracy: 0.9667 - val_loss: 0.3994 - val_accuracy: 0.9000\n",
      "Epoch 440/1000\n",
      "120/120 [==============================] - 0s 290us/sample - loss: 0.3665 - accuracy: 0.9667 - val_loss: 0.3986 - val_accuracy: 0.9000\n",
      "Epoch 441/1000\n",
      "120/120 [==============================] - 0s 253us/sample - loss: 0.3657 - accuracy: 0.9667 - val_loss: 0.3978 - val_accuracy: 0.9000\n",
      "Epoch 442/1000\n",
      "120/120 [==============================] - 0s 254us/sample - loss: 0.3649 - accuracy: 0.9667 - val_loss: 0.3970 - val_accuracy: 0.9000\n",
      "Epoch 443/1000\n",
      "120/120 [==============================] - 0s 251us/sample - loss: 0.3642 - accuracy: 0.9750 - val_loss: 0.3962 - val_accuracy: 0.9000\n",
      "Epoch 444/1000\n",
      "120/120 [==============================] - 0s 252us/sample - loss: 0.3634 - accuracy: 0.9750 - val_loss: 0.3954 - val_accuracy: 0.9000\n",
      "Epoch 445/1000\n",
      "120/120 [==============================] - 0s 295us/sample - loss: 0.3626 - accuracy: 0.9750 - val_loss: 0.3946 - val_accuracy: 0.9000\n",
      "Epoch 446/1000\n",
      "120/120 [==============================] - 0s 302us/sample - loss: 0.3618 - accuracy: 0.9750 - val_loss: 0.3938 - val_accuracy: 0.9000\n",
      "Epoch 447/1000\n",
      "120/120 [==============================] - 0s 262us/sample - loss: 0.3611 - accuracy: 0.9750 - val_loss: 0.3931 - val_accuracy: 0.9000\n",
      "Epoch 448/1000\n",
      "120/120 [==============================] - 0s 299us/sample - loss: 0.3603 - accuracy: 0.9750 - val_loss: 0.3923 - val_accuracy: 0.9000\n",
      "Epoch 449/1000\n",
      "120/120 [==============================] - 0s 268us/sample - loss: 0.3596 - accuracy: 0.9750 - val_loss: 0.3916 - val_accuracy: 0.9000\n",
      "Epoch 450/1000\n",
      "120/120 [==============================] - 0s 285us/sample - loss: 0.3588 - accuracy: 0.9750 - val_loss: 0.3908 - val_accuracy: 0.9000\n",
      "Epoch 451/1000\n",
      "120/120 [==============================] - 0s 278us/sample - loss: 0.3581 - accuracy: 0.9750 - val_loss: 0.3901 - val_accuracy: 0.9000\n",
      "Epoch 452/1000\n",
      "120/120 [==============================] - 0s 330us/sample - loss: 0.3573 - accuracy: 0.9750 - val_loss: 0.3893 - val_accuracy: 0.9000\n",
      "Epoch 453/1000\n",
      "120/120 [==============================] - 0s 290us/sample - loss: 0.3566 - accuracy: 0.9750 - val_loss: 0.3886 - val_accuracy: 0.9000\n",
      "Epoch 454/1000\n",
      "120/120 [==============================] - 0s 330us/sample - loss: 0.3559 - accuracy: 0.9833 - val_loss: 0.3879 - val_accuracy: 0.9000\n",
      "Epoch 455/1000\n",
      "120/120 [==============================] - 0s 296us/sample - loss: 0.3551 - accuracy: 0.9833 - val_loss: 0.3871 - val_accuracy: 0.9000\n",
      "Epoch 456/1000\n",
      "120/120 [==============================] - 0s 342us/sample - loss: 0.3544 - accuracy: 0.9833 - val_loss: 0.3864 - val_accuracy: 0.9000\n",
      "Epoch 457/1000\n",
      "120/120 [==============================] - 0s 331us/sample - loss: 0.3536 - accuracy: 0.9833 - val_loss: 0.3856 - val_accuracy: 0.9000\n",
      "Epoch 458/1000\n",
      "120/120 [==============================] - 0s 332us/sample - loss: 0.3529 - accuracy: 0.9833 - val_loss: 0.3848 - val_accuracy: 0.9000\n",
      "Epoch 459/1000\n",
      "120/120 [==============================] - 0s 246us/sample - loss: 0.3522 - accuracy: 0.9833 - val_loss: 0.3841 - val_accuracy: 0.9000\n",
      "Epoch 460/1000\n",
      "120/120 [==============================] - 0s 312us/sample - loss: 0.3514 - accuracy: 0.9833 - val_loss: 0.3834 - val_accuracy: 0.9000\n",
      "Epoch 461/1000\n",
      "120/120 [==============================] - 0s 316us/sample - loss: 0.3507 - accuracy: 0.9833 - val_loss: 0.3826 - val_accuracy: 0.9000\n",
      "Epoch 462/1000\n",
      "120/120 [==============================] - 0s 335us/sample - loss: 0.3499 - accuracy: 0.9833 - val_loss: 0.3819 - val_accuracy: 0.9000\n",
      "Epoch 463/1000\n",
      "120/120 [==============================] - 0s 458us/sample - loss: 0.3492 - accuracy: 0.9833 - val_loss: 0.3812 - val_accuracy: 0.9000\n",
      "Epoch 464/1000\n",
      "120/120 [==============================] - 0s 282us/sample - loss: 0.3485 - accuracy: 0.9833 - val_loss: 0.3804 - val_accuracy: 0.9000\n",
      "Epoch 465/1000\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.3478 - accuracy: 0.9833 - val_loss: 0.3797 - val_accuracy: 0.9000\n",
      "Epoch 466/1000\n",
      "120/120 [==============================] - 0s 322us/sample - loss: 0.3471 - accuracy: 0.9833 - val_loss: 0.3789 - val_accuracy: 0.9000\n",
      "Epoch 467/1000\n",
      "120/120 [==============================] - 0s 326us/sample - loss: 0.3463 - accuracy: 0.9750 - val_loss: 0.3782 - val_accuracy: 0.9000\n",
      "Epoch 468/1000\n",
      "120/120 [==============================] - 0s 310us/sample - loss: 0.3456 - accuracy: 0.9750 - val_loss: 0.3774 - val_accuracy: 0.9000\n",
      "Epoch 469/1000\n",
      "120/120 [==============================] - 0s 369us/sample - loss: 0.3449 - accuracy: 0.9750 - val_loss: 0.3767 - val_accuracy: 0.9000\n",
      "Epoch 470/1000\n",
      "120/120 [==============================] - 0s 399us/sample - loss: 0.3442 - accuracy: 0.9750 - val_loss: 0.3760 - val_accuracy: 0.9000\n",
      "Epoch 471/1000\n",
      "120/120 [==============================] - 0s 316us/sample - loss: 0.3435 - accuracy: 0.9750 - val_loss: 0.3753 - val_accuracy: 0.9000\n",
      "Epoch 472/1000\n",
      "120/120 [==============================] - 0s 350us/sample - loss: 0.3429 - accuracy: 0.9750 - val_loss: 0.3746 - val_accuracy: 0.9000\n",
      "Epoch 473/1000\n",
      "120/120 [==============================] - 0s 281us/sample - loss: 0.3420 - accuracy: 0.9750 - val_loss: 0.3739 - val_accuracy: 0.9000\n",
      "Epoch 474/1000\n",
      "120/120 [==============================] - 0s 342us/sample - loss: 0.3413 - accuracy: 0.9750 - val_loss: 0.3732 - val_accuracy: 0.9000\n",
      "Epoch 475/1000\n",
      "120/120 [==============================] - 0s 319us/sample - loss: 0.3407 - accuracy: 0.9750 - val_loss: 0.3725 - val_accuracy: 0.9000\n",
      "Epoch 476/1000\n",
      "120/120 [==============================] - 0s 378us/sample - loss: 0.3399 - accuracy: 0.9750 - val_loss: 0.3718 - val_accuracy: 0.9000\n",
      "Epoch 477/1000\n",
      "120/120 [==============================] - 0s 385us/sample - loss: 0.3392 - accuracy: 0.9750 - val_loss: 0.3711 - val_accuracy: 0.9000\n",
      "Epoch 478/1000\n",
      "120/120 [==============================] - 0s 290us/sample - loss: 0.3385 - accuracy: 0.9750 - val_loss: 0.3704 - val_accuracy: 0.9000\n",
      "Epoch 479/1000\n",
      "120/120 [==============================] - 0s 362us/sample - loss: 0.3378 - accuracy: 0.9750 - val_loss: 0.3697 - val_accuracy: 0.9000\n",
      "Epoch 480/1000\n",
      "120/120 [==============================] - 0s 308us/sample - loss: 0.3371 - accuracy: 0.9750 - val_loss: 0.3691 - val_accuracy: 0.9000\n",
      "Epoch 481/1000\n",
      "120/120 [==============================] - 0s 296us/sample - loss: 0.3364 - accuracy: 0.9833 - val_loss: 0.3684 - val_accuracy: 0.9000\n",
      "Epoch 482/1000\n",
      "120/120 [==============================] - 0s 255us/sample - loss: 0.3357 - accuracy: 0.9833 - val_loss: 0.3677 - val_accuracy: 0.9000\n",
      "Epoch 483/1000\n",
      "120/120 [==============================] - 0s 375us/sample - loss: 0.3350 - accuracy: 0.9833 - val_loss: 0.3670 - val_accuracy: 0.9000\n",
      "Epoch 484/1000\n",
      "120/120 [==============================] - 0s 265us/sample - loss: 0.3344 - accuracy: 0.9833 - val_loss: 0.3663 - val_accuracy: 0.9000\n",
      "Epoch 485/1000\n",
      "120/120 [==============================] - 0s 411us/sample - loss: 0.3336 - accuracy: 0.9833 - val_loss: 0.3656 - val_accuracy: 0.9000\n",
      "Epoch 486/1000\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.3329 - accuracy: 0.9833 - val_loss: 0.3649 - val_accuracy: 0.9000\n",
      "Epoch 487/1000\n",
      "120/120 [==============================] - 0s 259us/sample - loss: 0.3322 - accuracy: 0.9833 - val_loss: 0.3642 - val_accuracy: 0.9000\n",
      "Epoch 488/1000\n",
      "120/120 [==============================] - 0s 336us/sample - loss: 0.3316 - accuracy: 0.9833 - val_loss: 0.3636 - val_accuracy: 0.9000\n",
      "Epoch 489/1000\n",
      "120/120 [==============================] - 0s 311us/sample - loss: 0.3308 - accuracy: 0.9833 - val_loss: 0.3628 - val_accuracy: 0.9000\n",
      "Epoch 490/1000\n",
      "120/120 [==============================] - 0s 325us/sample - loss: 0.3302 - accuracy: 0.9833 - val_loss: 0.3621 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 491/1000\n",
      "120/120 [==============================] - 0s 284us/sample - loss: 0.3295 - accuracy: 0.9833 - val_loss: 0.3614 - val_accuracy: 0.9000\n",
      "Epoch 492/1000\n",
      "120/120 [==============================] - 0s 315us/sample - loss: 0.3288 - accuracy: 0.9833 - val_loss: 0.3607 - val_accuracy: 0.9000\n",
      "Epoch 493/1000\n",
      "120/120 [==============================] - 0s 379us/sample - loss: 0.3281 - accuracy: 0.9833 - val_loss: 0.3601 - val_accuracy: 0.9000\n",
      "Epoch 494/1000\n",
      "120/120 [==============================] - 0s 341us/sample - loss: 0.3275 - accuracy: 0.9833 - val_loss: 0.3594 - val_accuracy: 0.9000\n",
      "Epoch 495/1000\n",
      "120/120 [==============================] - 0s 327us/sample - loss: 0.3268 - accuracy: 0.9833 - val_loss: 0.3587 - val_accuracy: 0.9000\n",
      "Epoch 496/1000\n",
      "120/120 [==============================] - 0s 314us/sample - loss: 0.3261 - accuracy: 0.9833 - val_loss: 0.3580 - val_accuracy: 0.9000\n",
      "Epoch 497/1000\n",
      "120/120 [==============================] - 0s 409us/sample - loss: 0.3255 - accuracy: 0.9833 - val_loss: 0.3574 - val_accuracy: 0.9000\n",
      "Epoch 498/1000\n",
      "120/120 [==============================] - 0s 350us/sample - loss: 0.3247 - accuracy: 0.9833 - val_loss: 0.3567 - val_accuracy: 0.9000\n",
      "Epoch 499/1000\n",
      "120/120 [==============================] - 0s 301us/sample - loss: 0.3241 - accuracy: 0.9833 - val_loss: 0.3560 - val_accuracy: 0.9000\n",
      "Epoch 500/1000\n",
      "120/120 [==============================] - 0s 352us/sample - loss: 0.3234 - accuracy: 0.9833 - val_loss: 0.3553 - val_accuracy: 0.9000\n",
      "Epoch 501/1000\n",
      "120/120 [==============================] - 0s 338us/sample - loss: 0.3227 - accuracy: 0.9833 - val_loss: 0.3547 - val_accuracy: 0.9000\n",
      "Epoch 502/1000\n",
      "120/120 [==============================] - 0s 317us/sample - loss: 0.3220 - accuracy: 0.9833 - val_loss: 0.3541 - val_accuracy: 0.9000\n",
      "Epoch 503/1000\n",
      "120/120 [==============================] - 0s 309us/sample - loss: 0.3214 - accuracy: 0.9833 - val_loss: 0.3534 - val_accuracy: 0.9000\n",
      "Epoch 504/1000\n",
      "120/120 [==============================] - 0s 331us/sample - loss: 0.3208 - accuracy: 0.9833 - val_loss: 0.3528 - val_accuracy: 0.9000\n",
      "Epoch 505/1000\n",
      "120/120 [==============================] - 0s 305us/sample - loss: 0.3201 - accuracy: 0.9833 - val_loss: 0.3522 - val_accuracy: 0.9000\n",
      "Epoch 506/1000\n",
      "120/120 [==============================] - 0s 371us/sample - loss: 0.3195 - accuracy: 0.9833 - val_loss: 0.3516 - val_accuracy: 0.9000\n",
      "Epoch 507/1000\n",
      "120/120 [==============================] - 0s 340us/sample - loss: 0.3189 - accuracy: 0.9833 - val_loss: 0.3508 - val_accuracy: 0.9000\n",
      "Epoch 508/1000\n",
      "120/120 [==============================] - 0s 291us/sample - loss: 0.3181 - accuracy: 0.9833 - val_loss: 0.3502 - val_accuracy: 0.9000\n",
      "Epoch 509/1000\n",
      "120/120 [==============================] - 0s 284us/sample - loss: 0.3176 - accuracy: 0.9833 - val_loss: 0.3494 - val_accuracy: 0.9000\n",
      "Epoch 510/1000\n",
      "120/120 [==============================] - 0s 414us/sample - loss: 0.3168 - accuracy: 0.9833 - val_loss: 0.3488 - val_accuracy: 0.9000\n",
      "Epoch 511/1000\n",
      "120/120 [==============================] - 0s 304us/sample - loss: 0.3161 - accuracy: 0.9833 - val_loss: 0.3481 - val_accuracy: 0.9000\n",
      "Epoch 512/1000\n",
      "120/120 [==============================] - 0s 316us/sample - loss: 0.3155 - accuracy: 0.9833 - val_loss: 0.3475 - val_accuracy: 0.9000\n",
      "Epoch 513/1000\n",
      "120/120 [==============================] - 0s 339us/sample - loss: 0.3148 - accuracy: 0.9833 - val_loss: 0.3468 - val_accuracy: 0.9000\n",
      "Epoch 514/1000\n",
      "120/120 [==============================] - 0s 302us/sample - loss: 0.3142 - accuracy: 0.9833 - val_loss: 0.3462 - val_accuracy: 0.9000\n",
      "Epoch 515/1000\n",
      "120/120 [==============================] - 0s 305us/sample - loss: 0.3136 - accuracy: 0.9833 - val_loss: 0.3455 - val_accuracy: 0.9000\n",
      "Epoch 516/1000\n",
      "120/120 [==============================] - 0s 322us/sample - loss: 0.3129 - accuracy: 0.9833 - val_loss: 0.3449 - val_accuracy: 0.9000\n",
      "Epoch 517/1000\n",
      "120/120 [==============================] - 0s 276us/sample - loss: 0.3123 - accuracy: 0.9833 - val_loss: 0.3443 - val_accuracy: 0.9000\n",
      "Epoch 518/1000\n",
      "120/120 [==============================] - 0s 401us/sample - loss: 0.3117 - accuracy: 0.9833 - val_loss: 0.3437 - val_accuracy: 0.9000\n",
      "Epoch 519/1000\n",
      "120/120 [==============================] - 0s 366us/sample - loss: 0.3110 - accuracy: 0.9833 - val_loss: 0.3430 - val_accuracy: 0.9000\n",
      "Epoch 520/1000\n",
      "120/120 [==============================] - 0s 336us/sample - loss: 0.3104 - accuracy: 0.9833 - val_loss: 0.3424 - val_accuracy: 0.9000\n",
      "Epoch 521/1000\n",
      "120/120 [==============================] - 0s 291us/sample - loss: 0.3100 - accuracy: 0.9833 - val_loss: 0.3418 - val_accuracy: 0.9000\n",
      "Epoch 522/1000\n",
      "120/120 [==============================] - 0s 299us/sample - loss: 0.3092 - accuracy: 0.9833 - val_loss: 0.3411 - val_accuracy: 0.9000\n",
      "Epoch 523/1000\n",
      "120/120 [==============================] - 0s 313us/sample - loss: 0.3084 - accuracy: 0.9833 - val_loss: 0.3404 - val_accuracy: 0.9000\n",
      "Epoch 524/1000\n",
      "120/120 [==============================] - 0s 302us/sample - loss: 0.3078 - accuracy: 0.9833 - val_loss: 0.3398 - val_accuracy: 0.9000\n",
      "Epoch 525/1000\n",
      "120/120 [==============================] - 0s 436us/sample - loss: 0.3072 - accuracy: 0.9833 - val_loss: 0.3391 - val_accuracy: 0.9000\n",
      "Epoch 526/1000\n",
      "120/120 [==============================] - 0s 313us/sample - loss: 0.3066 - accuracy: 0.9833 - val_loss: 0.3385 - val_accuracy: 0.9000\n",
      "Epoch 527/1000\n",
      "120/120 [==============================] - 0s 324us/sample - loss: 0.3060 - accuracy: 0.9833 - val_loss: 0.3379 - val_accuracy: 0.9000\n",
      "Epoch 528/1000\n",
      "120/120 [==============================] - 0s 299us/sample - loss: 0.3054 - accuracy: 0.9833 - val_loss: 0.3373 - val_accuracy: 0.9000\n",
      "Epoch 529/1000\n",
      "120/120 [==============================] - 0s 350us/sample - loss: 0.3047 - accuracy: 0.9833 - val_loss: 0.3366 - val_accuracy: 0.9000\n",
      "Epoch 530/1000\n",
      "120/120 [==============================] - 0s 296us/sample - loss: 0.3041 - accuracy: 0.9833 - val_loss: 0.3360 - val_accuracy: 0.9000\n",
      "Epoch 531/1000\n",
      "120/120 [==============================] - 0s 305us/sample - loss: 0.3035 - accuracy: 0.9833 - val_loss: 0.3354 - val_accuracy: 0.9000\n",
      "Epoch 532/1000\n",
      "120/120 [==============================] - 0s 375us/sample - loss: 0.3029 - accuracy: 0.9833 - val_loss: 0.3348 - val_accuracy: 0.9000\n",
      "Epoch 533/1000\n",
      "120/120 [==============================] - 0s 318us/sample - loss: 0.3022 - accuracy: 0.9833 - val_loss: 0.3342 - val_accuracy: 0.9000\n",
      "Epoch 534/1000\n",
      "120/120 [==============================] - 0s 327us/sample - loss: 0.3016 - accuracy: 0.9833 - val_loss: 0.3336 - val_accuracy: 0.9000\n",
      "Epoch 535/1000\n",
      "120/120 [==============================] - 0s 317us/sample - loss: 0.3010 - accuracy: 0.9833 - val_loss: 0.3330 - val_accuracy: 0.9000\n",
      "Epoch 536/1000\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 0.3004 - accuracy: 0.9833 - val_loss: 0.3324 - val_accuracy: 0.9000\n",
      "Epoch 537/1000\n",
      "120/120 [==============================] - 0s 333us/sample - loss: 0.2999 - accuracy: 0.9833 - val_loss: 0.3318 - val_accuracy: 0.9000\n",
      "Epoch 538/1000\n",
      "120/120 [==============================] - 0s 330us/sample - loss: 0.2992 - accuracy: 0.9833 - val_loss: 0.3312 - val_accuracy: 0.9000\n",
      "Epoch 539/1000\n",
      "120/120 [==============================] - 0s 355us/sample - loss: 0.2986 - accuracy: 0.9833 - val_loss: 0.3306 - val_accuracy: 0.9000\n",
      "Epoch 540/1000\n",
      "120/120 [==============================] - 0s 379us/sample - loss: 0.2982 - accuracy: 0.9833 - val_loss: 0.3299 - val_accuracy: 0.9000\n",
      "Epoch 541/1000\n",
      "120/120 [==============================] - 0s 331us/sample - loss: 0.2974 - accuracy: 0.9833 - val_loss: 0.3293 - val_accuracy: 0.9000\n",
      "Epoch 542/1000\n",
      "120/120 [==============================] - 0s 263us/sample - loss: 0.2968 - accuracy: 0.9833 - val_loss: 0.3287 - val_accuracy: 0.9000\n",
      "Epoch 543/1000\n",
      "120/120 [==============================] - 0s 307us/sample - loss: 0.2963 - accuracy: 0.9833 - val_loss: 0.3282 - val_accuracy: 0.9000\n",
      "Epoch 544/1000\n",
      "120/120 [==============================] - 0s 264us/sample - loss: 0.2956 - accuracy: 0.9833 - val_loss: 0.3276 - val_accuracy: 0.9000\n",
      "Epoch 545/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 303us/sample - loss: 0.2950 - accuracy: 0.9833 - val_loss: 0.3270 - val_accuracy: 0.9000\n",
      "Epoch 546/1000\n",
      "120/120 [==============================] - 0s 270us/sample - loss: 0.2944 - accuracy: 0.9833 - val_loss: 0.3264 - val_accuracy: 0.9000\n",
      "Epoch 547/1000\n",
      "120/120 [==============================] - 0s 287us/sample - loss: 0.2938 - accuracy: 0.9833 - val_loss: 0.3258 - val_accuracy: 0.9000\n",
      "Epoch 548/1000\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.2932 - accuracy: 0.9833 - val_loss: 0.3252 - val_accuracy: 0.9000\n",
      "Epoch 549/1000\n",
      "120/120 [==============================] - 0s 264us/sample - loss: 0.2927 - accuracy: 0.9833 - val_loss: 0.3245 - val_accuracy: 0.9000\n",
      "Epoch 550/1000\n",
      "120/120 [==============================] - 0s 278us/sample - loss: 0.2920 - accuracy: 0.9833 - val_loss: 0.3240 - val_accuracy: 0.9000\n",
      "Epoch 551/1000\n",
      "120/120 [==============================] - 0s 235us/sample - loss: 0.2915 - accuracy: 0.9833 - val_loss: 0.3234 - val_accuracy: 0.9000\n",
      "Epoch 552/1000\n",
      "120/120 [==============================] - 0s 299us/sample - loss: 0.2909 - accuracy: 0.9833 - val_loss: 0.3228 - val_accuracy: 0.9000\n",
      "Epoch 553/1000\n",
      "120/120 [==============================] - 0s 248us/sample - loss: 0.2903 - accuracy: 0.9833 - val_loss: 0.3223 - val_accuracy: 0.9000\n",
      "Epoch 554/1000\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.2897 - accuracy: 0.9833 - val_loss: 0.3217 - val_accuracy: 0.9000\n",
      "Epoch 555/1000\n",
      "120/120 [==============================] - 0s 281us/sample - loss: 0.2891 - accuracy: 0.9833 - val_loss: 0.3212 - val_accuracy: 0.9000\n",
      "Epoch 556/1000\n",
      "120/120 [==============================] - 0s 282us/sample - loss: 0.2885 - accuracy: 0.9833 - val_loss: 0.3206 - val_accuracy: 0.9000\n",
      "Epoch 557/1000\n",
      "120/120 [==============================] - 0s 292us/sample - loss: 0.2881 - accuracy: 0.9833 - val_loss: 0.3202 - val_accuracy: 0.9000\n",
      "Epoch 558/1000\n",
      "120/120 [==============================] - 0s 257us/sample - loss: 0.2874 - accuracy: 0.9833 - val_loss: 0.3196 - val_accuracy: 0.9000\n",
      "Epoch 559/1000\n",
      "120/120 [==============================] - 0s 261us/sample - loss: 0.2868 - accuracy: 0.9833 - val_loss: 0.3190 - val_accuracy: 0.9000\n",
      "Epoch 560/1000\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.2862 - accuracy: 0.9833 - val_loss: 0.3184 - val_accuracy: 0.9000\n",
      "Epoch 561/1000\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.2857 - accuracy: 0.9833 - val_loss: 0.3179 - val_accuracy: 0.9000\n",
      "Epoch 562/1000\n",
      "120/120 [==============================] - 0s 259us/sample - loss: 0.2852 - accuracy: 0.9833 - val_loss: 0.3173 - val_accuracy: 0.9000\n",
      "Epoch 563/1000\n",
      "120/120 [==============================] - 0s 356us/sample - loss: 0.2846 - accuracy: 0.9833 - val_loss: 0.3168 - val_accuracy: 0.9000\n",
      "Epoch 564/1000\n",
      "120/120 [==============================] - 0s 347us/sample - loss: 0.2840 - accuracy: 0.9833 - val_loss: 0.3162 - val_accuracy: 0.9000\n",
      "Epoch 565/1000\n",
      "120/120 [==============================] - 0s 278us/sample - loss: 0.2835 - accuracy: 0.9833 - val_loss: 0.3155 - val_accuracy: 0.9000\n",
      "Epoch 566/1000\n",
      "120/120 [==============================] - 0s 308us/sample - loss: 0.2829 - accuracy: 0.9833 - val_loss: 0.3150 - val_accuracy: 0.9000\n",
      "Epoch 567/1000\n",
      "120/120 [==============================] - 0s 259us/sample - loss: 0.2823 - accuracy: 0.9833 - val_loss: 0.3144 - val_accuracy: 0.9000\n",
      "Epoch 568/1000\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.2817 - accuracy: 0.9833 - val_loss: 0.3139 - val_accuracy: 0.9000\n",
      "Epoch 569/1000\n",
      "120/120 [==============================] - 0s 243us/sample - loss: 0.2812 - accuracy: 0.9833 - val_loss: 0.3133 - val_accuracy: 0.9000\n",
      "Epoch 570/1000\n",
      "120/120 [==============================] - 0s 281us/sample - loss: 0.2806 - accuracy: 0.9833 - val_loss: 0.3127 - val_accuracy: 0.9000\n",
      "Epoch 571/1000\n",
      "120/120 [==============================] - 0s 293us/sample - loss: 0.2800 - accuracy: 0.9833 - val_loss: 0.3122 - val_accuracy: 0.9000\n",
      "Epoch 572/1000\n",
      "120/120 [==============================] - 0s 289us/sample - loss: 0.2796 - accuracy: 0.9833 - val_loss: 0.3116 - val_accuracy: 0.9000\n",
      "Epoch 573/1000\n",
      "120/120 [==============================] - 0s 227us/sample - loss: 0.2789 - accuracy: 0.9833 - val_loss: 0.3111 - val_accuracy: 0.9000\n",
      "Epoch 574/1000\n",
      "120/120 [==============================] - 0s 268us/sample - loss: 0.2784 - accuracy: 0.9833 - val_loss: 0.3106 - val_accuracy: 0.9000\n",
      "Epoch 575/1000\n",
      "120/120 [==============================] - 0s 247us/sample - loss: 0.2779 - accuracy: 0.9833 - val_loss: 0.3101 - val_accuracy: 0.9000\n",
      "Epoch 576/1000\n",
      "120/120 [==============================] - 0s 282us/sample - loss: 0.2773 - accuracy: 0.9833 - val_loss: 0.3095 - val_accuracy: 0.9000\n",
      "Epoch 577/1000\n",
      "120/120 [==============================] - 0s 235us/sample - loss: 0.2767 - accuracy: 0.9833 - val_loss: 0.3089 - val_accuracy: 0.9000\n",
      "Epoch 578/1000\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.2762 - accuracy: 0.9833 - val_loss: 0.3084 - val_accuracy: 0.9000\n",
      "Epoch 579/1000\n",
      "120/120 [==============================] - 0s 261us/sample - loss: 0.2756 - accuracy: 0.9833 - val_loss: 0.3078 - val_accuracy: 0.9000\n",
      "Epoch 580/1000\n",
      "120/120 [==============================] - 0s 282us/sample - loss: 0.2752 - accuracy: 0.9833 - val_loss: 0.3072 - val_accuracy: 0.9000\n",
      "Epoch 581/1000\n",
      "120/120 [==============================] - 0s 302us/sample - loss: 0.2745 - accuracy: 0.9833 - val_loss: 0.3067 - val_accuracy: 0.9000\n",
      "Epoch 582/1000\n",
      "120/120 [==============================] - 0s 284us/sample - loss: 0.2740 - accuracy: 0.9833 - val_loss: 0.3061 - val_accuracy: 0.9000\n",
      "Epoch 583/1000\n",
      "120/120 [==============================] - 0s 281us/sample - loss: 0.2735 - accuracy: 0.9833 - val_loss: 0.3057 - val_accuracy: 0.9000\n",
      "Epoch 584/1000\n",
      "120/120 [==============================] - 0s 261us/sample - loss: 0.2729 - accuracy: 0.9833 - val_loss: 0.3051 - val_accuracy: 0.9000\n",
      "Epoch 585/1000\n",
      "120/120 [==============================] - 0s 256us/sample - loss: 0.2724 - accuracy: 0.9833 - val_loss: 0.3046 - val_accuracy: 0.9000\n",
      "Epoch 586/1000\n",
      "120/120 [==============================] - 0s 265us/sample - loss: 0.2719 - accuracy: 0.9833 - val_loss: 0.3041 - val_accuracy: 0.9000\n",
      "Epoch 587/1000\n",
      "120/120 [==============================] - 0s 323us/sample - loss: 0.2714 - accuracy: 0.9833 - val_loss: 0.3035 - val_accuracy: 0.9000\n",
      "Epoch 588/1000\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.2708 - accuracy: 0.9833 - val_loss: 0.3030 - val_accuracy: 0.9000\n",
      "Epoch 589/1000\n",
      "120/120 [==============================] - 0s 292us/sample - loss: 0.2703 - accuracy: 0.9833 - val_loss: 0.3024 - val_accuracy: 0.9000\n",
      "Epoch 590/1000\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.2698 - accuracy: 0.9833 - val_loss: 0.3020 - val_accuracy: 0.9000\n",
      "Epoch 591/1000\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.2692 - accuracy: 0.9833 - val_loss: 0.3015 - val_accuracy: 0.9000\n",
      "Epoch 592/1000\n",
      "120/120 [==============================] - 0s 310us/sample - loss: 0.2687 - accuracy: 0.9833 - val_loss: 0.3010 - val_accuracy: 0.9000\n",
      "Epoch 593/1000\n",
      "120/120 [==============================] - 0s 285us/sample - loss: 0.2681 - accuracy: 0.9833 - val_loss: 0.3005 - val_accuracy: 0.9000\n",
      "Epoch 594/1000\n",
      "120/120 [==============================] - 0s 273us/sample - loss: 0.2676 - accuracy: 0.9833 - val_loss: 0.3000 - val_accuracy: 0.9000\n",
      "Epoch 595/1000\n",
      "120/120 [==============================] - 0s 299us/sample - loss: 0.2671 - accuracy: 0.9833 - val_loss: 0.2995 - val_accuracy: 0.9000\n",
      "Epoch 596/1000\n",
      "120/120 [==============================] - 0s 256us/sample - loss: 0.2666 - accuracy: 0.9833 - val_loss: 0.2990 - val_accuracy: 0.9000\n",
      "Epoch 597/1000\n",
      "120/120 [==============================] - 0s 272us/sample - loss: 0.2660 - accuracy: 0.9833 - val_loss: 0.2985 - val_accuracy: 0.9000\n",
      "Epoch 598/1000\n",
      "120/120 [==============================] - 0s 245us/sample - loss: 0.2656 - accuracy: 0.9833 - val_loss: 0.2979 - val_accuracy: 0.9000\n",
      "Epoch 599/1000\n",
      "120/120 [==============================] - 0s 247us/sample - loss: 0.2650 - accuracy: 0.9833 - val_loss: 0.2975 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 600/1000\n",
      "120/120 [==============================] - 0s 287us/sample - loss: 0.2646 - accuracy: 0.9833 - val_loss: 0.2971 - val_accuracy: 0.9000\n",
      "Epoch 601/1000\n",
      "120/120 [==============================] - 0s 299us/sample - loss: 0.2641 - accuracy: 0.9833 - val_loss: 0.2965 - val_accuracy: 0.9000\n",
      "Epoch 602/1000\n",
      "120/120 [==============================] - 0s 345us/sample - loss: 0.2635 - accuracy: 0.9833 - val_loss: 0.2960 - val_accuracy: 0.9000\n",
      "Epoch 603/1000\n",
      "120/120 [==============================] - 0s 321us/sample - loss: 0.2630 - accuracy: 0.9833 - val_loss: 0.2955 - val_accuracy: 0.9000\n",
      "Epoch 604/1000\n",
      "120/120 [==============================] - 0s 351us/sample - loss: 0.2627 - accuracy: 0.9833 - val_loss: 0.2951 - val_accuracy: 0.9000\n",
      "Epoch 605/1000\n",
      "120/120 [==============================] - 0s 277us/sample - loss: 0.2620 - accuracy: 0.9833 - val_loss: 0.2945 - val_accuracy: 0.9000\n",
      "Epoch 606/1000\n",
      "120/120 [==============================] - 0s 330us/sample - loss: 0.2614 - accuracy: 0.9833 - val_loss: 0.2940 - val_accuracy: 0.9000\n",
      "Epoch 607/1000\n",
      "120/120 [==============================] - 0s 408us/sample - loss: 0.2609 - accuracy: 0.9833 - val_loss: 0.2934 - val_accuracy: 0.9000\n",
      "Epoch 608/1000\n",
      "120/120 [==============================] - 0s 352us/sample - loss: 0.2604 - accuracy: 0.9833 - val_loss: 0.2928 - val_accuracy: 0.9000\n",
      "Epoch 609/1000\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.2599 - accuracy: 0.9833 - val_loss: 0.2923 - val_accuracy: 0.9000\n",
      "Epoch 610/1000\n",
      "120/120 [==============================] - 0s 277us/sample - loss: 0.2594 - accuracy: 0.9833 - val_loss: 0.2918 - val_accuracy: 0.9000\n",
      "Epoch 611/1000\n",
      "120/120 [==============================] - 0s 247us/sample - loss: 0.2589 - accuracy: 0.9833 - val_loss: 0.2914 - val_accuracy: 0.9000\n",
      "Epoch 612/1000\n",
      "120/120 [==============================] - 0s 289us/sample - loss: 0.2584 - accuracy: 0.9833 - val_loss: 0.2909 - val_accuracy: 0.9000\n",
      "Epoch 613/1000\n",
      "120/120 [==============================] - 0s 270us/sample - loss: 0.2580 - accuracy: 0.9833 - val_loss: 0.2904 - val_accuracy: 0.9000\n",
      "Epoch 614/1000\n",
      "120/120 [==============================] - 0s 281us/sample - loss: 0.2574 - accuracy: 0.9833 - val_loss: 0.2899 - val_accuracy: 0.9000\n",
      "Epoch 615/1000\n",
      "120/120 [==============================] - 0s 230us/sample - loss: 0.2569 - accuracy: 0.9833 - val_loss: 0.2894 - val_accuracy: 0.9000\n",
      "Epoch 616/1000\n",
      "120/120 [==============================] - 0s 277us/sample - loss: 0.2564 - accuracy: 0.9833 - val_loss: 0.2890 - val_accuracy: 0.9000\n",
      "Epoch 617/1000\n",
      "120/120 [==============================] - 0s 246us/sample - loss: 0.2561 - accuracy: 0.9833 - val_loss: 0.2884 - val_accuracy: 0.9000\n",
      "Epoch 618/1000\n",
      "120/120 [==============================] - 0s 281us/sample - loss: 0.2554 - accuracy: 0.9833 - val_loss: 0.2880 - val_accuracy: 0.9000\n",
      "Epoch 619/1000\n",
      "120/120 [==============================] - 0s 297us/sample - loss: 0.2550 - accuracy: 0.9833 - val_loss: 0.2876 - val_accuracy: 0.9000\n",
      "Epoch 620/1000\n",
      "120/120 [==============================] - 0s 239us/sample - loss: 0.2545 - accuracy: 0.9833 - val_loss: 0.2871 - val_accuracy: 0.9000\n",
      "Epoch 621/1000\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 0.2540 - accuracy: 0.9833 - val_loss: 0.2867 - val_accuracy: 0.9000\n",
      "Epoch 622/1000\n",
      "120/120 [==============================] - 0s 247us/sample - loss: 0.2535 - accuracy: 0.9833 - val_loss: 0.2862 - val_accuracy: 0.9000\n",
      "Epoch 623/1000\n",
      "120/120 [==============================] - 0s 289us/sample - loss: 0.2531 - accuracy: 0.9833 - val_loss: 0.2856 - val_accuracy: 0.9000\n",
      "Epoch 624/1000\n",
      "120/120 [==============================] - 0s 302us/sample - loss: 0.2525 - accuracy: 0.9833 - val_loss: 0.2851 - val_accuracy: 0.9000\n",
      "Epoch 625/1000\n",
      "120/120 [==============================] - 0s 309us/sample - loss: 0.2520 - accuracy: 0.9833 - val_loss: 0.2846 - val_accuracy: 0.9000\n",
      "Epoch 626/1000\n",
      "120/120 [==============================] - 0s 247us/sample - loss: 0.2516 - accuracy: 0.9833 - val_loss: 0.2842 - val_accuracy: 0.9000\n",
      "Epoch 627/1000\n",
      "120/120 [==============================] - 0s 243us/sample - loss: 0.2511 - accuracy: 0.9833 - val_loss: 0.2837 - val_accuracy: 0.9000\n",
      "Epoch 628/1000\n",
      "120/120 [==============================] - 0s 322us/sample - loss: 0.2507 - accuracy: 0.9833 - val_loss: 0.2833 - val_accuracy: 0.9000\n",
      "Epoch 629/1000\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.2501 - accuracy: 0.9833 - val_loss: 0.2827 - val_accuracy: 0.9000\n",
      "Epoch 630/1000\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.2497 - accuracy: 0.9833 - val_loss: 0.2821 - val_accuracy: 0.9000\n",
      "Epoch 631/1000\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.2492 - accuracy: 0.9833 - val_loss: 0.2817 - val_accuracy: 0.9000\n",
      "Epoch 632/1000\n",
      "120/120 [==============================] - 0s 263us/sample - loss: 0.2488 - accuracy: 0.9833 - val_loss: 0.2812 - val_accuracy: 0.9000\n",
      "Epoch 633/1000\n",
      "120/120 [==============================] - 0s 284us/sample - loss: 0.2483 - accuracy: 0.9833 - val_loss: 0.2809 - val_accuracy: 0.9000\n",
      "Epoch 634/1000\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.2478 - accuracy: 0.9833 - val_loss: 0.2805 - val_accuracy: 0.9000\n",
      "Epoch 635/1000\n",
      "120/120 [==============================] - 0s 270us/sample - loss: 0.2474 - accuracy: 0.9833 - val_loss: 0.2801 - val_accuracy: 0.9000\n",
      "Epoch 636/1000\n",
      "120/120 [==============================] - 0s 327us/sample - loss: 0.2468 - accuracy: 0.9833 - val_loss: 0.2796 - val_accuracy: 0.9000\n",
      "Epoch 637/1000\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.2464 - accuracy: 0.9833 - val_loss: 0.2790 - val_accuracy: 0.9000\n",
      "Epoch 638/1000\n",
      "120/120 [==============================] - 0s 301us/sample - loss: 0.2459 - accuracy: 0.9833 - val_loss: 0.2786 - val_accuracy: 0.9000\n",
      "Epoch 639/1000\n",
      "120/120 [==============================] - 0s 269us/sample - loss: 0.2455 - accuracy: 0.9833 - val_loss: 0.2781 - val_accuracy: 0.9000\n",
      "Epoch 640/1000\n",
      "120/120 [==============================] - 0s 251us/sample - loss: 0.2450 - accuracy: 0.9833 - val_loss: 0.2777 - val_accuracy: 0.9000\n",
      "Epoch 641/1000\n",
      "120/120 [==============================] - 0s 221us/sample - loss: 0.2446 - accuracy: 0.9833 - val_loss: 0.2773 - val_accuracy: 0.9000\n",
      "Epoch 642/1000\n",
      "120/120 [==============================] - 0s 270us/sample - loss: 0.2441 - accuracy: 0.9833 - val_loss: 0.2768 - val_accuracy: 0.9000\n",
      "Epoch 643/1000\n",
      "120/120 [==============================] - 0s 279us/sample - loss: 0.2436 - accuracy: 0.9833 - val_loss: 0.2763 - val_accuracy: 0.9000\n",
      "Epoch 644/1000\n",
      "120/120 [==============================] - 0s 299us/sample - loss: 0.2431 - accuracy: 0.9833 - val_loss: 0.2758 - val_accuracy: 0.9000\n",
      "Epoch 645/1000\n",
      "120/120 [==============================] - 0s 246us/sample - loss: 0.2427 - accuracy: 0.9833 - val_loss: 0.2754 - val_accuracy: 0.9000\n",
      "Epoch 646/1000\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.2423 - accuracy: 0.9833 - val_loss: 0.2750 - val_accuracy: 0.9000\n",
      "Epoch 647/1000\n",
      "120/120 [==============================] - 0s 273us/sample - loss: 0.2418 - accuracy: 0.9833 - val_loss: 0.2746 - val_accuracy: 0.9000\n",
      "Epoch 648/1000\n",
      "120/120 [==============================] - 0s 246us/sample - loss: 0.2413 - accuracy: 0.9833 - val_loss: 0.2741 - val_accuracy: 0.9000\n",
      "Epoch 649/1000\n",
      "120/120 [==============================] - 0s 299us/sample - loss: 0.2410 - accuracy: 0.9833 - val_loss: 0.2738 - val_accuracy: 0.9000\n",
      "Epoch 650/1000\n",
      "120/120 [==============================] - 0s 279us/sample - loss: 0.2404 - accuracy: 0.9833 - val_loss: 0.2733 - val_accuracy: 0.9000\n",
      "Epoch 651/1000\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.2400 - accuracy: 0.9833 - val_loss: 0.2729 - val_accuracy: 0.9000\n",
      "Epoch 652/1000\n",
      "120/120 [==============================] - 0s 279us/sample - loss: 0.2395 - accuracy: 0.9833 - val_loss: 0.2726 - val_accuracy: 0.9000\n",
      "Epoch 653/1000\n",
      "120/120 [==============================] - 0s 245us/sample - loss: 0.2391 - accuracy: 0.9833 - val_loss: 0.2722 - val_accuracy: 0.9000\n",
      "Epoch 654/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 241us/sample - loss: 0.2387 - accuracy: 0.9833 - val_loss: 0.2718 - val_accuracy: 0.9000\n",
      "Epoch 655/1000\n",
      "120/120 [==============================] - 0s 290us/sample - loss: 0.2382 - accuracy: 0.9833 - val_loss: 0.2713 - val_accuracy: 0.9000\n",
      "Epoch 656/1000\n",
      "120/120 [==============================] - 0s 261us/sample - loss: 0.2378 - accuracy: 0.9833 - val_loss: 0.2708 - val_accuracy: 0.9000\n",
      "Epoch 657/1000\n",
      "120/120 [==============================] - 0s 268us/sample - loss: 0.2373 - accuracy: 0.9833 - val_loss: 0.2704 - val_accuracy: 0.9000\n",
      "Epoch 658/1000\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.2369 - accuracy: 0.9833 - val_loss: 0.2701 - val_accuracy: 0.9000\n",
      "Epoch 659/1000\n",
      "120/120 [==============================] - 0s 269us/sample - loss: 0.2364 - accuracy: 0.9833 - val_loss: 0.2698 - val_accuracy: 0.9000\n",
      "Epoch 660/1000\n",
      "120/120 [==============================] - 0s 256us/sample - loss: 0.2360 - accuracy: 0.9833 - val_loss: 0.2693 - val_accuracy: 0.9000\n",
      "Epoch 661/1000\n",
      "120/120 [==============================] - 0s 305us/sample - loss: 0.2356 - accuracy: 0.9833 - val_loss: 0.2688 - val_accuracy: 0.9000\n",
      "Epoch 662/1000\n",
      "120/120 [==============================] - 0s 306us/sample - loss: 0.2351 - accuracy: 0.9833 - val_loss: 0.2684 - val_accuracy: 0.9000\n",
      "Epoch 663/1000\n",
      "120/120 [==============================] - 0s 269us/sample - loss: 0.2347 - accuracy: 0.9833 - val_loss: 0.2681 - val_accuracy: 0.9000\n",
      "Epoch 664/1000\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 0.2343 - accuracy: 0.9833 - val_loss: 0.2677 - val_accuracy: 0.9000\n",
      "Epoch 665/1000\n",
      "120/120 [==============================] - 0s 297us/sample - loss: 0.2339 - accuracy: 0.9833 - val_loss: 0.2673 - val_accuracy: 0.9000\n",
      "Epoch 666/1000\n",
      "120/120 [==============================] - 0s 261us/sample - loss: 0.2334 - accuracy: 0.9833 - val_loss: 0.2669 - val_accuracy: 0.9000\n",
      "Epoch 667/1000\n",
      "120/120 [==============================] - 0s 253us/sample - loss: 0.2330 - accuracy: 0.9833 - val_loss: 0.2664 - val_accuracy: 0.9000\n",
      "Epoch 668/1000\n",
      "120/120 [==============================] - 0s 239us/sample - loss: 0.2325 - accuracy: 0.9833 - val_loss: 0.2659 - val_accuracy: 0.9000\n",
      "Epoch 669/1000\n",
      "120/120 [==============================] - 0s 231us/sample - loss: 0.2321 - accuracy: 0.9833 - val_loss: 0.2655 - val_accuracy: 0.9000\n",
      "Epoch 670/1000\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 0.2317 - accuracy: 0.9833 - val_loss: 0.2649 - val_accuracy: 0.9000\n",
      "Epoch 671/1000\n",
      "120/120 [==============================] - 0s 309us/sample - loss: 0.2313 - accuracy: 0.9833 - val_loss: 0.2645 - val_accuracy: 0.9000\n",
      "Epoch 672/1000\n",
      "120/120 [==============================] - 0s 265us/sample - loss: 0.2309 - accuracy: 0.9833 - val_loss: 0.2639 - val_accuracy: 0.9000\n",
      "Epoch 673/1000\n",
      "120/120 [==============================] - 0s 311us/sample - loss: 0.2304 - accuracy: 0.9833 - val_loss: 0.2635 - val_accuracy: 0.9000\n",
      "Epoch 674/1000\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.2300 - accuracy: 0.9833 - val_loss: 0.2630 - val_accuracy: 0.9000\n",
      "Epoch 675/1000\n",
      "120/120 [==============================] - 0s 259us/sample - loss: 0.2296 - accuracy: 0.9833 - val_loss: 0.2627 - val_accuracy: 0.9000\n",
      "Epoch 676/1000\n",
      "120/120 [==============================] - 0s 255us/sample - loss: 0.2292 - accuracy: 0.9833 - val_loss: 0.2623 - val_accuracy: 0.9000\n",
      "Epoch 677/1000\n",
      "120/120 [==============================] - 0s 291us/sample - loss: 0.2288 - accuracy: 0.9833 - val_loss: 0.2620 - val_accuracy: 0.9000\n",
      "Epoch 678/1000\n",
      "120/120 [==============================] - 0s 229us/sample - loss: 0.2283 - accuracy: 0.9833 - val_loss: 0.2616 - val_accuracy: 0.9000\n",
      "Epoch 679/1000\n",
      "120/120 [==============================] - 0s 301us/sample - loss: 0.2279 - accuracy: 0.9833 - val_loss: 0.2613 - val_accuracy: 0.9000\n",
      "Epoch 680/1000\n",
      "120/120 [==============================] - 0s 276us/sample - loss: 0.2274 - accuracy: 0.9833 - val_loss: 0.2610 - val_accuracy: 0.9000\n",
      "Epoch 681/1000\n",
      "120/120 [==============================] - 0s 257us/sample - loss: 0.2271 - accuracy: 0.9833 - val_loss: 0.2607 - val_accuracy: 0.9000\n",
      "Epoch 682/1000\n",
      "120/120 [==============================] - 0s 280us/sample - loss: 0.2267 - accuracy: 0.9833 - val_loss: 0.2603 - val_accuracy: 0.9000\n",
      "Epoch 683/1000\n",
      "120/120 [==============================] - 0s 256us/sample - loss: 0.2263 - accuracy: 0.9833 - val_loss: 0.2599 - val_accuracy: 0.9000\n",
      "Epoch 684/1000\n",
      "120/120 [==============================] - 0s 260us/sample - loss: 0.2259 - accuracy: 0.9833 - val_loss: 0.2594 - val_accuracy: 0.9000\n",
      "Epoch 685/1000\n",
      "120/120 [==============================] - 0s 269us/sample - loss: 0.2255 - accuracy: 0.9833 - val_loss: 0.2590 - val_accuracy: 0.9000\n",
      "Epoch 686/1000\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.2252 - accuracy: 0.9833 - val_loss: 0.2584 - val_accuracy: 0.9000\n",
      "Epoch 687/1000\n",
      "120/120 [==============================] - 0s 262us/sample - loss: 0.2246 - accuracy: 0.9833 - val_loss: 0.2580 - val_accuracy: 0.9000\n",
      "Epoch 688/1000\n",
      "120/120 [==============================] - 0s 278us/sample - loss: 0.2243 - accuracy: 0.9833 - val_loss: 0.2577 - val_accuracy: 0.9000\n",
      "Epoch 689/1000\n",
      "120/120 [==============================] - 0s 281us/sample - loss: 0.2238 - accuracy: 0.9833 - val_loss: 0.2573 - val_accuracy: 0.9000\n",
      "Epoch 690/1000\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 0.2234 - accuracy: 0.9833 - val_loss: 0.2569 - val_accuracy: 0.9000\n",
      "Epoch 691/1000\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 0.2230 - accuracy: 0.9833 - val_loss: 0.2566 - val_accuracy: 0.9000\n",
      "Epoch 692/1000\n",
      "120/120 [==============================] - 0s 255us/sample - loss: 0.2226 - accuracy: 0.9833 - val_loss: 0.2561 - val_accuracy: 0.9000\n",
      "Epoch 693/1000\n",
      "120/120 [==============================] - 0s 262us/sample - loss: 0.2222 - accuracy: 0.9833 - val_loss: 0.2558 - val_accuracy: 0.9000\n",
      "Epoch 694/1000\n",
      "120/120 [==============================] - 0s 278us/sample - loss: 0.2218 - accuracy: 0.9833 - val_loss: 0.2554 - val_accuracy: 0.9000\n",
      "Epoch 695/1000\n",
      "120/120 [==============================] - 0s 284us/sample - loss: 0.2214 - accuracy: 0.9833 - val_loss: 0.2550 - val_accuracy: 0.9000\n",
      "Epoch 696/1000\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.2212 - accuracy: 0.9833 - val_loss: 0.2545 - val_accuracy: 0.9000\n",
      "Epoch 697/1000\n",
      "120/120 [==============================] - 0s 295us/sample - loss: 0.2206 - accuracy: 0.9833 - val_loss: 0.2542 - val_accuracy: 0.9000\n",
      "Epoch 698/1000\n",
      "120/120 [==============================] - 0s 232us/sample - loss: 0.2202 - accuracy: 0.9833 - val_loss: 0.2540 - val_accuracy: 0.9000\n",
      "Epoch 699/1000\n",
      "120/120 [==============================] - 0s 301us/sample - loss: 0.2199 - accuracy: 0.9833 - val_loss: 0.2537 - val_accuracy: 0.9000\n",
      "Epoch 700/1000\n",
      "120/120 [==============================] - 0s 315us/sample - loss: 0.2195 - accuracy: 0.9833 - val_loss: 0.2533 - val_accuracy: 0.9000\n",
      "Epoch 701/1000\n",
      "120/120 [==============================] - 0s 240us/sample - loss: 0.2190 - accuracy: 0.9833 - val_loss: 0.2530 - val_accuracy: 0.9000\n",
      "Epoch 702/1000\n",
      "120/120 [==============================] - 0s 311us/sample - loss: 0.2187 - accuracy: 0.9833 - val_loss: 0.2527 - val_accuracy: 0.9000\n",
      "Epoch 703/1000\n",
      "120/120 [==============================] - 0s 301us/sample - loss: 0.2183 - accuracy: 0.9833 - val_loss: 0.2524 - val_accuracy: 0.9000\n",
      "Epoch 704/1000\n",
      "120/120 [==============================] - 0s 269us/sample - loss: 0.2179 - accuracy: 0.9833 - val_loss: 0.2520 - val_accuracy: 0.9000\n",
      "Epoch 705/1000\n",
      "120/120 [==============================] - 0s 247us/sample - loss: 0.2176 - accuracy: 0.9833 - val_loss: 0.2515 - val_accuracy: 0.9000\n",
      "Epoch 706/1000\n",
      "120/120 [==============================] - 0s 333us/sample - loss: 0.2172 - accuracy: 0.9833 - val_loss: 0.2513 - val_accuracy: 0.9000\n",
      "Epoch 707/1000\n",
      "120/120 [==============================] - 0s 308us/sample - loss: 0.2167 - accuracy: 0.9833 - val_loss: 0.2509 - val_accuracy: 0.9000\n",
      "Epoch 708/1000\n",
      "120/120 [==============================] - 0s 297us/sample - loss: 0.2164 - accuracy: 0.9833 - val_loss: 0.2506 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 709/1000\n",
      "120/120 [==============================] - 0s 285us/sample - loss: 0.2160 - accuracy: 0.9833 - val_loss: 0.2502 - val_accuracy: 0.9000\n",
      "Epoch 710/1000\n",
      "120/120 [==============================] - 0s 291us/sample - loss: 0.2156 - accuracy: 0.9833 - val_loss: 0.2498 - val_accuracy: 0.9000\n",
      "Epoch 711/1000\n",
      "120/120 [==============================] - 0s 350us/sample - loss: 0.2152 - accuracy: 0.9833 - val_loss: 0.2493 - val_accuracy: 0.9000\n",
      "Epoch 712/1000\n",
      "120/120 [==============================] - 0s 308us/sample - loss: 0.2149 - accuracy: 0.9833 - val_loss: 0.2487 - val_accuracy: 0.9000\n",
      "Epoch 713/1000\n",
      "120/120 [==============================] - 0s 359us/sample - loss: 0.2145 - accuracy: 0.9833 - val_loss: 0.2483 - val_accuracy: 0.9000\n",
      "Epoch 714/1000\n",
      "120/120 [==============================] - 0s 300us/sample - loss: 0.2142 - accuracy: 0.9833 - val_loss: 0.2480 - val_accuracy: 0.9000\n",
      "Epoch 715/1000\n",
      "120/120 [==============================] - 0s 304us/sample - loss: 0.2138 - accuracy: 0.9833 - val_loss: 0.2479 - val_accuracy: 0.9000\n",
      "Epoch 716/1000\n",
      "120/120 [==============================] - 0s 303us/sample - loss: 0.2134 - accuracy: 0.9833 - val_loss: 0.2476 - val_accuracy: 0.9000\n",
      "Epoch 717/1000\n",
      "120/120 [==============================] - 0s 315us/sample - loss: 0.2130 - accuracy: 0.9833 - val_loss: 0.2474 - val_accuracy: 0.9000\n",
      "Epoch 718/1000\n",
      "120/120 [==============================] - 0s 310us/sample - loss: 0.2128 - accuracy: 0.9833 - val_loss: 0.2468 - val_accuracy: 0.9000\n",
      "Epoch 719/1000\n",
      "120/120 [==============================] - 0s 293us/sample - loss: 0.2122 - accuracy: 0.9833 - val_loss: 0.2465 - val_accuracy: 0.9000\n",
      "Epoch 720/1000\n",
      "120/120 [==============================] - 0s 342us/sample - loss: 0.2119 - accuracy: 0.9833 - val_loss: 0.2462 - val_accuracy: 0.9000\n",
      "Epoch 721/1000\n",
      "120/120 [==============================] - 0s 331us/sample - loss: 0.2115 - accuracy: 0.9833 - val_loss: 0.2459 - val_accuracy: 0.9000\n",
      "Epoch 722/1000\n",
      "120/120 [==============================] - 0s 343us/sample - loss: 0.2112 - accuracy: 0.9833 - val_loss: 0.2457 - val_accuracy: 0.9000\n",
      "Epoch 723/1000\n",
      "120/120 [==============================] - 0s 272us/sample - loss: 0.2108 - accuracy: 0.9833 - val_loss: 0.2452 - val_accuracy: 0.9000\n",
      "Epoch 724/1000\n",
      "120/120 [==============================] - 0s 362us/sample - loss: 0.2105 - accuracy: 0.9833 - val_loss: 0.2450 - val_accuracy: 0.9000\n",
      "Epoch 725/1000\n",
      "120/120 [==============================] - 0s 382us/sample - loss: 0.2101 - accuracy: 0.9833 - val_loss: 0.2445 - val_accuracy: 0.9000\n",
      "Epoch 726/1000\n",
      "120/120 [==============================] - 0s 334us/sample - loss: 0.2097 - accuracy: 0.9833 - val_loss: 0.2442 - val_accuracy: 0.9000\n",
      "Epoch 727/1000\n",
      "120/120 [==============================] - 0s 320us/sample - loss: 0.2094 - accuracy: 0.9833 - val_loss: 0.2437 - val_accuracy: 0.9000\n",
      "Epoch 728/1000\n",
      "120/120 [==============================] - 0s 341us/sample - loss: 0.2090 - accuracy: 0.9833 - val_loss: 0.2434 - val_accuracy: 0.9000\n",
      "Epoch 729/1000\n",
      "120/120 [==============================] - 0s 288us/sample - loss: 0.2086 - accuracy: 0.9833 - val_loss: 0.2431 - val_accuracy: 0.9000\n",
      "Epoch 730/1000\n",
      "120/120 [==============================] - 0s 389us/sample - loss: 0.2083 - accuracy: 0.9833 - val_loss: 0.2430 - val_accuracy: 0.9000\n",
      "Epoch 731/1000\n",
      "120/120 [==============================] - 0s 327us/sample - loss: 0.2079 - accuracy: 0.9833 - val_loss: 0.2427 - val_accuracy: 0.9000\n",
      "Epoch 732/1000\n",
      "120/120 [==============================] - 0s 279us/sample - loss: 0.2076 - accuracy: 0.9833 - val_loss: 0.2423 - val_accuracy: 0.9000\n",
      "Epoch 733/1000\n",
      "120/120 [==============================] - 0s 398us/sample - loss: 0.2072 - accuracy: 0.9833 - val_loss: 0.2421 - val_accuracy: 0.9000\n",
      "Epoch 734/1000\n",
      "120/120 [==============================] - 0s 298us/sample - loss: 0.2068 - accuracy: 0.9833 - val_loss: 0.2416 - val_accuracy: 0.9000\n",
      "Epoch 735/1000\n",
      "120/120 [==============================] - 0s 293us/sample - loss: 0.2065 - accuracy: 0.9833 - val_loss: 0.2411 - val_accuracy: 0.9000\n",
      "Epoch 736/1000\n",
      "120/120 [==============================] - 0s 296us/sample - loss: 0.2061 - accuracy: 0.9833 - val_loss: 0.2407 - val_accuracy: 0.9000\n",
      "Epoch 737/1000\n",
      "120/120 [==============================] - 0s 324us/sample - loss: 0.2058 - accuracy: 0.9833 - val_loss: 0.2404 - val_accuracy: 0.9000\n",
      "Epoch 738/1000\n",
      "120/120 [==============================] - 0s 332us/sample - loss: 0.2054 - accuracy: 0.9833 - val_loss: 0.2401 - val_accuracy: 0.9000\n",
      "Epoch 739/1000\n",
      "120/120 [==============================] - 0s 325us/sample - loss: 0.2050 - accuracy: 0.9833 - val_loss: 0.2398 - val_accuracy: 0.9000\n",
      "Epoch 740/1000\n",
      "120/120 [==============================] - 0s 304us/sample - loss: 0.2047 - accuracy: 0.9833 - val_loss: 0.2394 - val_accuracy: 0.9000\n",
      "Epoch 741/1000\n",
      "120/120 [==============================] - 0s 377us/sample - loss: 0.2043 - accuracy: 0.9833 - val_loss: 0.2392 - val_accuracy: 0.9000\n",
      "Epoch 742/1000\n",
      "120/120 [==============================] - 0s 328us/sample - loss: 0.2040 - accuracy: 0.9833 - val_loss: 0.2390 - val_accuracy: 0.9000\n",
      "Epoch 743/1000\n",
      "120/120 [==============================] - 0s 344us/sample - loss: 0.2036 - accuracy: 0.9833 - val_loss: 0.2387 - val_accuracy: 0.9000\n",
      "Epoch 744/1000\n",
      "120/120 [==============================] - 0s 337us/sample - loss: 0.2034 - accuracy: 0.9833 - val_loss: 0.2385 - val_accuracy: 0.9000\n",
      "Epoch 745/1000\n",
      "120/120 [==============================] - 0s 360us/sample - loss: 0.2030 - accuracy: 0.9833 - val_loss: 0.2382 - val_accuracy: 0.9000\n",
      "Epoch 746/1000\n",
      "120/120 [==============================] - 0s 318us/sample - loss: 0.2027 - accuracy: 0.9833 - val_loss: 0.2376 - val_accuracy: 0.9000\n",
      "Epoch 747/1000\n",
      "120/120 [==============================] - 0s 333us/sample - loss: 0.2023 - accuracy: 0.9833 - val_loss: 0.2374 - val_accuracy: 0.9000\n",
      "Epoch 748/1000\n",
      "120/120 [==============================] - 0s 318us/sample - loss: 0.2019 - accuracy: 0.9833 - val_loss: 0.2371 - val_accuracy: 0.9000\n",
      "Epoch 749/1000\n",
      "120/120 [==============================] - 0s 356us/sample - loss: 0.2015 - accuracy: 0.9833 - val_loss: 0.2367 - val_accuracy: 0.9000\n",
      "Epoch 750/1000\n",
      "120/120 [==============================] - 0s 293us/sample - loss: 0.2012 - accuracy: 0.9833 - val_loss: 0.2364 - val_accuracy: 0.9000\n",
      "Epoch 751/1000\n",
      "120/120 [==============================] - 0s 293us/sample - loss: 0.2010 - accuracy: 0.9833 - val_loss: 0.2362 - val_accuracy: 0.9000\n",
      "Epoch 752/1000\n",
      "120/120 [==============================] - 0s 322us/sample - loss: 0.2006 - accuracy: 0.9833 - val_loss: 0.2357 - val_accuracy: 0.9000\n",
      "Epoch 753/1000\n",
      "120/120 [==============================] - 0s 280us/sample - loss: 0.2002 - accuracy: 0.9833 - val_loss: 0.2354 - val_accuracy: 0.9000\n",
      "Epoch 754/1000\n",
      "120/120 [==============================] - 0s 304us/sample - loss: 0.1999 - accuracy: 0.9833 - val_loss: 0.2353 - val_accuracy: 0.9000\n",
      "Epoch 755/1000\n",
      "120/120 [==============================] - 0s 332us/sample - loss: 0.1995 - accuracy: 0.9833 - val_loss: 0.2349 - val_accuracy: 0.9000\n",
      "Epoch 756/1000\n",
      "120/120 [==============================] - 0s 336us/sample - loss: 0.1992 - accuracy: 0.9833 - val_loss: 0.2345 - val_accuracy: 0.9000\n",
      "Epoch 757/1000\n",
      "120/120 [==============================] - 0s 347us/sample - loss: 0.1989 - accuracy: 0.9833 - val_loss: 0.2342 - val_accuracy: 0.9000\n",
      "Epoch 758/1000\n",
      "120/120 [==============================] - 0s 333us/sample - loss: 0.1985 - accuracy: 0.9833 - val_loss: 0.2338 - val_accuracy: 0.9000\n",
      "Epoch 759/1000\n",
      "120/120 [==============================] - 0s 322us/sample - loss: 0.1982 - accuracy: 0.9833 - val_loss: 0.2334 - val_accuracy: 0.9000\n",
      "Epoch 760/1000\n",
      "120/120 [==============================] - 0s 312us/sample - loss: 0.1979 - accuracy: 0.9833 - val_loss: 0.2332 - val_accuracy: 0.9000\n",
      "Epoch 761/1000\n",
      "120/120 [==============================] - 0s 357us/sample - loss: 0.1975 - accuracy: 0.9833 - val_loss: 0.2329 - val_accuracy: 0.9000\n",
      "Epoch 762/1000\n",
      "120/120 [==============================] - 0s 308us/sample - loss: 0.1974 - accuracy: 0.9833 - val_loss: 0.2324 - val_accuracy: 0.9000\n",
      "Epoch 763/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 350us/sample - loss: 0.1968 - accuracy: 0.9833 - val_loss: 0.2323 - val_accuracy: 0.9000\n",
      "Epoch 764/1000\n",
      "120/120 [==============================] - 0s 311us/sample - loss: 0.1965 - accuracy: 0.9833 - val_loss: 0.2322 - val_accuracy: 0.9000\n",
      "Epoch 765/1000\n",
      "120/120 [==============================] - 0s 408us/sample - loss: 0.1962 - accuracy: 0.9833 - val_loss: 0.2320 - val_accuracy: 0.9000\n",
      "Epoch 766/1000\n",
      "120/120 [==============================] - 0s 290us/sample - loss: 0.1959 - accuracy: 0.9833 - val_loss: 0.2318 - val_accuracy: 0.9000\n",
      "Epoch 767/1000\n",
      "120/120 [==============================] - 0s 271us/sample - loss: 0.1956 - accuracy: 0.9833 - val_loss: 0.2316 - val_accuracy: 0.9000\n",
      "Epoch 768/1000\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.1953 - accuracy: 0.9833 - val_loss: 0.2312 - val_accuracy: 0.9000\n",
      "Epoch 769/1000\n",
      "120/120 [==============================] - 0s 329us/sample - loss: 0.1949 - accuracy: 0.9833 - val_loss: 0.2311 - val_accuracy: 0.9000\n",
      "Epoch 770/1000\n",
      "120/120 [==============================] - 0s 409us/sample - loss: 0.1946 - accuracy: 0.9833 - val_loss: 0.2308 - val_accuracy: 0.9000\n",
      "Epoch 771/1000\n",
      "120/120 [==============================] - 0s 294us/sample - loss: 0.1944 - accuracy: 0.9833 - val_loss: 0.2302 - val_accuracy: 0.9000\n",
      "Epoch 772/1000\n",
      "120/120 [==============================] - 0s 284us/sample - loss: 0.1939 - accuracy: 0.9833 - val_loss: 0.2298 - val_accuracy: 0.9000\n",
      "Epoch 773/1000\n",
      "120/120 [==============================] - 0s 268us/sample - loss: 0.1936 - accuracy: 0.9833 - val_loss: 0.2296 - val_accuracy: 0.9000\n",
      "Epoch 774/1000\n",
      "120/120 [==============================] - 0s 268us/sample - loss: 0.1934 - accuracy: 0.9833 - val_loss: 0.2294 - val_accuracy: 0.9000\n",
      "Epoch 775/1000\n",
      "120/120 [==============================] - 0s 269us/sample - loss: 0.1930 - accuracy: 0.9833 - val_loss: 0.2289 - val_accuracy: 0.9000\n",
      "Epoch 776/1000\n",
      "120/120 [==============================] - 0s 273us/sample - loss: 0.1927 - accuracy: 0.9833 - val_loss: 0.2288 - val_accuracy: 0.9000\n",
      "Epoch 777/1000\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.1923 - accuracy: 0.9833 - val_loss: 0.2283 - val_accuracy: 0.9000\n",
      "Epoch 778/1000\n",
      "120/120 [==============================] - 0s 289us/sample - loss: 0.1921 - accuracy: 0.9833 - val_loss: 0.2278 - val_accuracy: 0.9000\n",
      "Epoch 779/1000\n",
      "120/120 [==============================] - 0s 302us/sample - loss: 0.1918 - accuracy: 0.9833 - val_loss: 0.2277 - val_accuracy: 0.9000\n",
      "Epoch 780/1000\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.1914 - accuracy: 0.9833 - val_loss: 0.2275 - val_accuracy: 0.9000\n",
      "Epoch 781/1000\n",
      "120/120 [==============================] - 0s 276us/sample - loss: 0.1911 - accuracy: 0.9833 - val_loss: 0.2270 - val_accuracy: 0.9000\n",
      "Epoch 782/1000\n",
      "120/120 [==============================] - 0s 253us/sample - loss: 0.1908 - accuracy: 0.9833 - val_loss: 0.2266 - val_accuracy: 0.9000\n",
      "Epoch 783/1000\n",
      "120/120 [==============================] - 0s 282us/sample - loss: 0.1905 - accuracy: 0.9833 - val_loss: 0.2264 - val_accuracy: 0.9000\n",
      "Epoch 784/1000\n",
      "120/120 [==============================] - 0s 298us/sample - loss: 0.1901 - accuracy: 0.9833 - val_loss: 0.2264 - val_accuracy: 0.9000\n",
      "Epoch 785/1000\n",
      "120/120 [==============================] - 0s 315us/sample - loss: 0.1899 - accuracy: 0.9833 - val_loss: 0.2265 - val_accuracy: 0.9000\n",
      "Epoch 786/1000\n",
      "120/120 [==============================] - 0s 309us/sample - loss: 0.1896 - accuracy: 0.9833 - val_loss: 0.2265 - val_accuracy: 0.9000\n",
      "Epoch 787/1000\n",
      "120/120 [==============================] - 0s 378us/sample - loss: 0.1893 - accuracy: 0.9833 - val_loss: 0.2261 - val_accuracy: 0.9000\n",
      "Epoch 788/1000\n",
      "120/120 [==============================] - 0s 392us/sample - loss: 0.1890 - accuracy: 0.9833 - val_loss: 0.2254 - val_accuracy: 0.9000\n",
      "Epoch 789/1000\n",
      "120/120 [==============================] - 0s 329us/sample - loss: 0.1887 - accuracy: 0.9833 - val_loss: 0.2248 - val_accuracy: 0.9000\n",
      "Epoch 790/1000\n",
      "120/120 [==============================] - 0s 343us/sample - loss: 0.1883 - accuracy: 0.9833 - val_loss: 0.2244 - val_accuracy: 0.9000\n",
      "Epoch 791/1000\n",
      "120/120 [==============================] - 0s 323us/sample - loss: 0.1880 - accuracy: 0.9833 - val_loss: 0.2243 - val_accuracy: 0.9000\n",
      "Epoch 792/1000\n",
      "120/120 [==============================] - 0s 333us/sample - loss: 0.1877 - accuracy: 0.9833 - val_loss: 0.2240 - val_accuracy: 0.9000\n",
      "Epoch 793/1000\n",
      "120/120 [==============================] - 0s 356us/sample - loss: 0.1874 - accuracy: 0.9833 - val_loss: 0.2238 - val_accuracy: 0.9000\n",
      "Epoch 794/1000\n",
      "120/120 [==============================] - 0s 356us/sample - loss: 0.1871 - accuracy: 0.9833 - val_loss: 0.2235 - val_accuracy: 0.9000\n",
      "Epoch 795/1000\n",
      "120/120 [==============================] - 0s 328us/sample - loss: 0.1868 - accuracy: 0.9833 - val_loss: 0.2233 - val_accuracy: 0.9000\n",
      "Epoch 796/1000\n",
      "120/120 [==============================] - 0s 317us/sample - loss: 0.1864 - accuracy: 0.9833 - val_loss: 0.2229 - val_accuracy: 0.9000\n",
      "Epoch 797/1000\n",
      "120/120 [==============================] - 0s 256us/sample - loss: 0.1862 - accuracy: 0.9833 - val_loss: 0.2226 - val_accuracy: 0.9000\n",
      "Epoch 798/1000\n",
      "120/120 [==============================] - 0s 361us/sample - loss: 0.1858 - accuracy: 0.9833 - val_loss: 0.2223 - val_accuracy: 0.9000\n",
      "Epoch 799/1000\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.1856 - accuracy: 0.9833 - val_loss: 0.2220 - val_accuracy: 0.9000\n",
      "Epoch 800/1000\n",
      "120/120 [==============================] - 0s 300us/sample - loss: 0.1853 - accuracy: 0.9833 - val_loss: 0.2217 - val_accuracy: 0.9000\n",
      "Epoch 801/1000\n",
      "120/120 [==============================] - 0s 229us/sample - loss: 0.1850 - accuracy: 0.9833 - val_loss: 0.2214 - val_accuracy: 0.9000\n",
      "Epoch 802/1000\n",
      "120/120 [==============================] - 0s 231us/sample - loss: 0.1849 - accuracy: 0.9833 - val_loss: 0.2208 - val_accuracy: 0.9000\n",
      "Epoch 803/1000\n",
      "120/120 [==============================] - 0s 286us/sample - loss: 0.1844 - accuracy: 0.9833 - val_loss: 0.2204 - val_accuracy: 0.9000\n",
      "Epoch 804/1000\n",
      "120/120 [==============================] - 0s 243us/sample - loss: 0.1841 - accuracy: 0.9833 - val_loss: 0.2204 - val_accuracy: 0.9000\n",
      "Epoch 805/1000\n",
      "120/120 [==============================] - 0s 256us/sample - loss: 0.1838 - accuracy: 0.9833 - val_loss: 0.2203 - val_accuracy: 0.9000\n",
      "Epoch 806/1000\n",
      "120/120 [==============================] - 0s 384us/sample - loss: 0.1835 - accuracy: 0.9833 - val_loss: 0.2200 - val_accuracy: 0.9000\n",
      "Epoch 807/1000\n",
      "120/120 [==============================] - 0s 264us/sample - loss: 0.1833 - accuracy: 0.9833 - val_loss: 0.2193 - val_accuracy: 0.9000\n",
      "Epoch 808/1000\n",
      "120/120 [==============================] - 0s 352us/sample - loss: 0.1829 - accuracy: 0.9833 - val_loss: 0.2191 - val_accuracy: 0.9000\n",
      "Epoch 809/1000\n",
      "120/120 [==============================] - 0s 346us/sample - loss: 0.1826 - accuracy: 0.9833 - val_loss: 0.2188 - val_accuracy: 0.9000\n",
      "Epoch 810/1000\n",
      "120/120 [==============================] - 0s 414us/sample - loss: 0.1823 - accuracy: 0.9833 - val_loss: 0.2186 - val_accuracy: 0.9000\n",
      "Epoch 811/1000\n",
      "120/120 [==============================] - 0s 361us/sample - loss: 0.1820 - accuracy: 0.9833 - val_loss: 0.2186 - val_accuracy: 0.9000\n",
      "Epoch 812/1000\n",
      "120/120 [==============================] - 0s 342us/sample - loss: 0.1817 - accuracy: 0.9833 - val_loss: 0.2184 - val_accuracy: 0.9000\n",
      "Epoch 813/1000\n",
      "120/120 [==============================] - 0s 291us/sample - loss: 0.1815 - accuracy: 0.9833 - val_loss: 0.2185 - val_accuracy: 0.9000\n",
      "Epoch 814/1000\n",
      "120/120 [==============================] - 0s 295us/sample - loss: 0.1812 - accuracy: 0.9833 - val_loss: 0.2183 - val_accuracy: 0.9000\n",
      "Epoch 815/1000\n",
      "120/120 [==============================] - 0s 264us/sample - loss: 0.1809 - accuracy: 0.9833 - val_loss: 0.2182 - val_accuracy: 0.9000\n",
      "Epoch 816/1000\n",
      "120/120 [==============================] - 0s 287us/sample - loss: 0.1807 - accuracy: 0.9833 - val_loss: 0.2181 - val_accuracy: 0.9000\n",
      "Epoch 817/1000\n",
      "120/120 [==============================] - 0s 301us/sample - loss: 0.1803 - accuracy: 0.9833 - val_loss: 0.2177 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 818/1000\n",
      "120/120 [==============================] - 0s 296us/sample - loss: 0.1800 - accuracy: 0.9833 - val_loss: 0.2173 - val_accuracy: 0.9000\n",
      "Epoch 819/1000\n",
      "120/120 [==============================] - 0s 277us/sample - loss: 0.1797 - accuracy: 0.9833 - val_loss: 0.2167 - val_accuracy: 0.9000\n",
      "Epoch 820/1000\n",
      "120/120 [==============================] - 0s 292us/sample - loss: 0.1795 - accuracy: 0.9833 - val_loss: 0.2163 - val_accuracy: 0.9000\n",
      "Epoch 821/1000\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.1791 - accuracy: 0.9833 - val_loss: 0.2159 - val_accuracy: 0.9000\n",
      "Epoch 822/1000\n",
      "120/120 [==============================] - 0s 268us/sample - loss: 0.1789 - accuracy: 0.9833 - val_loss: 0.2154 - val_accuracy: 0.9000\n",
      "Epoch 823/1000\n",
      "120/120 [==============================] - 0s 272us/sample - loss: 0.1786 - accuracy: 0.9833 - val_loss: 0.2149 - val_accuracy: 0.9333\n",
      "Epoch 824/1000\n",
      "120/120 [==============================] - 0s 279us/sample - loss: 0.1784 - accuracy: 0.9833 - val_loss: 0.2146 - val_accuracy: 0.9333\n",
      "Epoch 825/1000\n",
      "120/120 [==============================] - 0s 271us/sample - loss: 0.1781 - accuracy: 0.9833 - val_loss: 0.2144 - val_accuracy: 0.9333\n",
      "Epoch 826/1000\n",
      "120/120 [==============================] - 0s 324us/sample - loss: 0.1779 - accuracy: 0.9833 - val_loss: 0.2144 - val_accuracy: 0.9000\n",
      "Epoch 827/1000\n",
      "120/120 [==============================] - 0s 359us/sample - loss: 0.1775 - accuracy: 0.9833 - val_loss: 0.2141 - val_accuracy: 0.9000\n",
      "Epoch 828/1000\n",
      "120/120 [==============================] - 0s 309us/sample - loss: 0.1773 - accuracy: 0.9833 - val_loss: 0.2140 - val_accuracy: 0.9000\n",
      "Epoch 829/1000\n",
      "120/120 [==============================] - 0s 312us/sample - loss: 0.1771 - accuracy: 0.9833 - val_loss: 0.2140 - val_accuracy: 0.9000\n",
      "Epoch 830/1000\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.1767 - accuracy: 0.9833 - val_loss: 0.2135 - val_accuracy: 0.9000\n",
      "Epoch 831/1000\n",
      "120/120 [==============================] - 0s 302us/sample - loss: 0.1764 - accuracy: 0.9833 - val_loss: 0.2133 - val_accuracy: 0.9000\n",
      "Epoch 832/1000\n",
      "120/120 [==============================] - 0s 316us/sample - loss: 0.1761 - accuracy: 0.9833 - val_loss: 0.2132 - val_accuracy: 0.9000\n",
      "Epoch 833/1000\n",
      "120/120 [==============================] - 0s 308us/sample - loss: 0.1760 - accuracy: 0.9833 - val_loss: 0.2126 - val_accuracy: 0.9000\n",
      "Epoch 834/1000\n",
      "120/120 [==============================] - 0s 360us/sample - loss: 0.1757 - accuracy: 0.9833 - val_loss: 0.2124 - val_accuracy: 0.9000\n",
      "Epoch 835/1000\n",
      "120/120 [==============================] - 0s 371us/sample - loss: 0.1753 - accuracy: 0.9833 - val_loss: 0.2122 - val_accuracy: 0.9000\n",
      "Epoch 836/1000\n",
      "120/120 [==============================] - 0s 308us/sample - loss: 0.1751 - accuracy: 0.9833 - val_loss: 0.2124 - val_accuracy: 0.9000\n",
      "Epoch 837/1000\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 0.1748 - accuracy: 0.9833 - val_loss: 0.2121 - val_accuracy: 0.9000\n",
      "Epoch 838/1000\n",
      "120/120 [==============================] - 0s 313us/sample - loss: 0.1746 - accuracy: 0.9833 - val_loss: 0.2121 - val_accuracy: 0.9000\n",
      "Epoch 839/1000\n",
      "120/120 [==============================] - 0s 354us/sample - loss: 0.1742 - accuracy: 0.9833 - val_loss: 0.2118 - val_accuracy: 0.9000\n",
      "Epoch 840/1000\n",
      "120/120 [==============================] - 0s 351us/sample - loss: 0.1740 - accuracy: 0.9833 - val_loss: 0.2117 - val_accuracy: 0.9000\n",
      "Epoch 841/1000\n",
      "120/120 [==============================] - 0s 252us/sample - loss: 0.1737 - accuracy: 0.9833 - val_loss: 0.2112 - val_accuracy: 0.9000\n",
      "Epoch 842/1000\n",
      "120/120 [==============================] - 0s 302us/sample - loss: 0.1734 - accuracy: 0.9833 - val_loss: 0.2109 - val_accuracy: 0.9000\n",
      "Epoch 843/1000\n",
      "120/120 [==============================] - 0s 397us/sample - loss: 0.1732 - accuracy: 0.9833 - val_loss: 0.2106 - val_accuracy: 0.9000\n",
      "Epoch 844/1000\n",
      "120/120 [==============================] - 0s 315us/sample - loss: 0.1729 - accuracy: 0.9833 - val_loss: 0.2105 - val_accuracy: 0.9000\n",
      "Epoch 845/1000\n",
      "120/120 [==============================] - 0s 341us/sample - loss: 0.1726 - accuracy: 0.9833 - val_loss: 0.2103 - val_accuracy: 0.9000\n",
      "Epoch 846/1000\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.1724 - accuracy: 0.9833 - val_loss: 0.2103 - val_accuracy: 0.9000\n",
      "Epoch 847/1000\n",
      "120/120 [==============================] - 0s 358us/sample - loss: 0.1721 - accuracy: 0.9833 - val_loss: 0.2100 - val_accuracy: 0.9000\n",
      "Epoch 848/1000\n",
      "120/120 [==============================] - 0s 410us/sample - loss: 0.1719 - accuracy: 0.9833 - val_loss: 0.2099 - val_accuracy: 0.9000\n",
      "Epoch 849/1000\n",
      "120/120 [==============================] - 0s 372us/sample - loss: 0.1716 - accuracy: 0.9833 - val_loss: 0.2094 - val_accuracy: 0.9000\n",
      "Epoch 850/1000\n",
      "120/120 [==============================] - 0s 304us/sample - loss: 0.1713 - accuracy: 0.9833 - val_loss: 0.2091 - val_accuracy: 0.9000\n",
      "Epoch 851/1000\n",
      "120/120 [==============================] - 0s 315us/sample - loss: 0.1710 - accuracy: 0.9833 - val_loss: 0.2087 - val_accuracy: 0.9000\n",
      "Epoch 852/1000\n",
      "120/120 [==============================] - 0s 282us/sample - loss: 0.1708 - accuracy: 0.9833 - val_loss: 0.2082 - val_accuracy: 0.9000\n",
      "Epoch 853/1000\n",
      "120/120 [==============================] - 0s 226us/sample - loss: 0.1705 - accuracy: 0.9833 - val_loss: 0.2079 - val_accuracy: 0.9000\n",
      "Epoch 854/1000\n",
      "120/120 [==============================] - 0s 332us/sample - loss: 0.1703 - accuracy: 0.9833 - val_loss: 0.2076 - val_accuracy: 0.9000\n",
      "Epoch 855/1000\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.1701 - accuracy: 0.9833 - val_loss: 0.2077 - val_accuracy: 0.9000\n",
      "Epoch 856/1000\n",
      "120/120 [==============================] - 0s 213us/sample - loss: 0.1701 - accuracy: 0.9833 - val_loss: 0.2079 - val_accuracy: 0.9000\n",
      "Epoch 857/1000\n",
      "120/120 [==============================] - 0s 349us/sample - loss: 0.1695 - accuracy: 0.9833 - val_loss: 0.2073 - val_accuracy: 0.9000\n",
      "Epoch 858/1000\n",
      "120/120 [==============================] - 0s 292us/sample - loss: 0.1693 - accuracy: 0.9833 - val_loss: 0.2069 - val_accuracy: 0.9000\n",
      "Epoch 859/1000\n",
      "120/120 [==============================] - 0s 289us/sample - loss: 0.1690 - accuracy: 0.9833 - val_loss: 0.2063 - val_accuracy: 0.9333\n",
      "Epoch 860/1000\n",
      "120/120 [==============================] - 0s 256us/sample - loss: 0.1688 - accuracy: 0.9833 - val_loss: 0.2061 - val_accuracy: 0.9333\n",
      "Epoch 861/1000\n",
      "120/120 [==============================] - 0s 271us/sample - loss: 0.1686 - accuracy: 0.9833 - val_loss: 0.2056 - val_accuracy: 0.9333\n",
      "Epoch 862/1000\n",
      "120/120 [==============================] - 0s 245us/sample - loss: 0.1682 - accuracy: 0.9833 - val_loss: 0.2055 - val_accuracy: 0.9333\n",
      "Epoch 863/1000\n",
      "120/120 [==============================] - 0s 333us/sample - loss: 0.1681 - accuracy: 0.9833 - val_loss: 0.2055 - val_accuracy: 0.9333\n",
      "Epoch 864/1000\n",
      "120/120 [==============================] - 0s 235us/sample - loss: 0.1677 - accuracy: 0.9833 - val_loss: 0.2053 - val_accuracy: 0.9000\n",
      "Epoch 865/1000\n",
      "120/120 [==============================] - 0s 229us/sample - loss: 0.1675 - accuracy: 0.9833 - val_loss: 0.2049 - val_accuracy: 0.9333\n",
      "Epoch 866/1000\n",
      "120/120 [==============================] - 0s 338us/sample - loss: 0.1673 - accuracy: 0.9833 - val_loss: 0.2045 - val_accuracy: 0.9333\n",
      "Epoch 867/1000\n",
      "120/120 [==============================] - 0s 244us/sample - loss: 0.1670 - accuracy: 0.9833 - val_loss: 0.2044 - val_accuracy: 0.9333\n",
      "Epoch 868/1000\n",
      "120/120 [==============================] - 0s 263us/sample - loss: 0.1667 - accuracy: 0.9833 - val_loss: 0.2043 - val_accuracy: 0.9333\n",
      "Epoch 869/1000\n",
      "120/120 [==============================] - 0s 238us/sample - loss: 0.1665 - accuracy: 0.9833 - val_loss: 0.2042 - val_accuracy: 0.9333\n",
      "Epoch 870/1000\n",
      "120/120 [==============================] - 0s 299us/sample - loss: 0.1662 - accuracy: 0.9833 - val_loss: 0.2041 - val_accuracy: 0.9000\n",
      "Epoch 871/1000\n",
      "120/120 [==============================] - 0s 446us/sample - loss: 0.1660 - accuracy: 0.9833 - val_loss: 0.2042 - val_accuracy: 0.9000\n",
      "Epoch 872/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 395us/sample - loss: 0.1658 - accuracy: 0.9833 - val_loss: 0.2038 - val_accuracy: 0.9000\n",
      "Epoch 873/1000\n",
      "120/120 [==============================] - 0s 285us/sample - loss: 0.1655 - accuracy: 0.9833 - val_loss: 0.2036 - val_accuracy: 0.9000\n",
      "Epoch 874/1000\n",
      "120/120 [==============================] - 0s 335us/sample - loss: 0.1653 - accuracy: 0.9833 - val_loss: 0.2038 - val_accuracy: 0.9000\n",
      "Epoch 875/1000\n",
      "120/120 [==============================] - 0s 326us/sample - loss: 0.1650 - accuracy: 0.9833 - val_loss: 0.2036 - val_accuracy: 0.9000\n",
      "Epoch 876/1000\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 0.1650 - accuracy: 0.9833 - val_loss: 0.2038 - val_accuracy: 0.9000\n",
      "Epoch 877/1000\n",
      "120/120 [==============================] - 0s 228us/sample - loss: 0.1645 - accuracy: 0.9833 - val_loss: 0.2032 - val_accuracy: 0.9000\n",
      "Epoch 878/1000\n",
      "120/120 [==============================] - 0s 281us/sample - loss: 0.1643 - accuracy: 0.9833 - val_loss: 0.2029 - val_accuracy: 0.9000\n",
      "Epoch 879/1000\n",
      "120/120 [==============================] - 0s 236us/sample - loss: 0.1640 - accuracy: 0.9833 - val_loss: 0.2025 - val_accuracy: 0.9000\n",
      "Epoch 880/1000\n",
      "120/120 [==============================] - 0s 255us/sample - loss: 0.1638 - accuracy: 0.9833 - val_loss: 0.2021 - val_accuracy: 0.9000\n",
      "Epoch 881/1000\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.1635 - accuracy: 0.9833 - val_loss: 0.2017 - val_accuracy: 0.9000\n",
      "Epoch 882/1000\n",
      "120/120 [==============================] - 0s 269us/sample - loss: 0.1633 - accuracy: 0.9833 - val_loss: 0.2014 - val_accuracy: 0.9333\n",
      "Epoch 883/1000\n",
      "120/120 [==============================] - 0s 288us/sample - loss: 0.1630 - accuracy: 0.9833 - val_loss: 0.2012 - val_accuracy: 0.9000\n",
      "Epoch 884/1000\n",
      "120/120 [==============================] - 0s 303us/sample - loss: 0.1628 - accuracy: 0.9833 - val_loss: 0.2012 - val_accuracy: 0.9000\n",
      "Epoch 885/1000\n",
      "120/120 [==============================] - 0s 236us/sample - loss: 0.1626 - accuracy: 0.9833 - val_loss: 0.2007 - val_accuracy: 0.9333\n",
      "Epoch 886/1000\n",
      "120/120 [==============================] - 0s 254us/sample - loss: 0.1623 - accuracy: 0.9833 - val_loss: 0.2004 - val_accuracy: 0.9333\n",
      "Epoch 887/1000\n",
      "120/120 [==============================] - 0s 297us/sample - loss: 0.1621 - accuracy: 0.9833 - val_loss: 0.2003 - val_accuracy: 0.9333\n",
      "Epoch 888/1000\n",
      "120/120 [==============================] - 0s 276us/sample - loss: 0.1620 - accuracy: 0.9833 - val_loss: 0.2003 - val_accuracy: 0.9000\n",
      "Epoch 889/1000\n",
      "120/120 [==============================] - 0s 289us/sample - loss: 0.1616 - accuracy: 0.9833 - val_loss: 0.1999 - val_accuracy: 0.9333\n",
      "Epoch 890/1000\n",
      "120/120 [==============================] - 0s 303us/sample - loss: 0.1614 - accuracy: 0.9833 - val_loss: 0.1996 - val_accuracy: 0.9333\n",
      "Epoch 891/1000\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.1611 - accuracy: 0.9833 - val_loss: 0.1994 - val_accuracy: 0.9333\n",
      "Epoch 892/1000\n",
      "120/120 [==============================] - 0s 272us/sample - loss: 0.1610 - accuracy: 0.9833 - val_loss: 0.1990 - val_accuracy: 0.9333\n",
      "Epoch 893/1000\n",
      "120/120 [==============================] - 0s 277us/sample - loss: 0.1607 - accuracy: 0.9833 - val_loss: 0.1991 - val_accuracy: 0.9000\n",
      "Epoch 894/1000\n",
      "120/120 [==============================] - 0s 281us/sample - loss: 0.1605 - accuracy: 0.9833 - val_loss: 0.1992 - val_accuracy: 0.9000\n",
      "Epoch 895/1000\n",
      "120/120 [==============================] - 0s 238us/sample - loss: 0.1602 - accuracy: 0.9833 - val_loss: 0.1989 - val_accuracy: 0.9000\n",
      "Epoch 896/1000\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.1600 - accuracy: 0.9833 - val_loss: 0.1989 - val_accuracy: 0.9000\n",
      "Epoch 897/1000\n",
      "120/120 [==============================] - 0s 292us/sample - loss: 0.1597 - accuracy: 0.9833 - val_loss: 0.1988 - val_accuracy: 0.9000\n",
      "Epoch 898/1000\n",
      "120/120 [==============================] - 0s 252us/sample - loss: 0.1595 - accuracy: 0.9833 - val_loss: 0.1987 - val_accuracy: 0.9000\n",
      "Epoch 899/1000\n",
      "120/120 [==============================] - 0s 243us/sample - loss: 0.1593 - accuracy: 0.9833 - val_loss: 0.1983 - val_accuracy: 0.9000\n",
      "Epoch 900/1000\n",
      "120/120 [==============================] - 0s 273us/sample - loss: 0.1591 - accuracy: 0.9833 - val_loss: 0.1984 - val_accuracy: 0.9000\n",
      "Epoch 901/1000\n",
      "120/120 [==============================] - 0s 293us/sample - loss: 0.1588 - accuracy: 0.9833 - val_loss: 0.1981 - val_accuracy: 0.9000\n",
      "Epoch 902/1000\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.1587 - accuracy: 0.9833 - val_loss: 0.1979 - val_accuracy: 0.9000\n",
      "Epoch 903/1000\n",
      "120/120 [==============================] - 0s 299us/sample - loss: 0.1583 - accuracy: 0.9833 - val_loss: 0.1975 - val_accuracy: 0.9000\n",
      "Epoch 904/1000\n",
      "120/120 [==============================] - 0s 349us/sample - loss: 0.1582 - accuracy: 0.9833 - val_loss: 0.1970 - val_accuracy: 0.9000\n",
      "Epoch 905/1000\n",
      "120/120 [==============================] - 0s 391us/sample - loss: 0.1580 - accuracy: 0.9833 - val_loss: 0.1967 - val_accuracy: 0.9000\n",
      "Epoch 906/1000\n",
      "120/120 [==============================] - 0s 402us/sample - loss: 0.1577 - accuracy: 0.9833 - val_loss: 0.1966 - val_accuracy: 0.9000\n",
      "Epoch 907/1000\n",
      "120/120 [==============================] - 0s 269us/sample - loss: 0.1574 - accuracy: 0.9833 - val_loss: 0.1965 - val_accuracy: 0.9000\n",
      "Epoch 908/1000\n",
      "120/120 [==============================] - 0s 352us/sample - loss: 0.1572 - accuracy: 0.9833 - val_loss: 0.1963 - val_accuracy: 0.9000\n",
      "Epoch 909/1000\n",
      "120/120 [==============================] - 0s 315us/sample - loss: 0.1570 - accuracy: 0.9833 - val_loss: 0.1961 - val_accuracy: 0.9000\n",
      "Epoch 910/1000\n",
      "120/120 [==============================] - 0s 331us/sample - loss: 0.1568 - accuracy: 0.9833 - val_loss: 0.1958 - val_accuracy: 0.9000\n",
      "Epoch 911/1000\n",
      "120/120 [==============================] - 0s 332us/sample - loss: 0.1566 - accuracy: 0.9833 - val_loss: 0.1955 - val_accuracy: 0.9333\n",
      "Epoch 912/1000\n",
      "120/120 [==============================] - 0s 364us/sample - loss: 0.1563 - accuracy: 0.9833 - val_loss: 0.1953 - val_accuracy: 0.9333\n",
      "Epoch 913/1000\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.1561 - accuracy: 0.9833 - val_loss: 0.1947 - val_accuracy: 0.9333\n",
      "Epoch 914/1000\n",
      "120/120 [==============================] - 0s 286us/sample - loss: 0.1559 - accuracy: 0.9833 - val_loss: 0.1944 - val_accuracy: 0.9333\n",
      "Epoch 915/1000\n",
      "120/120 [==============================] - 0s 296us/sample - loss: 0.1557 - accuracy: 0.9833 - val_loss: 0.1941 - val_accuracy: 0.9333\n",
      "Epoch 916/1000\n",
      "120/120 [==============================] - 0s 246us/sample - loss: 0.1554 - accuracy: 0.9833 - val_loss: 0.1939 - val_accuracy: 0.9333\n",
      "Epoch 917/1000\n",
      "120/120 [==============================] - 0s 286us/sample - loss: 0.1552 - accuracy: 0.9833 - val_loss: 0.1939 - val_accuracy: 0.9333\n",
      "Epoch 918/1000\n",
      "120/120 [==============================] - 0s 263us/sample - loss: 0.1550 - accuracy: 0.9833 - val_loss: 0.1936 - val_accuracy: 0.9333\n",
      "Epoch 919/1000\n",
      "120/120 [==============================] - 0s 328us/sample - loss: 0.1548 - accuracy: 0.9833 - val_loss: 0.1935 - val_accuracy: 0.9333\n",
      "Epoch 920/1000\n",
      "120/120 [==============================] - 0s 261us/sample - loss: 0.1546 - accuracy: 0.9833 - val_loss: 0.1932 - val_accuracy: 0.9333\n",
      "Epoch 921/1000\n",
      "120/120 [==============================] - 0s 277us/sample - loss: 0.1543 - accuracy: 0.9833 - val_loss: 0.1931 - val_accuracy: 0.9333\n",
      "Epoch 922/1000\n",
      "120/120 [==============================] - 0s 243us/sample - loss: 0.1542 - accuracy: 0.9833 - val_loss: 0.1931 - val_accuracy: 0.9333\n",
      "Epoch 923/1000\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.1539 - accuracy: 0.9833 - val_loss: 0.1927 - val_accuracy: 0.9333\n",
      "Epoch 924/1000\n",
      "120/120 [==============================] - 0s 243us/sample - loss: 0.1537 - accuracy: 0.9833 - val_loss: 0.1924 - val_accuracy: 0.9333\n",
      "Epoch 925/1000\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.1536 - accuracy: 0.9833 - val_loss: 0.1926 - val_accuracy: 0.9333\n",
      "Epoch 926/1000\n",
      "120/120 [==============================] - 0s 310us/sample - loss: 0.1533 - accuracy: 0.9833 - val_loss: 0.1921 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 927/1000\n",
      "120/120 [==============================] - 0s 349us/sample - loss: 0.1531 - accuracy: 0.9833 - val_loss: 0.1919 - val_accuracy: 0.9333\n",
      "Epoch 928/1000\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 0.1528 - accuracy: 0.9833 - val_loss: 0.1919 - val_accuracy: 0.9333\n",
      "Epoch 929/1000\n",
      "120/120 [==============================] - 0s 298us/sample - loss: 0.1527 - accuracy: 0.9833 - val_loss: 0.1920 - val_accuracy: 0.9333\n",
      "Epoch 930/1000\n",
      "120/120 [==============================] - 0s 332us/sample - loss: 0.1525 - accuracy: 0.9833 - val_loss: 0.1917 - val_accuracy: 0.9333\n",
      "Epoch 931/1000\n",
      "120/120 [==============================] - 0s 297us/sample - loss: 0.1522 - accuracy: 0.9833 - val_loss: 0.1920 - val_accuracy: 0.9000\n",
      "Epoch 932/1000\n",
      "120/120 [==============================] - 0s 315us/sample - loss: 0.1521 - accuracy: 0.9833 - val_loss: 0.1923 - val_accuracy: 0.9000\n",
      "Epoch 933/1000\n",
      "120/120 [==============================] - 0s 314us/sample - loss: 0.1518 - accuracy: 0.9833 - val_loss: 0.1919 - val_accuracy: 0.9000\n",
      "Epoch 934/1000\n",
      "120/120 [==============================] - 0s 228us/sample - loss: 0.1517 - accuracy: 0.9833 - val_loss: 0.1918 - val_accuracy: 0.9000\n",
      "Epoch 935/1000\n",
      "120/120 [==============================] - 0s 264us/sample - loss: 0.1513 - accuracy: 0.9833 - val_loss: 0.1912 - val_accuracy: 0.9000\n",
      "Epoch 936/1000\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.1511 - accuracy: 0.9833 - val_loss: 0.1907 - val_accuracy: 0.9333\n",
      "Epoch 937/1000\n",
      "120/120 [==============================] - 0s 251us/sample - loss: 0.1509 - accuracy: 0.9833 - val_loss: 0.1904 - val_accuracy: 0.9333\n",
      "Epoch 938/1000\n",
      "120/120 [==============================] - 0s 278us/sample - loss: 0.1507 - accuracy: 0.9833 - val_loss: 0.1902 - val_accuracy: 0.9333\n",
      "Epoch 939/1000\n",
      "120/120 [==============================] - 0s 278us/sample - loss: 0.1505 - accuracy: 0.9833 - val_loss: 0.1896 - val_accuracy: 0.9333\n",
      "Epoch 940/1000\n",
      "120/120 [==============================] - 0s 276us/sample - loss: 0.1503 - accuracy: 0.9833 - val_loss: 0.1894 - val_accuracy: 0.9333\n",
      "Epoch 941/1000\n",
      "120/120 [==============================] - 0s 365us/sample - loss: 0.1501 - accuracy: 0.9833 - val_loss: 0.1892 - val_accuracy: 0.9333\n",
      "Epoch 942/1000\n",
      "120/120 [==============================] - 0s 325us/sample - loss: 0.1501 - accuracy: 0.9833 - val_loss: 0.1893 - val_accuracy: 0.9333\n",
      "Epoch 943/1000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1972 - accuracy: 0.96 - 0s 296us/sample - loss: 0.1497 - accuracy: 0.9833 - val_loss: 0.1889 - val_accuracy: 0.9333\n",
      "Epoch 944/1000\n",
      "120/120 [==============================] - 0s 353us/sample - loss: 0.1495 - accuracy: 0.9833 - val_loss: 0.1887 - val_accuracy: 0.9333\n",
      "Epoch 945/1000\n",
      "120/120 [==============================] - 0s 328us/sample - loss: 0.1493 - accuracy: 0.9833 - val_loss: 0.1883 - val_accuracy: 0.9333\n",
      "Epoch 946/1000\n",
      "120/120 [==============================] - 0s 319us/sample - loss: 0.1491 - accuracy: 0.9833 - val_loss: 0.1883 - val_accuracy: 0.9333\n",
      "Epoch 947/1000\n",
      "120/120 [==============================] - 0s 341us/sample - loss: 0.1488 - accuracy: 0.9833 - val_loss: 0.1882 - val_accuracy: 0.9333\n",
      "Epoch 948/1000\n",
      "120/120 [==============================] - 0s 313us/sample - loss: 0.1487 - accuracy: 0.9833 - val_loss: 0.1881 - val_accuracy: 0.9333\n",
      "Epoch 949/1000\n",
      "120/120 [==============================] - 0s 356us/sample - loss: 0.1484 - accuracy: 0.9833 - val_loss: 0.1878 - val_accuracy: 0.9333\n",
      "Epoch 950/1000\n",
      "120/120 [==============================] - 0s 317us/sample - loss: 0.1482 - accuracy: 0.9833 - val_loss: 0.1876 - val_accuracy: 0.9333\n",
      "Epoch 951/1000\n",
      "120/120 [==============================] - 0s 259us/sample - loss: 0.1481 - accuracy: 0.9833 - val_loss: 0.1873 - val_accuracy: 0.9333\n",
      "Epoch 952/1000\n",
      "120/120 [==============================] - 0s 324us/sample - loss: 0.1478 - accuracy: 0.9833 - val_loss: 0.1872 - val_accuracy: 0.9333\n",
      "Epoch 953/1000\n",
      "120/120 [==============================] - 0s 365us/sample - loss: 0.1476 - accuracy: 0.9833 - val_loss: 0.1873 - val_accuracy: 0.9333\n",
      "Epoch 954/1000\n",
      "120/120 [==============================] - 0s 286us/sample - loss: 0.1475 - accuracy: 0.9833 - val_loss: 0.1874 - val_accuracy: 0.9333\n",
      "Epoch 955/1000\n",
      "120/120 [==============================] - 0s 288us/sample - loss: 0.1473 - accuracy: 0.9833 - val_loss: 0.1871 - val_accuracy: 0.9333\n",
      "Epoch 956/1000\n",
      "120/120 [==============================] - 0s 299us/sample - loss: 0.1470 - accuracy: 0.9833 - val_loss: 0.1870 - val_accuracy: 0.9333\n",
      "Epoch 957/1000\n",
      "120/120 [==============================] - 0s 246us/sample - loss: 0.1468 - accuracy: 0.9833 - val_loss: 0.1868 - val_accuracy: 0.9333\n",
      "Epoch 958/1000\n",
      "120/120 [==============================] - 0s 299us/sample - loss: 0.1466 - accuracy: 0.9833 - val_loss: 0.1866 - val_accuracy: 0.9333\n",
      "Epoch 959/1000\n",
      "120/120 [==============================] - 0s 302us/sample - loss: 0.1464 - accuracy: 0.9833 - val_loss: 0.1863 - val_accuracy: 0.9333\n",
      "Epoch 960/1000\n",
      "120/120 [==============================] - 0s 322us/sample - loss: 0.1463 - accuracy: 0.9833 - val_loss: 0.1862 - val_accuracy: 0.9333\n",
      "Epoch 961/1000\n",
      "120/120 [==============================] - 0s 429us/sample - loss: 0.1460 - accuracy: 0.9833 - val_loss: 0.1859 - val_accuracy: 0.9333\n",
      "Epoch 962/1000\n",
      "120/120 [==============================] - 0s 330us/sample - loss: 0.1459 - accuracy: 0.9833 - val_loss: 0.1858 - val_accuracy: 0.9333\n",
      "Epoch 963/1000\n",
      "120/120 [==============================] - 0s 321us/sample - loss: 0.1457 - accuracy: 0.9833 - val_loss: 0.1854 - val_accuracy: 0.9333\n",
      "Epoch 964/1000\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 0.1455 - accuracy: 0.9833 - val_loss: 0.1854 - val_accuracy: 0.9333\n",
      "Epoch 965/1000\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 0.1453 - accuracy: 0.9833 - val_loss: 0.1853 - val_accuracy: 0.9333\n",
      "Epoch 966/1000\n",
      "120/120 [==============================] - 0s 310us/sample - loss: 0.1451 - accuracy: 0.9833 - val_loss: 0.1852 - val_accuracy: 0.9333\n",
      "Epoch 967/1000\n",
      "120/120 [==============================] - 0s 333us/sample - loss: 0.1449 - accuracy: 0.9833 - val_loss: 0.1848 - val_accuracy: 0.9333\n",
      "Epoch 968/1000\n",
      "120/120 [==============================] - 0s 281us/sample - loss: 0.1447 - accuracy: 0.9833 - val_loss: 0.1844 - val_accuracy: 0.9333\n",
      "Epoch 969/1000\n",
      "120/120 [==============================] - 0s 362us/sample - loss: 0.1446 - accuracy: 0.9833 - val_loss: 0.1839 - val_accuracy: 0.9333\n",
      "Epoch 970/1000\n",
      "120/120 [==============================] - 0s 256us/sample - loss: 0.1443 - accuracy: 0.9833 - val_loss: 0.1840 - val_accuracy: 0.9333\n",
      "Epoch 971/1000\n",
      "120/120 [==============================] - 0s 269us/sample - loss: 0.1441 - accuracy: 0.9833 - val_loss: 0.1839 - val_accuracy: 0.9333\n",
      "Epoch 972/1000\n",
      "120/120 [==============================] - 0s 294us/sample - loss: 0.1440 - accuracy: 0.9833 - val_loss: 0.1838 - val_accuracy: 0.9333\n",
      "Epoch 973/1000\n",
      "120/120 [==============================] - 0s 254us/sample - loss: 0.1437 - accuracy: 0.9833 - val_loss: 0.1836 - val_accuracy: 0.9333\n",
      "Epoch 974/1000\n",
      "120/120 [==============================] - 0s 313us/sample - loss: 0.1435 - accuracy: 0.9833 - val_loss: 0.1836 - val_accuracy: 0.9333\n",
      "Epoch 975/1000\n",
      "120/120 [==============================] - 0s 402us/sample - loss: 0.1434 - accuracy: 0.9833 - val_loss: 0.1834 - val_accuracy: 0.9333\n",
      "Epoch 976/1000\n",
      "120/120 [==============================] - 0s 386us/sample - loss: 0.1432 - accuracy: 0.9833 - val_loss: 0.1830 - val_accuracy: 0.9333\n",
      "Epoch 977/1000\n",
      "120/120 [==============================] - 0s 314us/sample - loss: 0.1430 - accuracy: 0.9833 - val_loss: 0.1828 - val_accuracy: 0.9333\n",
      "Epoch 978/1000\n",
      "120/120 [==============================] - 0s 287us/sample - loss: 0.1428 - accuracy: 0.9833 - val_loss: 0.1827 - val_accuracy: 0.9333\n",
      "Epoch 979/1000\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 0.1426 - accuracy: 0.9833 - val_loss: 0.1826 - val_accuracy: 0.9333\n",
      "Epoch 980/1000\n",
      "120/120 [==============================] - 0s 291us/sample - loss: 0.1424 - accuracy: 0.9833 - val_loss: 0.1822 - val_accuracy: 0.9333\n",
      "Epoch 981/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 332us/sample - loss: 0.1422 - accuracy: 0.9833 - val_loss: 0.1821 - val_accuracy: 0.9333\n",
      "Epoch 982/1000\n",
      "120/120 [==============================] - 0s 327us/sample - loss: 0.1420 - accuracy: 0.9833 - val_loss: 0.1821 - val_accuracy: 0.9333\n",
      "Epoch 983/1000\n",
      "120/120 [==============================] - 0s 318us/sample - loss: 0.1418 - accuracy: 0.9833 - val_loss: 0.1820 - val_accuracy: 0.9333\n",
      "Epoch 984/1000\n",
      "120/120 [==============================] - 0s 315us/sample - loss: 0.1416 - accuracy: 0.9833 - val_loss: 0.1817 - val_accuracy: 0.9333\n",
      "Epoch 985/1000\n",
      "120/120 [==============================] - 0s 353us/sample - loss: 0.1414 - accuracy: 0.9833 - val_loss: 0.1817 - val_accuracy: 0.9333\n",
      "Epoch 986/1000\n",
      "120/120 [==============================] - 0s 300us/sample - loss: 0.1413 - accuracy: 0.9833 - val_loss: 0.1815 - val_accuracy: 0.9333\n",
      "Epoch 987/1000\n",
      "120/120 [==============================] - 0s 324us/sample - loss: 0.1411 - accuracy: 0.9833 - val_loss: 0.1815 - val_accuracy: 0.9333\n",
      "Epoch 988/1000\n",
      "120/120 [==============================] - 0s 293us/sample - loss: 0.1409 - accuracy: 0.9833 - val_loss: 0.1814 - val_accuracy: 0.9333\n",
      "Epoch 989/1000\n",
      "120/120 [==============================] - 0s 347us/sample - loss: 0.1408 - accuracy: 0.9833 - val_loss: 0.1812 - val_accuracy: 0.9333\n",
      "Epoch 990/1000\n",
      "120/120 [==============================] - 0s 395us/sample - loss: 0.1407 - accuracy: 0.9833 - val_loss: 0.1815 - val_accuracy: 0.9000\n",
      "Epoch 991/1000\n",
      "120/120 [==============================] - 0s 390us/sample - loss: 0.1404 - accuracy: 0.9833 - val_loss: 0.1813 - val_accuracy: 0.9000\n",
      "Epoch 992/1000\n",
      "120/120 [==============================] - 0s 282us/sample - loss: 0.1402 - accuracy: 0.9833 - val_loss: 0.1812 - val_accuracy: 0.9000\n",
      "Epoch 993/1000\n",
      "120/120 [==============================] - 0s 282us/sample - loss: 0.1400 - accuracy: 0.9833 - val_loss: 0.1811 - val_accuracy: 0.9000\n",
      "Epoch 994/1000\n",
      "120/120 [==============================] - 0s 297us/sample - loss: 0.1399 - accuracy: 0.9833 - val_loss: 0.1810 - val_accuracy: 0.9000\n",
      "Epoch 995/1000\n",
      "120/120 [==============================] - 0s 224us/sample - loss: 0.1396 - accuracy: 0.9833 - val_loss: 0.1807 - val_accuracy: 0.9000\n",
      "Epoch 996/1000\n",
      "120/120 [==============================] - 0s 286us/sample - loss: 0.1395 - accuracy: 0.9833 - val_loss: 0.1801 - val_accuracy: 0.9333\n",
      "Epoch 997/1000\n",
      "120/120 [==============================] - 0s 317us/sample - loss: 0.1393 - accuracy: 0.9833 - val_loss: 0.1798 - val_accuracy: 0.9333\n",
      "Epoch 998/1000\n",
      "120/120 [==============================] - 0s 301us/sample - loss: 0.1392 - accuracy: 0.9833 - val_loss: 0.1793 - val_accuracy: 0.9333\n",
      "Epoch 999/1000\n",
      "120/120 [==============================] - 0s 271us/sample - loss: 0.1389 - accuracy: 0.9833 - val_loss: 0.1791 - val_accuracy: 0.9333\n",
      "Epoch 1000/1000\n",
      "120/120 [==============================] - 0s 341us/sample - loss: 0.1387 - accuracy: 0.9833 - val_loss: 0.1790 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x139bb9910>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_X_train,y=y_train,epochs=1000,\n",
    "         validation_data=(scaled_X_test,y_test),callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.251584</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.209071</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.243828</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.204249</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.236645</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.199225</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.228879</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.194640</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.222413</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.190050</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.139458</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.180142</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.139277</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.179765</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.139171</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.179261</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.138921</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.179051</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.138711</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.179008</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy  val_loss  val_accuracy\n",
       "0    1.251584  0.333333  1.209071      0.333333\n",
       "1    1.243828  0.333333  1.204249      0.333333\n",
       "2    1.236645  0.333333  1.199225      0.333333\n",
       "3    1.228879  0.333333  1.194640      0.333333\n",
       "4    1.222413  0.333333  1.190050      0.300000\n",
       "..        ...       ...       ...           ...\n",
       "995  0.139458  0.983333  0.180142      0.933333\n",
       "996  0.139277  0.983333  0.179765      0.933333\n",
       "997  0.139171  0.983333  0.179261      0.933333\n",
       "998  0.138921  0.983333  0.179051      0.933333\n",
       "999  0.138711  0.983333  0.179008      0.933333\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13a0f5950>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13a14e910>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['accuracy','val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "30/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 90us/sample - loss: 0.1790 - accuracy: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17900750041007996, 0.93333334]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(scaled_X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
